<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Intel_Intrinsic_Functions]]></title>
    <url>%2F2019%2F05%2F12%2FIntel-Intrinsic-Functions%2F</url>
    <content type="text"><![CDATA[介绍SSE128位的SIMD指令集https://blog.csdn.net/woxiaohahaa/article/details/51014425SSE有8个128位寄存器，XMM0 ~XMM7 AVX2AVX2 expands most integer commands to 256 bits and introduces fused multiply-accumulate (FMA) operations.AVX uses sixteen YMM registers. Each YMM register contains: eight 32-bit single-precision floating point numbers or four 64-bit double-precision floating point numbers. AVX512AVX-512 are 512-bit extensions to the 256-bit Advanced Vector Extensions SIMD instructions for x86 instruction set architecture (ISA) 一般的流程参考这个知乎的回答https://www.zhihu.com/question/51206237 load：将数据从内存载入到寄存器里面 计算 save, 将数据从寄存器写入到内存变量里面 头文件Intrinsic functions 是直接提供给客户去调用的1#include &lt;immintrin.h&gt; 每个Intrinsic函数封装了调用了一些汇编 api手册查看这个linkhttps://software.intel.com/sites/landingpage/IntrinsicsGuide/打开一个函数，可以看到里面的汇编 反汇编查看示例代码：https://github.com/Leslie-Fang/Intel_Intrinsic_Functions在这个示例代码里面，调用了sse的_mm_add_ps(Intrinsic functions)去做加法，objdump -d main反汇编之后可以看到调用了addps的汇编指令，查看上面的API手册_mm_add_ps(Intrinsic functions)函数就是封装了这条指令]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BigDL源码分析]]></title>
    <url>%2F2019%2F04%2F19%2FBigDL%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Install先安装sparkhttps://spark.apache.org/downloads.html 编译bigdlhttps://bigdl-project.github.io/master/#ScalaUserGuide/install-build-src/1bash make-dist.sh -P spark_2.x 运行的例子每个model下面都有具体该如何运行的例子https://github.com/intel-analytics/BigDL/tree/master/spark/dl/src/main/scala/com/intel/analytics/bigdl/models/lenet 训练的时候java虚拟机的堆空间溢出java.lang.OutOfMemoryError: Java heap space 设置driver的memoryspark-submit –driver-memory 12g –master local[1] –class com.intel.analytics.bigdl.models.vgg.Train dist/lib/bigdl-0.8.0-jar-with-dependencies.jar -f /home/dataset/cifar10/cifar-10-batches-bin -b 4 Issue requirement failed: only mini-batch supported (2D tensor), got 1D tensor instead-b 指定的batchszie应该是core数量的4倍https://github.com/intel-analytics/BigDL/issues/462 源代码阅读如何在intellij中导入项目https://www.jianshu.com/p/81a484ac83aehttp://dengfengli.com/blog/how-to-run-and-debug-spark-source-code-locally/ 设计概念 运行初始化时的模型构建BigDL的设计是初始化的时候，一层一层将模型的读入，然后转化（每一层都寻找合适的BigDL的层，根据你输入的参数engine类型等），构建一个内部的图存在内存里面，以后的train或者inference的时候就使用这个内部的图 BigDL的INT8化也是这么做的，是在inference初始化的时候，读取FP32的模型，然后一层层转换成INT8的层，放到运行时内部的模型，正式inference的时候就使用这个内部模型 latency的问题Spark适合进行批处理但是针对一张图片进行inference的时候，因为spark需要构造图等初始化的工作，导致效率比较低所以BigDL针对一张图片的latency的测试 不使用spark，走另外一套逻辑 Resnet代码示例看这个package：package com.intel.analytics.bigdl.models.resnet目录里面的文件和结构：ResNet 构建resnet的模型DataSetTrainCIFAR10这个例子 碎片知识设置和读取环境变量System.getProperty(“leslie”, “false”)可以在编译的时候-Dleslie=100去设定这个环境变量在intellij里面为VM的参数然后通过System.getProperty(“leslie”, “false”)就可以去获取这个变量的值了，false这个地方填的是默认值 this.synchronized 原子操作https://www.jianshu.com/p/0cc4c330f25a12345def getUniqueId() = this.synchronized &#123; val freshUid = uidCount + 1 uidCount = freshUid freshUid &#125; 把这个函数定义成原子操作，也就是多个线程调用这个函数的时候，必须等一个线程调用结束之后，另一个线程才可以开始调用 INT8scaling:spark-submit –master local[1] –driver-memory 50G –executor-memory 100G –executor-cores 32 –total-executor-cores 1 –class com.intel.analytics.bigdl.example.mkldnn.int8.GenerateInt8Scales ./dist/lib/bigdl-0.8.0-jar-with-dependencies.jar -f /home/dataset/bigdl_imagenet –batchSize 4 –model /home/lesliefang/bigdl/pre-trained-models/resnet-50.quantized.bigdl inferencespark-submit –master local[1] –driver-memory 50G –conf “spark.serializer=org.apache.spark.serializer.JavaSerializer” –conf “spark.network.timeout=1000000” –conf “spark.driver.extraJavaOptions=-Dbigdl.engineType=mkldnn -Dbigdl.mkldnn.fusion=true” –conf “spark.executor.extraJavaOptions=-Dbigdl.engineType=mkldnn -Dbigdl.mkldnn.fusion=true” –executor-memory 100G –executor-cores 1 –class com.intel.analytics.bigdl.example.mkldnn.int8.ImageNetInference ./dist/lib/bigdl-0.8.0-jar-with-dependencies.jar -f /home/dataset/bigdl_imagenet –batchSize 4 –model /home/lesliefang/bigdl/pre-trained-models/resnet-50.quantized.bigdl 2&gt;&amp;1 | tee test.log]]></content>
      <tags>
        <tag>技术 深度学习 框架源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[wnd代码阅读]]></title>
    <url>%2F2019%2F03%2F16%2Fwnd%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[两个工具$ bazel build –strip=never \–config=mkl \–copt=’-g’ \//tensorflow/tools/graph_transforms:transform_graph$ bazel build –strip=never \–config=mkl \–copt=’-g’ \//tensorflow/tools/graph_transforms:summarize_graph 看对应的代码summarize_graph_main.cctransform_graph_main.cc summarize这个工具代码比较简单，主要用来打印出所有的节点的名字transform才是用来转换节点的，这个很重要 看transform_graph_main.ccParseFlagsAndTransformGraph 解析命令行参数调用ParseTransformParameters解析–transforms传进来的所有要执行的转换操作TransformGraph正式执行转换 ParseTransformParameters调用scanner去解析–transforms传进来的文本 TransformGraph遍历–transforms传进来的所有操作调用Status transform_result = transform_func(*graph_def, context, &amp;transformed_graph_def);去执行转换transform_func时通过GetTransformRegistry仓库拿到的 GetTransformRegistry有个TransformRegistry对象TransformRegistrar类是个仓库调用REGISTER_GRAPH_TRANSFORM往仓库里面注册transform的操作 代码里grep -rni “REGISTER_GRAPH_TRANSFORM”可以看到所有注册操作的地方 看具体注册的操作grep -rni “REGISTER_GRAPH_TRANSFORM(\”fuse_quantized_matmul_and_requantize” 一个转换的例子：$ $TF_SRC_ROOT/bazel-bin/tensorflow/tools/graph_transforms/transform_graph \–in_graph=a.pb \–out_graph=b.pb \–inputs=’Placeholder*’ \–outputs=’head/predictions/probabilities’ \–transforms=’strip_unused_nodes remove_nodes(op=Identity, op=CheckNumerics) remove_attribute(attribute_name=_class)’ 先看strip_unused_nodes操作12-bash-4.2# grep -rni &quot;REGISTER_GRAPH_TRANSFORM(\&quot;strip&quot;tensorflow/tools/graph_transforms/strip_unused_nodes.cc:192:REGISTER_GRAPH_TRANSFORM(&quot;strip_unused_nodes&quot;, StripUnusedNodes); 看模型运行读取pbtensorboard –logdir log/对比INT8和FP32两个模型，发现主要区别在DNN模型上面 INT8 DNN 模型TF 代码使用分支:git checkout remotes/origin/dungeon_wnd INT8 DNN从tensorboard上面看到调用op是QuantizedMatMulWithBiasAndReluAndRequantize 在代码里面grep这个op12tensorflow/core/kernels/mkl_qmatmul_op.cc:1182:REGISTER_KERNEL_BUILDER(Name(&quot;QuantizedMatMulWithBiasAndReluAndRequantize&quot;)tensorflow/core/kernels/mkl_qmatmul_op.cc:1190:REGISTER_KERNEL_BUILDER(Name(&quot;QuantizedMatMulWithBiasAndReluAndRequantize&quot;) 但是这两个op对应的实现都是NoOp,肯定是在graph INT8化的时候替换的到这里线索断了 但是在转换的时候具体怎么替换的，还有些小细节的地方没有完全清楚 那如何进一步去看没办法，编译debug版本的TF去debug 如何具体看MKLDNN的调用关系step1首先export MKLDNN_VERBOSE=1运行代码，得到mkldnn调用到的具体的kernel的名字，比如igemm_s8u8s32:blas step2在代码里面搜索igemm_s8u8s32:blas，得到对应的执行的代码在gemm_x8s8s32x_inner_product.cpp第62行的generate函数去执行 step3编译debug版本的tensorflow，gdb调试，断点打在gemm_x8s8s32x_inner_product.cpp第62行bt 去看调用栈123456789101112131415161718#0 mkldnn::impl::cpu::gemm_x8s8s32x_inner_product_fwd_t&lt;(mkldnn_data_type_t)6, (mkldnn_data_type_t)6&gt;::pp_kernel_t::generate (this=this@entry=0x32ea900) at external/mkl_dnn/src/cpu/gemm_x8s8s32x_inner_product.cpp:62#1 0x00007fc231ee0048 in mkldnn::impl::cpu::gemm_x8s8s32x_inner_product_fwd_t&lt;(mkldnn_data_type_t)6, (mkldnn_data_type_t)6&gt;::pp_kernel_t::pp_kernel_t (this=0x32ea900, pd=0x59cd000, dst_is_acc=&lt;optimized out&gt;) at external/mkl_dnn/src/cpu/gemm_x8s8s32x_inner_product.cpp:58#2 0x00007fc231be7613 in gemm_x8s8s32x_inner_product_fwd_t (outputs=..., inputs=..., apd=0x59cd000, this=0x395e300) at external/mkl_dnn/src/cpu/gemm_x8s8s32x_inner_product.hpp:118#3 mkldnn::impl::cpu::gemm_x8s8s32x_inner_product_fwd_t&lt;(mkldnn_data_type_t)6, (mkldnn_data_type_t)6&gt;::pd_t::create_primitive (this=0x59cd000, primitive=0x7fc20f8b4550, inputs=0x7fc20f8b4560, outputs=&lt;optimized out&gt;) at external/mkl_dnn/src/cpu/gemm_x8s8s32x_inner_product.hpp:44#4 0x00007fc22ee367cc in mkldnn::inner_product_forward::inner_product_forward (this=0x4f11990, aprimitive_desc=..., src=..., weights=..., bias=..., dst=...) at external/mkl_dnn/include/mkldnn.hpp:2813#5 0x00007fc22ee390bb in tensorflow::MklIPFwdPrimitive&lt;float, Eigen::QUInt8, Eigen::QInt8, Eigen::QInt32, Eigen::QUInt8&gt;::Setup (this=this@entry=0x38df300, IPFwdDims=...) at tensorflow/core/kernels/mkl_qmatmul_op.cc:267#6 0x00007fc22ee3965b in tensorflow::MklIPFwdPrimitive&lt;float, Eigen::QUInt8, Eigen::QInt8, Eigen::QInt32, Eigen::QUInt8&gt;::MklIPFwdPrimitive (this=0x38df300, IPFwdDims=...) at tensorflow/core/kernels/mkl_qmatmul_op.cc:77#7 0x00007fc22ee3a48c in Get (do_not_cache=false, IPFwdDims=...) at tensorflow/core/kernels/mkl_qmatmul_op.cc:298#8 tensorflow::MklIPOp&lt;Eigen::ThreadPoolDevice, Eigen::QUInt8, Eigen::QInt8, Eigen::QInt32, Eigen::QUInt8, Eigen::QUInt8, true&gt;::Compute (this=0x1a69760, context=context@entry=0x7fc20f8b6730) at tensorflow/core/kernels/mkl_qmatmul_op.cc:499#9 0x00007fc22ee40f0b in tensorflow::MklQuantizedIPOp&lt;Eigen::ThreadPoolDevice, Eigen::QInt32, Eigen::QUInt8, Eigen::QUInt8, true&gt;::Compute (this=&lt;optimized out&gt;, context=0x7fc20f8b6730) at tensorflow/core/kernels/mkl_qmatmul_op.cc:752#10 0x00007fc229a1ca4c in tensorflow::(anonymous namespace)::ExecutorState::Process (this=&lt;optimized out&gt;, tagged_node=..., scheduled_nsec=0) at tensorflow/core/common_runtime/executor.cc:1817 看到对应的tensorflow的kernel是MklIPFwdPrimitive wnd数据集google搜索criteo-kaggleDisplay Advertising Challengehttps://blog.csdn.net/horizonheart/article/details/78891501https://www.kaggle.com/c/criteo-display-ad-challenge使用以上数据集的训练代码https://github.com/Leslie-Fang/wnd_kaggle]]></content>
      <tags>
        <tag>深度学习 推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统]]></title>
    <url>%2F2019%2F03%2F07%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[推荐系统介绍https://zhuanlan.zhihu.com/p/54464005包含召回和排序两个阶段 所有推荐系统的论文https://github.com/talentlei/PaperListhttps://www.jianshu.com/p/28a1849f6707 TF实现代码https://github.com/tensorflow/models/tree/master/official/wide_deep 美团实战的文章https://gitbook.cn/books/5aa0dd15cfbe2c144b71906d/index.html 术语one-hot编码：https://www.jianshu.com/p/a47a1c1fa3f1，onehot编码神经网络处理不来，用在线性模型里面特征嵌入Embedding:https://blog.csdn.net/pipisorry/article/details/76095118https://juejin.im/post/599183c6f265da3e2e5717d2 输入数据特征特征处理的文章：https://mp.weixin.qq.com/s/847h4ITQMtUlZcurJ9Vlvg?scene=25##wide侧：离散特征(高维离散特征)deep侧：组合特征和连续特征离散特征进行one-hot编码连续特征进行归一化组合特征：由低维的离散特征Embedding得到,one-hot编码编码之后数据量太大，通过矩阵映射到一个底维度的空间 用哪些特征作为输入https://zhuanlan.zhihu.com/p/32781570]]></content>
      <tags>
        <tag>技术 深度学习 推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow二次开发]]></title>
    <url>%2F2019%2F02%2F27%2Ftensorflow%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[编译 方法1： 1234567./configurebazel build --config=opt //tensorflow/tools/pip_package:build_pip_packagebuild出错清理：/root/.cache/bazel把下面的之前出错的缓存文件给删除掉生成whell包bazel-bin/tensorflow/tools/pip_package/build_pip_package /root/tensorflow/wheel_pkg/build_withSource 方法2： 1234yes &quot;&quot; | python configure.pybazel build --config=mkl --copt=-mavx2 --copt=-O3 --copt=-DINTEL_MKL_QUANTIZED -s //tensorflow/tools/pip_package:build_pip_package生成whell包bazel-bin/tensorflow/tools/pip_package/build_pip_package /root/tensorflow/wheel_pkg/build_withSource 编译命令和过程分析视频：https://www.youtube.com/watch?v=Rw-KrbfyABQhttps://www.cnblogs.com/shouhuxianjian/p/9416934.html 运行configure.py会把一些编译参数放入.bazelrc和.tf_configure.bazelrc文件里面(https://www.jianshu.com/p/5cd111ebb8bb)bazelrc文件的解释https://docs.bazel.build/versions/master/guide.html build 后面接的都是默认的编译参数build:mkl 后面接的编译参数只有当bazel build –config=mkl的时候mkl后面的编译参数才会起作用 -c的选项有可能是–config的缩写 bazel build的其他编译选项：https://docs.bazel.build/versions/master/user-manual.html–copt： This option takes an argument which is to be passed to the compiler. 所以–copt后面传进来的都是gcc或者是icc的编译参数 –strip是否删除debug信息，never表示不删除debug信息 增量编译直接bazel build然后重新生成wheel包pip unistall tensorflow一定先卸载然后重新安装否则还是原来的包 编译之后生成pywrap_tensorflow_internal.py 以及 pywrap_tensorflow_internal.cc在~/.cache/bazel目录下面,所有代码都在_pywrap_tensorflow_internal.so 的动态链接库里面pywrap_tensorflow_internal.py: 负责对接上层 Python 调用pywrap_tensorflow_internal.cc: 负责对接下层 C API 调用 pywrap_tensorflow_internal.py 模块首次被导入时，自动地加载 _pywrap_tensorflow_internal.so 的动态链接库；其中， _pywrap_tensorflow_internal.so包含了整个 TensorFlow 运行时的所有符号。 在 pywrap_tensorflow_internal.cc 的实现中，静态注册了一个函数符号表，实现了 Python 函数名到 C 函数名的二元关系。在运行时，按照 Python 的函数名称，匹找到对应的 C 函数实现，最终实现 Python 到 c_api.c 具体实现的调用关系。 调整tensorflow运行的日志等级TF代码又两个函数打印日志,LOG以及VLOGLOG是正常的打印日志，通过TF_CPP_MIN_LOG_LEVEL1export TF_CPP_MIN_LOG_LEVEL=level 去设置，值越小，打印日志越多VLOG通过1export TF_CPP_MIN_VLOG_LEVEL=level 去设置，但是VLOG只有在LOG等级为0的时候设置才有用比如要打印mkl_layout_pass.cc初始化rewirte op时的信息12export TF_CPP_MIN_LOG_LEVEL=0export TF_CPP_MIN_VLOG_LEVEL=1 编译debug版本的tensorflow添加 -c dbg选项移除优化选项 –copt=-O3 以及 -c opt1bazel build --config=mkl --copt=-mavx2 --copt=-O3 --copt=-DINTEL_MKL_QUANTIZED -s -c dbg //tensorflow/tools/pip_package:build_pip_package debug版本编译完大概有20G左右 指定编译目录默认编译在/root/.cache/bazel目录下面，有时候root目录空间不够123build_dir=/home/lesliefang/bazel_buildbazel --output_user_root=$build_dir cleanbazel --output_user_root=$build_dir build --config=mkl --copt=-mavx2 --copt=-O3 --copt=-DINTEL_MKL_QUANTIZED -s -c dbg //tensorflow/tools/pip_package:build_pip_package 编译报错找不到–march=broadwell使用gcc6.3以及以上版本，低版本的编译器不认识broadwell的选项 whell太大无法打包https://github.com/tensorflow/tensorflow/issues/5538 替换mkldnn版本以TF从0.18升级到0.19为例 下载mkldnn0.19计算sha256sum12345wget https://github.com/intel/mkl-dnn/archive/v0.19.tar.gzsha256sum v0.19.tar.gz记录这个结果ba39da6adb263df05c4ca2a120295641fc97be75b588922e4274cb628dbe1dcd后面会用到 修改$tensorflow_root/tensorflow/workspace.bzl搜索mkl_dnn123456789101112131415121 # Important: If you are upgrading MKL-DNN, then update the version numbers 122 # in third_party/mkl_dnn/mkldnn.BUILD. In addition, the new version of 123 # MKL-DNN might require upgrading MKL ML libraries also. If they need to be 124 # upgraded then update the version numbers on all three versions above 125 # (Linux, Mac, Windows). 126 tf_http_archive( 127 name = &quot;mkl_dnn&quot;, 128 build_file = clean_dep(&quot;//third_party/mkl_dnn:mkldnn.BUILD&quot;), 129 sha256 = &quot;38a1c02104ee9f630c1ad68164119cd58ad0aaf59e04ccbe7bd5781add7bfbea&quot;, 130 strip_prefix = &quot;mkl-dnn-0.18&quot;, 131 urls = [ 132 &quot;http://mirror.tensorflow.org/github.com/intel/mkl-dnn/archive/v0.18.tar.gz&quot;, 133 &quot;https://github.com/intel/mkl-dnn/archive/v0.18.tar.gz&quot;, 134 ], 135 ) 把里面所有0.18替换成0.19 替换上面得到的sha256sum 看第二步的注释和代码需要修改”//third_party/mkl_dnn:mkldnn.BUILD”$tensorflow_root/tensorflow/workspace.bzlvim $tensorflow_root/third_party/mkl_dnn/mkldnn.BUILD把里面的版本号从0.18改到0.19 注意：tensorflow里面，mkldnn是被当做source code编译进去的，所以不存在动态链接库 check:build_dir/b3a4cb07d89ceca0353d37b5d32ffadc/external/mkl_dnn里面是mkldnn下载下来的代码里面有个readme文件在开头的地方可以check版本是0.18还是0.19 gdb 调试二种方法方法去debug TF:method1:1231. gdb python2. run file.py3. bt method2:1234561. 跑测试2. top 看到python进程的pid3. gdb -p pid挂上之后，原来测试会挂住break 函数名或者其它打上断点,tensorflow找不到符号的情况下可以 文件名:line的方式去打断点continue 继续测试直到core-dump 如何添加python的信息 参考这个bloghttp://jcf94.com/2018/01/13/2018-01-13-tfunpacking/ warning找不到文件dir 目录去指定文件的搜索根目录使用gdbgui去调试的时候，也需要指定了目录之后才可以显示文件 调试前的参数设置以及技巧所有并行计算线程设置为1，避免多线程导致断点带来的麻烦命令后加&amp;echo $! 输出PID，进行gdb -p的调试 mkldnn调试12export MKLDNN_VERBOSE=1python *** 在运行测试之前，添加环境变量可以打出mkldnn的信息每一行的信息Each line with verbose information is formatted as a comma-separated list containing: mkldnn_verbose stage, e.g. create or exec primitive-kind, e.g. convolution, reorder, sum, … primitive implementation name propagation-kind, e.g. forward_training input/output data info, e.g. data type and data format auxiliary information, e.g. algorithm or number of input problem description for convolution the problem description is dumped in benchdnn friendly format for reorder, sum, and concat problem description is simply logical dims for other primitives the problem description is similar to convolution one execution time in milliseconds 看python到C++调用关系以Session 为例子：tf.Session时候的调用关系 python api/root/tensorflow_src/test_code/private-tensorflow/tensorflow/python目录下面： grep -rni “class Session”client/session.py:1475:class Session(BaseSession):里面调用了baseSession的构造函数 看baseSession里面调用了tf_session 12self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts)from tensorflow.python import pywrap_tensorflow as tf_session 看pywrap_tensorflow.py这个就是对应了编译出来的so文件 在source insight里面搜索TF_NewSessionRef看到定义在tf_session_help.cc里面里面调用了TF_NewSession source insight里面搜索TF_NewSession已经进入到C++ 代码内部 以matmul为列https://ggaaooppeenngg.github.io/zh-CN/2018/05/29/Tensorflow-%E7%9A%84-Tensor-%E5%92%8C-OpKernel-%E5%88%86%E6%9E%90/调用 tf.matmul(a,b) 查看1grep -rni &quot;tf_export.*matmul&quot; #这个函数需要用tf_export导出 ops/math_ops.py:2277:@tf_export(“linalg.matmul”, “matmul”) 看math_ops.py:2277api的使用有详细的解释调用了gen_math_ops.batch_mat_mul 或者 gen_math_ops.mat_mul 看gen_math_ops.py 1find / -name &quot;gen_math_ops.py&quot; 这个文件看文件名字，应该是在编译的时候生成的这个文件里面搜:batch_mat_mul batch_mat_mul函数这个函数里面调用了1234_result = _pywrap_tensorflow.TFE_Py_FastPathExecute( _ctx._context_handle, _ctx._eager_context.device_name, &quot;BatchMatMul&quot;, name, _ctx._post_execution_callbacks, x, y, &quot;adj_x&quot;, adj_x, &quot;adj_y&quot;, adj_y) 所以C++里面的op函数应该是BatchMatMul 搜索所有注册这个op的地方搜索op定义12[root@localhost private-tensorflow]# grep -rni &quot;REGISTER_OP(\&quot;MatMul\&quot;)&quot;tensorflow/core/ops/math_ops.cc:763:REGISTER_OP(&quot;MatMul&quot;) 搜索op的kernel实现1grep -rni &quot;Name(\&quot;MatMul\&quot;)&quot; 找到所有定义operationbreak 文件名:行在每个computer的d地方打断点看看调用到了哪个kernel 看class MatMulOp 的Compute方法里面最后调用了LaunchMatMul方法LaunchMatMul 继承自LaunchMatMulBase，在 LaunchMatMulBase 当中调用了 functor::MatMulFunctor，这个 functor 主要就会执行乘法操作 MatMulFunctor里面调用了MatMul方法MatMul方法里面进一步调用了out.device(d) = in0.contract(in1, dim_pair); contract是Eigen的一个方法，表示矩阵相乘，Eigen是一套高效的C++中调用的数学平台，里面实现了很多通用的数学运算。 以conv2d为例这个人博客很多好文章：http://lanhin.xyz/http://lanhin.xyz/2018/10/29/tensorflow%E4%B8%AD2d%E5%8D%B7%E7%A7%AF%E4%BB%A3%E7%A0%81%E7%AE%80%E6%9E%90/ python 接口 tf.nn.conv2d1grep -rni &quot;tf_export.*conv2d&quot; tensorflow_src/test_code/private-tensorflow/tensorflow/python/ops/nn_ops.py:1376:@tf_export(“nn.conv2d”, v1=[]) 查找输出的地方 1find / -name &quot;gen_math_ops.py&quot; 查看op注册和实现的地方 12grep -rni &quot;REGISTER_OP(\&quot;Conv2D\&quot;)&quot;grep -rni &quot;Name(\&quot;Conv2D\&quot;)&quot; 进入conv_ops.cc文件看Compute方法 输入为浮点数float调用LaunchDeepConvOp::Run 其它输入类型调用launcher_进一步看调用到了LaunchConv2DOp::operator()再往下tensorflow::LaunchGeneric::operator这个函数里面通过不同的条件判断调用两个不同的计算kernel：functor::MatMulConvFunctor()和functor::SpatialConvolution() MatMulConvFunctor定义在conv_2d.h文件里面out.device(d) = in0.contract(in1, dim_pair, output_kernel);到最后还是调用了矩阵乘法的函数这个contract应该是eigen库提供的接口 INT8 operation 读取RN50 int8的pb用tensorboard查看看到用到了op：QuantizedConv2DWithBiasAndReluAndRequantize 搜索不到对应op的时候tensorflow做了op的转换private-tensorflow\tensorflow\core\graph\mkl_layout_pass.cc参考这个文件果然再这个文件里面可以搜索到QuantizedConv2DWithBiasAndReluAndRequantizemkl_layout_pass.cc 根据PPT里面的解释，会把标准的输入的TF的graph转换成mkl优化的图，里面有个run函数应该是转换的入口 也有可能定义tensorflow/core/api_def/base_api/api_def_QuantizedMatMulWithBias.pbtxt这个目录下面也可能定义了pb文件 python api有两种定义方法（https://groups.google.com/a/tensorflow.org/forum/#!topic/developers/LmKn-y7LZ_E）：Python API endpoints are currently added using 2 ways: apidef.pbtxt files (python_op_gen_internal.cc would actually add tf_export decorator for each visible endpoint specified in apidef.pbtxt files) tf_export decorators 搜索这个op 12[root@localhost ~]# grep -rni &quot;name(\&quot;QuantizedConv2DWithBiasAndReluAndRequantize\&quot;)&quot;tensorflow_src/test_code/private-tensorflow/tensorflow/core/kernels/mkl_conv_ops.cc:1997:REGISTER_KERNEL_BUILDER(Name(&quot;QuantizedConv2DWithBiasAndReluAndRequantize&quot;) 这个op对应的kernel实现就是QuantizedConv2DWithBiasAndReluAndRequantize对应的kernel叫做NoOp看到注释：// Register NoOp kernel for QuantizedConv2DWithBiasAndRelu to get a python// interface.// This kernel will be replaced by an MKL kernel during graph-optimization pass. NoOp是因为这个op在图优化阶段被rewrite了(mkl_layout_pass.cc的RunPass函数) 同一个文件里面看另外一个op1_MklQuantizedConv2DWithBiasSumAndRelu 对应的kernel是MklQuantizedConv2DSumReluOp继承了MklQuantizedConv2DOp这个kernelMklQuantizedConv2DOp这个kernel继承了MklConvOpMklQuantizedConv2DOp的compute方法首先调用了123// Compute int32 output tensorMklConvOp&lt;Device, quint8, qint8, Tbias, Toutput, Ttemp_output, int32, biasEnabled, false&gt;::Compute(context); MklConvOp里面的compute方法调用了mkldnnconv_fwd-&gt;Execute执行mkldnn的计算 注意class MklConvOp在这个文件里面有两个类的定义通过template Execute 根据文件里面的宏的定义，应该只有一个函数会被编译出来 看这个mkldnn的类的实现代码，可以先看看MKLDNN的教程和实例代码mkldnn代码库的simple_net.cpp以及解释基本概念比较清晰，先创建memory/operator descriptor,再创建对应的Primitive descriptor ，最后创建primitive,然后把primitive放到stream里面去执行tensorflow的这个类的实现follow这个逻辑只是加了一些封装至于mkldnn里面进一步的实现(如何多线程等)就是mkldnn的事情了可以看我的mkldnn的文章 自己定义个operation参考文档：http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/adding_an_op.html#AUTOGENERATED-adding-a-new-op 定义operation1234#include &quot;tensorflow/core/framework/op.h&quot;REGISTER_OP(&quot;ZeroOut&quot;) .Input(&quot;to_zero: int32&quot;) .Output(&quot;zeroed: int32&quot;); 定义kernel12345678910111213141516171819202122232425#include &quot;tensorflow/core/framework/op_kernel.h&quot;using namespace tensorflow;class ZeroOutOp : public OpKernel &#123; public: explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) &#123;&#125; void Compute(OpKernelContext* context) override &#123; // 获取输入 tensor. const Tensor&amp; input_tensor = context-&gt;input(0); auto input = input_tensor.flat&lt;int32&gt;(); // 创建一个输出 tensor. Tensor* output_tensor = NULL; OP_REQUIRES_OK(context, context-&gt;allocate_output(0, input_tensor.shape(), &amp;output_tensor)); auto output = output_tensor-&gt;template flat&lt;int32&gt;(); // 设置 tensor 除第一个之外的元素均设为 0. const int N = input.size(); for (int i = 1; i &lt; N; i++) &#123; output(i) = 0; &#125; // 尽可能地保留第一个元素的值. if (N &gt; 0) output(0) = input(0); &#125;&#125;;REGISTER_KERNEL_BUILDER(Name(&quot;ZeroOut&quot;).Device(DEVICE_CPU), ZeroOutOp); 添加python wrap经过前面两步在编译之后，可以在bazel-genfiles/tensorflow/python/ops/gen_user_ops.py文件，比如我的一个例子vim /home/lesliefang/bazel_build/615e7e34d0a05b2b7ebac45eda8ba3c5/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/pip_package/build_pip_package.runfiles/org_tensorflow/tensorflow/python/ops/gen_user_ops.py里面找到对应的operation的函数为了使得python可以调用到,在tensorflow/python/user_ops/user_ops.py 文件中添加接口1234@tf_export(v1=[&apos;user_ops.leslie_zero_out&apos;])def leslie_zero_out(input): &quot;&quot;&quot;Example of overriding the generated code for an Op.&quot;&quot;&quot; return _gen_user_ops.zero_out(input) 测试重新编译之后安装之后测试代码12345678910111213import tensorflow as tfimport numpy as npimport datetimeimport osimport timeif __name__ == &quot;__main__&quot;: #time.sleep(30) with tf.Session() as sess: sess.run(tf.global_variables_initializer()) result = tf.user_ops.leslie_zero_out([5, 4, 3, 2, 1]) print(&quot;result is &#123;&#125;&quot;.format(result)) print(&quot;result is &#123;&#125;&quot;.format(sess.run(result))) 多线程To write a multi-threaded CPU kernel, the Shard function in work_sharder.h can be used. This function shards a computation function across the threads configured to be used for intra-op threading (see intra_op_parallelism_threads in config.proto). 核心运行机制推荐一个很好的Blog:http://jcf94.com/2018/01/13/2018-01-13-tfunpacking/这个blog对C++部分session的机制分析的很清楚 这边从python调用session.run开始分析 在python里面1.session.run 12result = self._run(None, fetches, feed_dict, options_ptr, run_metadata_ptr) 在_run里面 12results = self._do_run(handle, final_targets, final_fetches, feed_dict_tensor, options, run_metadata) do_run里面 12return self._call_tf_sessionrun( options, feed_dict, fetch_list, target_list, run_metadata) call_tf_sessionrun里面 123return tf_session.TF_SessionRun_wrapper( self._session, options, feed_dict, fetch_list, target_list, run_metadata) TF_SessionRun_wrapper 定义在pywrap_tensorflow_internal.py里面就是python和C++的桥梁 下面进入C++的部分 TF_SessionRun_wrapper_helper函数里面调用了TF_SessionRun TF_SessionRun 函数调用了TF_Run_Helper函数 TF_Run_Helper函数调用了session-&gt;Run函数 这是个虚函数用gdb跟进去看参考这篇文章：https://zhuanlan.zhihu.com/p/26031658local用direction_session分布式用grpc_session所以我们这边调用到了DirectSession::Run 看DirectSession::Run函数这个函数的分析：http://jcf94.com/2018/01/13/2018-01-13-tfunpacking/ GetOrCreateExecutors函数里面会去寻找有没有符合条件的exectuor，不存在的话则调用CreateExecutors函数去创建executors同时CreateExecutors里面调用到了CreateGraphs在CreateExecutors调用了CreateGraphs之后看到：12params.create_kernel = [this, lib, opseg](const NodeDef&amp; ndef, OpKernel** kernel) 我理解就是在这里实现了param里面的创建kernel的函数指针在CreateExecutors的最后调用了NewExecutor函数，会传入param变量(里面带上了create_kernel方法)NewExecutor函数里面通过工厂模式来生成Executor是个虚函数，通过gdb看到里面调用了tensorflow::(anonymous namespace)::DefaultExecutorRegistrar::Factory::NewExecutor (this=0x1fffd10, params=…, graph=…, out_executor=0x72fdee8) at tensorflow/core/common_runtime/executor.cc:285712345678910class Factory : public ExecutorFactory &#123; Status NewExecutor(const LocalExecutorParams&amp; params, std::unique_ptr&lt;const Graph&gt; graph, std::unique_ptr&lt;Executor&gt;* out_executor) override &#123; Executor* ret = nullptr; TF_RETURN_IF_ERROR(NewLocalExecutor(params, std::move(graph), &amp;ret)); out_executor-&gt;reset(ret); return Status::OK(); &#125;&#125;; 里面调用了NewLocalExecutor进一步调用ExecutorImpl-&gt;Initialize函数这个函数里面调用了params_.create_kernel函数去创建kernel(这个create_kernel函数就是之前在CreateExecutors函数里面定义的)同时在这个函数里面看到了一行注释12// Preprocess every node in the graph to create an instance of op// kernel for each node. 调试CreateExecutors的create_kernel函数gdb断点进去CreateKernel函数tensorflow/core/common_runtime/function.cc:521调用到526行的CreateKernel函数tensorflow/core/common_runtime/function.cc:526executor.cc的CreateNonCachedKernel函数op_kernel.cc的CreateOpKernel函数（*kernel = registration-&gt;factory-&gt;Create(&amp;context);）mkl_conv_ops.cc的TF_CALL_float(REGISTER_MKL_CPU_2D_FUSED);函数mkl_conv_ops.cc的MklFusedConvOp的构造函数 所以调用session.run多次，因为已经存在符合条件的exectuors，并不会多次创建图（别人的评论：第一次执行 sess.run(….) 的时候会根据 python 层的图构造出 C++ 层的图然后保存下来，之后如果下次 sess.run() 的目标节点是相同的，就不需要重新构造一遍了。详细可以去分析 sess.run() 的执行流程） 调用到了RunInternal函数 RunInternal函数里面调用了item.executor-&gt;RunAsync(args, barrier-&gt;Get());去执行异步计算 通过日志知道RunAsync会调用到executor的Process()函数process函数做了什么：http://jcf94.com/2018/01/13/2018-01-13-tfunpacking/遍历每个节点，针对每个节点的kernel进行计算（调用device-&gt;Compute，里面调用op_kernel-&gt;Compute(context);）在每个kernel里面都可以搜索到对应的Compute函数 看一个inner product的kernel是怎么生成的断点打在1b mkl_qmatmul_op.cc:183(一个setup函数里面) 汾西代码知道这个setup函数是设置上下文变量的查看调用栈12345678910111213#0 tensorflow::MklIPFwdPrimitive&lt;float, Eigen::QUInt8, Eigen::QInt8, Eigen::QInt32, Eigen::QUInt8&gt;::Setup (this=0x3d1a300, IPFwdDims=...) at tensorflow/core/kernels/mkl_qmatmul_op.cc:183#1 0x00007f6a77ee938c in tensorflow::MklIPFwdPrimitive&lt;float, Eigen::QUInt8, Eigen::QInt8, Eigen::QInt32, Eigen::QUInt8&gt;::MklIPFwdPrimitive (this=0x3d1a300, IPFwdDims=...) at tensorflow/core/kernels/mkl_qmatmul_op.cc:77#2 0x00007f6a77ee81c3 in tensorflow::MklIPFwdPrimitiveFactory&lt;float, Eigen::QUInt8, Eigen::QInt8, Eigen::QInt32, Eigen::QUInt8&gt;::Get (IPFwdDims=..., do_not_cache=false) at tensorflow/core/kernels/mkl_qmatmul_op.cc:298#3 0x00007f6a77ee0515 in tensorflow::MklIPOp&lt;Eigen::ThreadPoolDevice, Eigen::QUInt8, Eigen::QInt8, Eigen::QInt32, Eigen::QUInt8, Eigen::QUInt8, true&gt;::Compute ( this=0x1ea0f20, context=0x7f6a53f1d5f0) at tensorflow/core/kernels/mkl_qmatmul_op.cc:499#4 0x00007f6a77edee0e in tensorflow::MklQuantizedIPOp&lt;Eigen::ThreadPoolDevice, Eigen::QInt32, Eigen::QUInt8, Eigen::QUInt8, true&gt;::Compute (this=0x1ea0f20, context=0x7f6a53f1d5f0) at tensorflow/core/kernels/mkl_qmatmul_op.cc:752#5 0x00007f6a78410eae in tensorflow::Device::Compute (this=0x40a6780, op_kernel=0x1ea0f20, context=0x7f6a53f1d5f0) at ./tensorflow/core/common_runtime/device.h:89#6 0x00007f6a6c90f868 in tensorflow::(anonymous namespace)::ExecutorState::Process (this=0x54f6480, tagged_node=..., scheduled_nsec=0) at tensorflow/core/common_runtime/executor.cc:1817 #0 mkl_qmatmul_op.cc:183 在tensorflow里面这个primitive的setup函数看这个setup里面，看到先创建mkldnn的primitive的desc12345// create a inner product context_.fwd_desc.reset(new inner_product_forward::desc( prop_kind::forward_inference, *context_.src_md, *context_.weight_md, *context_.bias_md, *context_.dst_md)); 然后通过这个desc去创建primitive_desc(pd),跟进到mkldnn里面看，就是在创建pd的时候回去遍历mkldnn里面所有pd找到对应的满足条件的pd #1 mkl_qmatmul_op.cc:77 MklIPFwdPrimitive的构造函数 #2 mkl_qmatmul_op.cc:298 MklIPFwdPrimitiveFactory的Get函数，Get函数根据输入的MklIPFwdParams去try to find a suitable one in pool没有找到的话(if (IP_fwd == nullptr))会去创建 #3 mkl_qmatmul_op.cc:499 MklIPOp的compute方法，里面调用了MklIPFwdPrimitiveFactory的Get方法去拿到对应的IP_fwd(Primitive)MklIPOp的compute方法 应该是tensorflow在运行图的节点的时候会被调用到的方法继续看这个MklIPOp的compute方法后面会调用IP_fwd-&gt;Execute(src_data, weight_data, bias_data, dstdata);去做计算这个根据前几步选中的mkldnn的pd，会调用到mkldnn的submit函数(context.fwdstream-&gt;submit(context.fwd_primitives);)可以用GDB去跟进mkldnn去看调用关系，这里已经比较好理解了结论所以tensorflow的node到mkldnn的kernel的对应关系，是在第一次运行这个图的时候确认的，同时如果set了cache(默认都是设置的),后面几次运行的时候就会保留这个对应关系 #4 mkl_qmatmul_op.cc:752 MklQuantizedIPOp的Compute函数，这个函数会去调用MklIPOp的compute方法 #5 device.h:89 Device的Compute()是个虚函数,对应了device信息 #6 executor.cc:1817 ExecutorState::Process函数，这里已经是tensorflow创建了exectuor之后的执行了 #7 executor.cc:2258 ExecutorState::ScheduleReady 总结，关键是这个MklIPOp的compute方法，先通过Get方法去获得对应的mkldnn的kernel，然后调用execute去执行 通过pb文件去看调用的kernel 在代码里面加载输出每个节点的名字123456graph_def = graph_pb2.GraphDef()with open(args.input_graph, &quot;rb&quot;) as f: graph_def.ParseFromString(f.read()) #f就是pb文件for node in graph_def.node: k = node.name print(&quot;node op is &#123;&#125;&quot;.format(node.op)) 打印出node的名字比如其中一个MatMul 加载pb用tensorboard大概看一下123456789101112131415161718192021222324252 import pandas as pd3 import csv4 import struct5 from PIL import Image6 import numpy as np7 import datetime8 import os9 import argparse10 import tensorflow as tf1112 if __name__ == &quot;__main__&quot;:13 parser = argparse.ArgumentParser()14 parser.add_argument(&quot;mode&quot;, help=&quot;display a square of a given number&quot;)15 args = parser.parse_args()16 from tensorflow.python.platform import gfile17 with gfile.FastGFile(args.mode, &apos;rb&apos;) as f:18 graph_def = tf.GraphDef()19 graph_def.ParseFromString(f.read())20 for node in graph_def.node:21 print(&quot;node name is: &#123;&#125; \t node op is: &#123;&#125;&quot;.format(node.name,node.op))22 #tensorboard23 with tf.Session() as sess:24 sess.graph.as_default()25 tf.import_graph_def(graph_def, name=&apos;&apos;)26 summaryWriter = tf.summary.FileWriter(&apos;log/&apos;, sess.graph) 跑完之后，命令行运行tensorboard –logdir log/ 在tensorlfow里面搜索注册这个op和kernel的地方比如第二步打印看到的node.op是 Conv2D在代码里面搜索1grep -rni &quot;Name(\&quot;.*Conv2D.*\&quot;)&quot; 因为注册的kernel可能是Conv2D也有可能加了mkl前缀比如:REGISTER_KERNEL_BUILDER(Name(“_MklConv2D”)在directSession，创建新的exector的时候会去优化graph，这个时候会把Conv2D这个op转换成_MklConv2D，一般就是添加_MKL的前缀在mkl_layout_pass.cc这个文件的RunPass函数里面，会去做图的优化，包括临近节点的合成，op的rewrite以及mkldnn节点前添加数据格式的转换等op创建kernel时候的调用栈断点打在mkl_conv_ops.cc:861123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#0 tensorflow::MklConvOp&lt;Eigen::ThreadPoolDevice, float, float, float, float, float, int, false, false&gt;::MklConvOp (this=this@entry=0x36b35400, context=context@entry=0x7ffca8d435c0) at tensorflow/core/kernels/mkl_conv_ops.cc:861#1 0x00007fa3b9de7ecc in tensorflow::MklFusedConvOp&lt;Eigen::ThreadPoolDevice, float, float, float, float, float, int, true&gt;::MklFusedConvOp ( this=0x36b35400, context=0x7ffca8d435c0) at tensorflow/core/kernels/mkl_conv_ops.cc:1474#2 0x00007fa3b9dcd7b2 in operator() (__closure=0x0, context=0x7ffca8d435c0) at tensorflow/core/kernels/mkl_conv_ops.cc:2165#3 tensorflow::&lt;lambda(tensorflow::OpKernelConstruction*)&gt;::_FUN(tensorflow::OpKernelConstruction *) () at tensorflow/core/kernels/mkl_conv_ops.cc:2165#4 0x00007fa3b469ac77 in tensorflow::CreateOpKernel (device_type=..., device=device@entry=0x3c346e0, allocator=allocator@entry=0x1c1e380, flib=flib@entry=0x36bae2c0, node_def=..., graph_def_version=0, kernel=0x15b5c4bc8) at tensorflow/core/framework/op_kernel.cc:1302#5 0x00007fa3b498f80f in tensorflow::CreateNonCachedKernel (device=0x3c346e0, flib=flib@entry=0x36bae2c0, ndef=..., graph_def_version=&lt;optimized out&gt;, kernel=kernel@entry=0x15b5c4bc8) at tensorflow/core/common_runtime/executor.cc:2764#6 0x00007fa3b49aaaf7 in tensorflow::FunctionLibraryRuntimeImpl::CreateKernel (this=0x36bae2c0, ndef=..., lib_def=0x372c000, kernel=0x15b5c4bc8) at tensorflow/core/common_runtime/function.cc:539#7 0x00007fa3b49aac18 in tensorflow::FunctionLibraryRuntimeImpl::CreateKernel (this=&lt;optimized out&gt;, ndef=..., kernel=&lt;optimized out&gt;) at tensorflow/core/common_runtime/function.cc:515#8 0x00007fa3ba11e40b in operator() (kernel=0x15b5c4bc8, ndef=..., __closure=0x2ef1e660) at tensorflow/core/common_runtime/direct_session.cc:1261#9 std::_Function_handler&lt;tensorflow::Status(const tensorflow::NodeDef&amp;, tensorflow::OpKernel**), tensorflow::DirectSession::CreateExecutors(const tensorflow::CallableOptions&amp;, std::unique_ptr&lt;tensorflow::DirectSession::ExecutorsAndKeys&gt;*, std::unique_ptr&lt;tensorflow::DirectSession::FunctionInfo&gt;*, tensorflow::DirectSession::RunStateArgs*)::&lt;lambda(const tensorflow::NodeDef&amp;, tensorflow::OpKernel**)&gt; &gt;::_M_invoke(const std::_Any_data &amp;, const tensorflow::NodeDef &amp;, &lt;unknown type in /home/lesliefang/venv_python36_RN50_Debug/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, CU 0x23b51f7a, DIE 0x23c57fc7&gt;) (__functor=..., __args#0=..., __args#1=&lt;optimized out&gt;) at /home/lesliefang/gcc63/lib/gcc/x86_64-pc-linux-gnu/6.3.0/../../../../include/c++/6.3.0/functional:1717#10 0x00007fa3b49a164e in operator() (__args#1=&lt;optimized out&gt;, __args#0=..., this=0x169d87cf8) at /home/lesliefang/gcc63/lib/gcc/x86_64-pc-linux-gnu/6.3.0/../../../../include/c++/6.3.0/functional:2127#11 tensorflow::(anonymous namespace)::ExecutorImpl::Initialize (this=this@entry=0x169d87ce0) at tensorflow/core/common_runtime/executor.cc:620#12 0x00007fa3b49a3646 in tensorflow::NewLocalExecutor (params=..., graph=..., executor=executor@entry=0x7ffca8d44218) at tensorflow/core/common_runtime/executor.cc:2749#13 0x00007fa3b49a36d2 in tensorflow::(anonymous namespace)::DefaultExecutorRegistrar::Factory::NewExecutor (this=&lt;optimized out&gt;, params=..., graph=..., out_executor=0x3ab72bb8) at tensorflow/core/common_runtime/executor.cc:2785#14 0x00007fa3b49a61b2 in tensorflow::NewExecutor (executor_type=..., params=..., graph=..., out_executor=out_executor@entry=0x3ab72bb8) at tensorflow/core/common_runtime/executor_factory.cc:82#15 0x00007fa3ba128ee4 in tensorflow::DirectSession::CreateExecutors (this=this@entry=0x2edd8480, callable_options=..., out_executors_and_keys=out_executors_and_keys@entry=0x7ffca8d448a0, out_func_info=out_func_info@entry=0x7ffca8d448b0, run_state_args=run_state_args@entry=0x7ffca8d44fb0) at tensorflow/core/common_runtime/direct_session.cc:1296#16 0x00007fa3ba12a730 in tensorflow::DirectSession::GetOrCreateExecutors (this=this@entry=0x2edd8480, inputs=..., outputs=..., target_nodes=..., executors_and_keys=0x7ffca8d44f48, run_state_args=0x7ffca8d44fb0) at tensorflow/core/common_runtime/direct_session.cc:1429 #17 0x00007fa3ba12b747 in tensorflow::DirectSession::Run (this=&lt;optimized out&gt;, run_options=..., inputs=..., output_names=..., target_nodes=..., ---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit--- outputs=0x7ffca8d45340, run_metadata=0x7ffca8d453a0) at tensorflow/core/common_runtime/direct_session.cc:749 #18 0x00007fa3b76729f1 in tensorflow::SessionRef::Run (this=0x38d4a5f0, run_options=..., inputs=..., output_tensor_names=..., target_node_names=..., outputs=0x7ffca8d45340, run_metadata=0x7ffca8d453a0) at tensorflow/python/client/session_ref.cc:427 #19 0x00007fa3b78c2d9d in TF_Run_Helper (session=0x38d4a5f0, handle=handle@entry=0x0, run_options=run_options@entry=0x0, input_pairs=..., output_tensor_names=..., c_outputs=c_outputs@entry=0x7ffca8d45708, target_oper_names=..., run_metadata=0x0, status=0x2b657788) at tensorflow/c/c_api.cc:787 #20 0x00007fa3b78c3a3a in TF_SessionRun (session=session@entry=0x3b57ef60, run_options=run_options@entry=0x0, inputs=&lt;optimized out&gt;, input_values=&lt;optimized out&gt;, ninputs=&lt;optimized out&gt;, outputs=0x36bbfc00, output_values=0x7ffca8d45708, noutputs=1, target_opers=0x0, ntargets=0, run_metadata=0x0, status=0x2b657788) at tensorflow/c/c_api.cc:2638 #21 0x00007fa3b76710df in tensorflow::TF_SessionRun_wrapper_helper (session=0x3b57ef60, handle=handle@entry=0x0, run_options=0x0, inputs=..., input_ndarrays=..., outputs=..., targets=..., run_metadata=0x0, out_status=0x2b657788, py_outputs=0x7ffca8d45a50) at tensorflow/python/client/tf_session_helper.cc:410 #22 0x00007fa3b76711b2 in tensorflow::TF_SessionRun_wrapper (session=&lt;optimized out&gt;, run_options=&lt;optimized out&gt;, inputs=..., input_ndarrays=..., outputs=..., targets=..., run_metadata=0x0, out_status=0x2b657788, py_outputs=0x7ffca8d45a50) at tensorflow/python/client/tf_session_helper.cc:452 #23 0x00007fa3b760b8d0 in _wrap_TF_SessionRun_wrapper (args=&lt;optimized out&gt;) at bazel-out/k8-dbg/bin/tensorflow/python/pywrap_tensorflow_internal.cc:20508 关键代码分析：op_kernel.cc:1302 CreateOpKernel函数 12345// Everything needed for OpKernel construction.OpKernelConstruction context( device_type, device, allocator, &amp;node_def, op_def, flib, inputs, input_memory_types, outputs, output_memory_types, graph_def_version, &amp;s);*kernel = registration-&gt;factory-&gt;Create(&amp;context); OpKernelConstruction context构造了找寻合适的tensorflow的条件 总结：tensorflow这边node的多态有两层 第一层是在tensorflow自己框架的设计上，在session.run的时候，第一次运行创建exectuor的时候进行 第二层多态是mkldnn层面上的，在调用op.Compute的方法的时候，第一次调用会去根据输入的数据类型选择并创建正确的mkldnn的pd INT8化操作理论介绍：https://aidc.gallery.video/detail/videos/all-videos/video/5790616836001/understanding-new-vector-neural-network-instructions-vnni 重点推荐这篇文章，介绍量化很详细https://petewarden.com/2016/05/03/how-to-quantize-neural-networks-with-tensorflow/ 基本思想： 对于输入的张量每一个FP32的输入张量，额外通过一个Min Op得到最小值Min，通过一个Max op得到最大值Max。原始FP32张量，和Min以及Max一起过一个quantize的op得到INT8的张量，再过INT8的计算op(POOL,Conv2D)。再将计算结果，和Min以及Max值一起过一个Dequantize的op反量化得到FP32的输出如果邻近两个节点都是INT8的量化操作，它们之间的反量化和量化操作可以省略 对于原来存储的FP32格式的weight以及bias直接INT8化存储就可以了，存INT8值以及Min以及MaxTF1.10版本transform_graph 工具tensorflow/tools/graph_transforms 目录下面有个readme去介绍怎么做的包括transform_graph里面每个trainform操作做了什么这一步不是必须的对原来的FP32的图做一些预处理的操作每个操作的内容都写在–transforms参数里面，生成一个列表每一个操作在对应的文件里面通过1REGISTER_GRAPH_TRANSFORM(&quot;fold_batch_norms&quot;, FoldBatchNorms); 函数写到transform_registry里面 在主函数里面遍历–transforms的输入列表，从transform_registry里面找到对应操作的函数，执行操作，返回新的graph_def quantize_graph.py 脚本这一步是必须的这个脚本的作用： 是把原来图中的op转换成对应的INT8操作的op，比如conv2D转换成QuantizedConv2DWithBias或者QuantizedConv2DWithBiasAndRelu或者等等等 同时插入量化和反量化计算的节点，额外得到Min，Max 以及quantize和dequantize的op weights的量化操作也是在这一步做的，将FP32的weights值存成INT8的，有个quantize_weight_eightbit函数，将base_name对应的fp32节点换成int8，min,max 3个节点 转换之后多了几个节点：输入计算节点之前： Min：计算输入张量的最小值 Max：计算输入张量的最大值 QuantizeV2： 输入FP32，Min，Max计算量化的INT8输出，输入计算节点输入计算节点之后：计算节点的输出：比如量化卷积计算的输出是 INT32 的(MKLDNN x8s8X32的primitive) RequantizationRange：因为输出是INT32的，而且量化成INT8的scale不在原始图里面存着，需要再量化一次，通过RequantizationRange去计算INT32张量的最大值和最小值 Requantize：具体计算INT32输出量化成INT8 Dequantize：INT8结果反量化成FP32的格式 插入log节点，并得到每一层的参数范围这一步是必须的使用transform_graph 工具 插入log节点 Freeze Re-quantization Range因为量化卷积(mkldnn)输出是INT32的，需要重新量化成INT8，而且量化成INT8的scale不在原始图里面存着，所以通过这一步，做一次inference，记录scala，去需要再量化一次，通过RequantizationRange去计算如果量化节点的输出已经是INT8的格式(比如Maxpool节点)，就不需要Re-quantization这一步 freeze之后就没有RequantizationRange这个节点了 只保留了量化的scala 找到RequantizationRange这个节点，在这个节点后面插入一个Print节点去打印输出数据的范围信息RequantizationRange节点似乎是跟在Conv2D节点后面的，打印Conv2D的INT32输出的最大值和最小值 选取一部分训练数据，进行inference，记录最大和最小值（Print节点会打出来的），保存成min_max.log文件python Inference.py 2&gt; min_max.log因为Print节点的输出是error所以用2去重定向就可以了 利用min_max.log和transform_graph工具去freeze这个requantization_ranges这个节点，把节点值变成常量，加快运算freeze之后就没有RequantizationRange这个节点了freeze之后把这个requantization_ranges节点通过2个const(name/frozen_min和name/frozen_max)替换了tensorflow/tools/graph_transforms 里面的readme有介绍freeze_requantization_ranges这个transform做了什么 Freeze max rangesMax节点一般在量化之前出现，计算输入张量的最大值，用于量化 找到Max这个节点，在这个节点后面插入一个Print节点去打印输出数据的范围信息 选取一部分训练数据，进行inference，记录最大值（Print节点会打出来的），保存成max.log文件 利用max.log文件去freeze Max这个节点((去除Max节点，用大值const的节点去替换name/frozen_max_only)，加速inference的运算freeze之后就没有Max这个节点了 Freeze min rangesMin节点一般在量化之前出现，计算输入张量的最小值，用于量化 找到Min这个节点，在这个节点后面插入一个Print节点去打印输出数据的范围信息 选取一部分训练数据，进行inference，记录最大值（Print节点会打出来的），保存成min.log文件 利用min.log文件去freeze Min这个节点(去除Min节点，用小值const节点替换name/frozen_min_only)，加速inference的运算freeze之后就没有Min这个节点了 通过这几步之后，quantize_graph.py 脚本生成的6个节点，只剩下了三个: QuantizeV2： 输入FP32，Min，Max计算量化的INT8输出，输入计算节点输入计算节点之后：计算节点的输出：比如量化卷积计算的输出是 INT32 的(MKLDNN x8s8X32的primitive) Requantize：具体计算INT32输出量化成INT8 Dequantize：INT8结果反量化成FP32的格式 Requantize 又可以和conv合并成一个节点 利用transform_graph 工具这一步不是必须的,最好运行下 因为前面几步产生了一些不需要的节点，利用transform_graph 工具再移除一些不必要的节点strip_unused_nodes 将INT8的conv和后面的requantize节点合并:fuse_quantized_conv_and_requantize 对比FP32以及INT8模型FP32model.pb是训练得到的FP32模型BS1 精度： 0.94085BS128时的Throughput：2300 FPS conv层调用 op是Conv2D， 经过mkl_layer_pass之后对应了TF里面_mklconv这个op，对应了TF的MklConvOp这个kernel，123456REGISTER_KERNEL_BUILDER(Name(&quot;_MklConv2D&quot;) \ .Device(DEVICE_CPU) \ .TypeConstraint&lt;T&gt;(&quot;T&quot;) \ .Label(mkl_op_registry::kMklOpLabel), \ MklConvOp&lt;CPUDevice, float, float, float, float, \ float, int32, false, false&gt;); 根据这个函数去创建MklConvOp对象并调用Compute方法对应mkldnn里面的jit_avx512_common_convolution_fwd_t这个primitive mkldnn verbose的输出：mkldnn_verbose,exec,convolution,jit:avx512_common,forward_training,fsrc:nChw16c fwei:OIhw16i16o fbia:undef fdst:nChw16c,alg:convolution_direct,mb128_ic32oc64_ih14oh14kh5sh1dh0ph2_iw14ow14kw5sw1dw0pw2,1.41382 INT8一步步量化得到的INT8模型是： min_max_frozen_int8_model.pbBS1 精度： 0.93885BS128时的Throughput： 2380.7939278833765 images/second这个模型有两个卷积运算，第一个卷积运算没有INT8化，第二个卷积运算INT8化了我们这里关注第二个卷积运算 conv调用了 op是QuantizedConv2D， 经过mkl_layer_pass之后对应了TF里面_MklQuantizedConv2D这个op,TF的MklQuantizedConv2DOp这个kernel，MklQuantizedConv2DOp的Compute方法先调用了MklConvOp的Compute的方法虽然也调用了MklConvOp的Compute的方法但是MklQuantizedConv2DOp这个kernel是通过12MklConvOp&lt;Device, quint8, qint8, Tbias, Toutput, Ttemp_output, int32, biasEnabled, false&gt;::Compute(context); 去创建 MklConvOp对象并调用Compute方法，和FP32的模板参数类型不一样对应了Tinput, Tfilter以及Toutput因为模板参数不一样，调用MklConvOp的compute方法的时候对应找到的对应的mkldnn的pd也不一样，所以对应的mkldnn的primitive也不一样通过看mkldnn的cpu_engine.cpp的cpu_impl_list怀疑对应了mkldnn的jit_avx512_core_x8s8s32x_convolution_fwd_t这个primitive如何证实： 通过gdb去debug，证实了猜想 export MKLDNN_JIT_DUMP=1 去看dump出来的bin，里面果然有mkldnn_dump__jit_avx512_core_x8s8s32x_conv_fwd_ker_t.23.binjit_avx512_core_x8s8s32x_convolution_fwd_t这个op里面在满足输入条件时会去调用VNNI的指令集VPDPBUSD问题在运行测试时，dump jit-bin去查看是否调用了指令1xed64 -ir mkldnn_dump__jit_avx512_core_x8s8s32x_conv_fwd_ker_t.23.bin | grep vpdpbusd 我们这里没有看到调用VNNI的指令集重要 加-64选项1xed64 -ir mkldnn_dump__jit_avx512_core_x8s8s32x_conv_fwd_ker_t.23.bin -64 | grep vpdpbusd 这样就可以看到VPDPBUSD的指令被dump出来了我们单步调试，看到mkldnn里面jit_avx512_core_x8s8s32x_convolution_fwd_t里面jcp_ver 是 ver_vnni同时compute_ker函数(jit_avx512_core_x8s8s32x_conv_kernel.cpp)里面的cpmpute部分也的确调用到了vpdpbusd mkldnn verbose的输出：mkldnn_verbose,exec,convolution,jit_int8:avx512_core,forward_training,fsrc:nhwc fwei:OIhw4i16o4i fbia:undef fdst:nhwc,alg:convolution_direct,mb128_ic32oc64_ih14oh14kh5sh1dh0ph2_iw14ow14kw5sw1dw0pw2,0.535156 看到精度只掉了0.002但是Throughput也没有显著提高但是只看这一层的性能从1.4ms提高到了0.53ms AppendixIntel优化版本的介绍https://www.youtube.com/watch?v=VI5vjB6-zNE]]></content>
      <tags>
        <tag>技术 tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建电商搜索引擎]]></title>
    <url>%2F2019%2F02%2F08%2F%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[介绍做的一个电商的搜索引擎使用elk作为后台架构，elastic提供搜索的接口，logstash作为mysql和elastic之间数据同步的桥梁 其实这个只是常用引擎的第一步，一般的搜索引擎为了提高用户的点击率，在得到所有相关的物品之后，会进一步输入到一个模型当中，包含了用户的使用行为等参数，最后根据用户可能的购买率进行排序。参考wide&amp;deep模型：https://zhuanlan.zhihu.com/p/29640272 logstash配置logstash的基本安装和配置可以参考logstash的文章如何做数据同步参考这边文章https://zhuanlan.zhihu.com/p/40177683 logstash 每次只同步更新一条数据的问题https://stackoverflow.com/questions/41418060/logstash-is-indexing-only-one-row-of-select-query-from-mysql-to-elastic-search 配置的参数的官方文档：https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html 完整的logstash的配置初始化时候的配置,logstash-es-mysql.conf1234567891011121314151617181920212223242526272829303132333435363738input&#123; stdin &#123; &#125; jdbc &#123; jdbc_driver_library =&gt; &quot;/home/elastic/mysql-connector/mysql-connector-java.jar&quot; jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot; jdbc_connection_string =&gt; &quot;jdbc:mysql://116.62.126.101:3306/manzuoTestENV?characterEncoding=utf8&amp;useSSL=false&quot; jdbc_user =&gt; &quot;manzuo&quot; jdbc_password =&gt; &quot;password&quot; jdbc_paging_enabled =&gt; &quot;true&quot; jdbc_page_size =&gt; &quot;50000&quot; schedule =&gt; &quot;* * * * * &quot;#配置为每一分钟都更新一次 type =&gt; &quot;jdbc&quot; statement =&gt; &quot;select * from `index_alllist`&quot; #statement =&gt; &quot;select itemId,title,title2,parameter,author from `index_alllist`&quot; tracking_column =&gt; &quot;itemId&quot; tracking_column_type =&gt; &quot;numeric&quot; clean_run =&gt; true &#125;&#125;filter&#123; json&#123; source =&gt; &quot;message&quot; remove_field =&gt; [&quot;message&quot;] &#125;&#125;output&#123; elasticsearch &#123; hosts =&gt; [&quot;http://47.75.156.162:9200&quot;] index =&gt; &quot;manzuo_list&quot; document_type =&gt;&quot;items&quot; document_id =&gt; &quot;%&#123;itemid&#125;&quot; #这里全用小写的itemid，很重要，和mysql的大小写不同，应为es字段全是小写的啦 &#125; stdout &#123; codec =&gt; json_lines &#125;&#125; 启动logstash:./bin/logstash -f logstash-es-mysql.conf 启动之前首先创建索引，因为要使用中文的分词器先安装中文分词器的插件https://www.elastic.co/guide/en/elasticsearch/plugins/current/analysis-smartcn.html删除已有的索引(存在的话):DELETE /manzuo_list设置新索引的analyzer:1234567891011121314PUT /manzuo_list&#123; &quot;settings&quot;: &#123; &quot;index&quot;: &#123; &quot;analysis&quot;: &#123; &quot;analyzer&quot;: &#123; &quot;default&quot;: &#123; &quot;type&quot;: &quot;smartcn&quot; &#125; &#125; &#125; &#125; &#125;&#125; 启动logstash去同步数据:./bin/logstash -f logstash-es-mysql.conf搜索:12345678GET /manzuo_list/items/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;核桃&quot; &#125; &#125;&#125; 参考中文教程https://www.elastic.co/cn/blog/how-to-search-ch-jp-kr-part-1 存在的问题这样的配置只能做到mysql中的新数据向es中去追加一旦mysql删除了老数据，es并不会同步去删除]]></content>
      <tags>
        <tag>技术 深度学习 推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Caffe中的生产者模式]]></title>
    <url>%2F2019%2F01%2F31%2F%E6%B3%A8%E5%86%8C%E5%B1%82%2F</url>
    <content type="text"><![CDATA[在这个代码layer_factory.hpp的开头作者注释了怎么注册layer 比如我们PB的模型文件中有一层的type是DummyData 通过搜索grep -rni “REGISTER_LAYER_CLASS(Du” ./有些层搜不到比如Convolution那就可以搜索grep -rni “INSTANTIATE_CLASS(Convolution” ./ ./src/caffe/layers/dummy_data_layer.cpp:149:REGISTER_LAYER_CLASS(DummyData);可以搜索到在哪里注册层 从而在后面代码里面调用对应层的forward函数的时候就找到对应的实现了 注意 有一个很trick的地方比如我在PB文件里定义了一个层的type为InnerProduct按照上面的说法我们搜索：[root@localhost caffe-1.1.3]# grep -rni “REGISTER_LAYER_CLASS(InnerProduct” ././src/caffe/layers/inner_product_layer.cpp:189:// REGISTER_LAYER_CLASS(InnerProduct);[root@localhost caffe-1.1.3]# grep -rni “INSTANTIATE_CLASS(InnerProduct” ././src/caffe/layers/inner_product_layer.cpp:187:INSTANTIATE_CLASS(InnerProductLayer); 认为这个层定义在./src/caffe/layers/inner_product_layer.cpp这个文件里面，看对应的forward_cpu函数但其实不是因为我们默认或者指定使用了mkldnn作为engine在layer_factory.cpp的下面有一个函数GetInnerProductLayer里面会根据engine去找对应的层return shared_ptr]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MKLDNN与AVX512]]></title>
    <url>%2F2019%2F01%2F19%2FMKLDNN%E4%B8%8EAVX512%2F</url>
    <content type="text"><![CDATA[解释以caffe2为例子进行解释：caffe2的输入的数据格式为NCHWbatchsize，channel，height和width 对于caffe2来说，在每一层卷积的时候就会直接把这个NCHW的数据塞进mkldnn对应的primitive里面进行计算， mkldnn的primitive并行化计算包含两个层面，thread的层面和单个thread内部 NH方向的并行化对于NCHW的数据格式来说, N和H会对应了threads层面的并行化计算，也就是batchsize张图片或者一张图片很大也会被分配到多个不同的threads(每个thread可能绑定了CPU计算的core上)这解释了caffe2，detecture的时候batchsize从1增加到8，性能增加不明显的问题因为detecture的图片像素点很大10241024,正常resnet50的输入都是224224，所以detecture的图片在H方向上已经在多threads上并行计算了，增大batchsize无法提高性能 为什么说c16（channel数是16的倍数）很重要channel数是16的倍数，我们经常看到卷积核的输出的channel经常是32,64等16的倍数 AVX512AVX512指令集的意思就是一次处理512bit的数据，一个FP32的数据占了32bit，所以一次性可以处理16个FP32的数据 对应了上面的卷积计算来说，假设有个NCHW的数据，一个batchsize有32个通道，那我们定义的卷积核也有32的通道在第一个像素点上的卷积，可以先读取16个channel(通道)的第一个像素点的数据进来，对应了前16个卷积核的第一个像素点数据，进行一次卷积运算 同时，一个物理核(这里不确定是物理核还是逻辑核)会有 16？？ 个AVX512可以读取的寄存器，每个寄存器可以存512bit，所以一次性可以读每个通道的前16个像素点进来，一共(16(通道数)32(一个浮点数)16(一组16个像素点组成的浮点数))一起存在16个AVX512的数据的寄存器里面]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql备份]]></title>
    <url>%2F2019%2F01%2F18%2Fmysql%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[冷备份生成sql文件mysqldump -u用户名 -p 数据库名 &gt; 数据库名.sql范例：mysqldump -umanzuo -p -h116.62.126.101 manzuoTestENV &gt; manzuoTestENV.sql 导入sql文件mysql -u用户名 -p 数据库名 &lt; 数据库名.sql范例：mysql -uroot -p manzuoTestENV &lt; manzuoTestENV.sql]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tcpdump]]></title>
    <url>%2F2019%2F01%2F08%2Ftcpdump%2F</url>
    <content type="text"><![CDATA[介绍tcpdump可以用来抓包，在微服务架构下可以用来检查服务发现和rpc调用的包是否发送成功或者接收成功 用法入门教程]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决github冲突]]></title>
    <url>%2F2018%2F12%2F31%2F%E8%A7%A3%E5%86%B3github%E5%86%B2%E7%AA%81%2F</url>
    <content type="text"><![CDATA[工具sublime Merge 流程 stashgit stashgit pullgit stash pop commitgit add .git commit -mgit pullgit commit append]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[定位进程占用内存问题]]></title>
    <url>%2F2018%2F11%2F01%2F%E5%AE%9A%E4%BD%8D%E8%BF%9B%E7%A8%8B%E5%8D%A0%E7%94%A8%E5%86%85%E5%AD%98%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[定位一个服务内存占用率过高的问题： 起因机器报警，内存不足，用free命令去看，看到内存不足用top 然后M按内存使用率排序，找到服务的进程号top -p 进程号看到这个进程占用了1.5G的虚拟内存 分析12345678910111213141516cat /proc/&lt;pidnum&gt;/status......Groups: 0 1 2 3 4 6 10VmPeak: 1614960 kBVmSize: 1549424 kBVmLck: 12 kBVmPin: 0 kBVmHWM: 65352 kBVmRSS: 33520 kBVmData: 1046480 kBVmStk: 688 kBVmExe: 640 kBVmLib: 55276 kBVmPTE: 540 kBVmSwap: 0 kBThreads: 30 VmStk 栈区大概688KB还ok看到VmData占了将近1G大小，google了一下VmData介绍说是堆区 把代码遍历了一遍，找到所有new的地方，看看有没有delete，排除了内存泄漏的情况然后在代码中print了一把所有的new的类 cout&lt;&lt;sizeof(classname)&lt;&lt;endl;看到这些类加起来也就100KB，一共100个微线程加起来也就10MB的样子 进一步分析这时候就纠结了问了几个老同事，提供了些新的思路： 内存泄漏，已经排除过，而且程序刚启动就占用了很大的内存大小 把微线程限制到1个，在程序运行过程中，打印内存使用情况 解决这时候有个以前搞安全的同事帮忙一起看了：cat /proc/29912/smaps看看https://blog.csdn.net/tangtang_yue/article/details/78298067smaps文件中，每一条记录表示进程虚拟内存空间中一块连续的区域其中权限标识，rw-s表示可读可写的共享内存，rw-p表示可读可写的私有还可以在里面搜索heap和stack，应该有多块连续区域，可以累加得到堆栈的大小进一步在这个文件里搜索：看到最大的一块区域：5249 7fb495e28000-7fb49c228000 rw-s 00000000 00:04 1277991 /SYSV10910931 (deleted)5250 Size: 102400 kB /SYSV10910931 表示是一个共享内存 在/proc目录下,grep -rni “SYSV10910931” ./*/smaps 看到所有使用这块共享内存的进程 然后一个个单独 top -p 进程 判断一下哪个进程是最后可能创建这个共享内存的]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次刷数据的经历]]></title>
    <url>%2F2018%2F10%2F29%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E5%88%B7%E6%95%B0%E6%8D%AE%E7%9A%84%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[背景今天刷线上数据，需求很简单，DB中有一个字段，需要向缓存中添加。具体的做法就是，将DB中updatetime字段加1更新一下，从而可以触发同步组件，从DB拉取数据向CKV同步。 过程看似简单的一个操作，在测试环境实验了多遍之后，第一次在线上环境操作的时候还是踩坑了看到的现象: 在刷完数据之后，用脚本对比数据发现最后三条数据没有从db向CKV更新。解决方法: 还好数据量不大，就手动把这三条数据刷了一把。但是还是要找原因: 原因是在我刷数据的过程中，有人向数据库新添加了三条数据(亏我还选在了晚上来刷)。按照同步组件的原理，这新添加的三条数据应该已经往CKV中同步了。但是，因为我是先获取数据库中数据量，然后通过主键去遍历更新数据库中的每一条数据。而新添加的这三条数据，根据主键排序在数据库的中间位置，极小概率会出现在数据库的末尾，所以导致原来在数据库的末尾的三条数据超出了更新的范围(更新的范围在初始化时count一把数据库的值)。根本的解决办法: 从第一次的刷新的结束点开始往末尾再刷一下数据 全量再刷一遍数据 刷数据的注意点 运行脚本的时候，bash test.sh | tee run.log 2 &amp; 一定要要全量保存日志，方便出错定位 一定要写个脚本在刷完数据之后，全量比较一下DB和缓存中的数据是否一致，确保全量更新成功]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务架构]]></title>
    <url>%2F2018%2F10%2F24%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[介绍微服务架构应该是近年来，软件应用领域非常热门的概念微服务的概念源于2014年3月Martin Fowler所写的一篇文章“Microservices” 原有架构的缺点 只改变一部分代码，需要重新构建并部署整个项目 负载均衡与扩容，需要将整个项目一起横向扩容 微服务架构的优点 改变部分代码，只需要将单个微服务构建，可以方便的做到敏捷上线 负载均衡与扩容，单个微服务负载过高，只需要将单个微服务扩容 每个开发者只需要负责某几个微服务模块，可以显著提高开发效率 只要规定好微服务模块之间的通信协议，比如使用protobuf，就可以用不同语言编译协议，这也就允许不同模块之间采用不同语言开发 关键技术点 微服务之间通信，协议的定义非常重要，可以使用protobuf 单个微服务的并发能力的提高，微服务之间需要通过tcp和udp协议进行通信，这就意味在发送数据和等待接受数据之间，这个进程是hang的状态。所以微服务架构需要使用多进程，多线程，多协程(进程和线程的调度都是内核态，而协程的调度可以由框架实现，在用户态，这大大减小了协程之间切换的效率)。腾讯内部的spp框架和开源的msec框架就采用了类似的概念。]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小程序开发]]></title>
    <url>%2F2018%2F10%2F13%2F%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[框架前端：小程序后台： django数据库: mysql缓存: redis 数据库搭建配置mysql支持中文https://blog.csdn.net/u014657752/article/details/48206885https://blog.csdn.net/crave_shy/article/details/23345869再修改一个databases的字符集:https://stackoverflow.com/questions/22572558/how-to-set-character-set-database-and-collation-database-to-utf8-in-my-ini重启mysql，/etc/init.d/mysql restart 创建新用户创建数据库，并授权给新用户开启数据库远程登录https://blog.csdn.net/xiexievv/article/details/50513996授权然后注释：#bind-address = 127.0.0.1vim /etc/mysql/mysql.conf.d/mysqld.cnf 重启/etc/init.d/mysql restart django初始化时python manage.py migrate之后某个APP改动之后$ python manage.py makemigrations TestModel # 让 Django 知道我们在我们的模型有一些变更$ python manage.py migrate TestModel # 创建表结构]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rapidJson]]></title>
    <url>%2F2018%2F09%2F22%2FrapidJson%2F</url>
    <content type="text"><![CDATA[简介RapidJSON 是一个高效的 C++ JSON 解析／生成器http://rapidjson.org/zh-cn/md_doc_tutorial_8zh-cn.html 序列化12345678rapidjson::StringBuffer buffer1;rapidjson::Writer&lt;rapidjson::StringBuffer&gt; writer1(buffer1); writer1.StartObject();writer1.Key(&quot;count&quot;);writer1.Int(2); writer1.EndObject();printf(&quot;%s\n&quot;, buffer1.GetString()); 反序列化12345678910111213141516171819#include &quot;rapidjson/document.h&quot;using namespace rapidjson;string a=&quot;&#123; &quot;hello&quot;: &quot;world&quot;, &quot;t&quot;: true , &quot;f&quot;: false, &quot;n&quot;: null, &quot;i&quot;: 123, &quot;pi&quot;: 3.1416, &quot;a&quot;: [1, 2, 3, 4]&#125;&quot;Document document;document.Parse(a.c_str());if(!document.HasMember(&quot;hello&quot;))&#123; return -1;&#125;printf(&quot;hello = %s\n&quot;, document[&quot;hello&quot;].GetString());]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[protobuf]]></title>
    <url>%2F2018%2F09%2F01%2Fprotobuf%2F</url>
    <content type="text"><![CDATA[安装下载进入安装教程进入release版本目录下载C++版本release安装过程参考 12345./autogen.sh./configuremakemake checkmake install 教程参考文档]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[svn]]></title>
    <url>%2F2018%2F08%2F30%2Fsvn%2F</url>
    <content type="text"><![CDATA[一般先在服务器上建立个仓库12mkdir /root/CgiNgsvnadmin create /root/CgiNg 进入/root/CgiNg修改conf相关配置文件一般相关的有三个配置文件authz：负责账号权限的管理，控制账号是否有读写权限passwd：负责账号和密码的用户名单管理svnserve.conf：svn服务器配置文件具体修改哪些内容，可以参考这个链接 启动服务1svnserve -d -r /root/CgiNg 下载仓库windows上用tortoise svn右键checkout，输入地址svn://149.28.149.94:3690，和下载到本地的地址Linux上，12mkdir repo &amp;&amp; cd reposvn co svn://149.28.149.94:3690 提交文件 所有文件12svn add ./*svn commit -m &quot;message&quot; 注意在服务器端仓库中文件是用另外格式存储的，所以你在服务器端find是找不到代码文件的 单独文件 12svn add 文件名svn commit -m &quot;message&quot; 目录以及目录下文件 12svn add 目录svn commit -m &quot;message&quot; 删除文件(注意删除本地和远程的)两种方法： 方法1直接删除远程文件svn delete svn://路径(目录或文件的全路径) -m “删除备注信息文本” 推荐如下操作： 先删除本地文件然后commit上去svn delete 文件名svn ci -m “删除备注信息文本” &lt;- ci是commit的简写 不小心add了多余的文件1234svn add ./*之后发现有的文件不应该提交svn revert 文件svn revert --depth infinity 目录 Linux端命令详细手册]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言处理参数不定函数]]></title>
    <url>%2F2018%2F08%2F09%2FC%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%8F%82%E6%95%B0%E4%B8%8D%E5%AE%9A%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[使用va函数示例：求N个数的和 int sum(int count, …){ int sum = 0; int i; va_list ap; va_start(ap, count); for (i = 0; i &lt; count; ++i) { sum += va_arg(ap, int); } va_end(ap); return sum;} 下面是 里面重要的几个宏定义如下：typedef char* va_list;void va_start ( va_list ap, prev_param );type va_arg ( va_list ap, type );void va_end ( va_list ap );va_list 是一个字符指针，可以理解为指向当前参数的一个指针，取参必须通过这个指针进行。 在调用参数表之前，定义一个 va_list 类型的变量，(假设va_list 类型变量被定义为ap)； 然后应该对ap 进行初始化，让它指向可变参数表里面的第一个参数，这是通过 va_start 来实现的，第一个参数是 ap 本身，第二个参数是在变参表前面紧挨着的一个变量,即“…”之前的那个参数； 然后是获取参数，调用va_arg，它的第一个参数是ap，第二个参数是要获取的参数的指定类型，然后返回这个指定类型的值，并且把 ap 的位置指向变参表的下一个变量位置； 获取所有的参数之后，我们有必要将这个 ap 指针关掉，以免发生危险，方法是调用 va_end，他是输入的参数 ap 置为 NULL，应该养成获取完参数表之后关闭指针的习惯。说白了，就是让我们的程序具有健壮性。通常va_start和va_end是成对出现。http://www.cnblogs.com/hanyonglu/archive/2011/05/07/2039916.htmlhttps://blog.csdn.net/xyang81/article/details/41223527]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logstash]]></title>
    <url>%2F2018%2F08%2F05%2Flogstash%2F</url>
    <content type="text"><![CDATA[安装配置在配置文件logstash.conf中修改input指定log文件的位置filter对日志进行处理和格式化output指定输出到redis或者elastic 配置文件中一定需要显示指定一个input和output启动logstashbin/logstash -f logstash.conf 报错Logstash could not be started because there is already another instance using the configured data directory解决./bin/logstash -f test.conf –path.data=/home/elastic filter 介绍date filter的作用，原来输出字段中的@timestamp是读取系统时间，通过配置filter date可以从日志的message中简析出时间并格式化时间到@timestamp字段当中先用grok filter从mesage里面解析并转换生成新的字段 看看grok的用法，基本表达式%{SYNTAX:SEMANTIC}SYNTAX是指定的一个正则表达式，上面这句话的意思就是从message字段中，将匹配到SYNTAX的内容放到新生成的SEMANTIC字段当中 所以学好logstash一定要熟悉grok的正则匹配 配置模板 监听ssh用户登录input{ file{ path =&gt; “/var/log/secure” }}output{ stdout{}} 输出到elasticsearchinput{ file{ path =&gt; “/var/log/secure” }}output{ elasticsearch{ hosts =&gt; “http://10.239.182.93:9200“ index =&gt; “logstash-test” document_type =&gt; “test” }} 简析系统日志elasticsearch配置input{ file{ path =&gt; “/var/log/secure” type =&gt; “system-ssh-log” } }filter{ grok{ match=&gt;{“message”=&gt;”%{SYSLOGBASE}”} }}output{ elasticsearch{ hosts =&gt; “http://10.239.182.93:9200“ index =&gt; “logstash-%{type}-%{+YYYY.MM.dd}” document_type =&gt; “%{type}” } } SYSLOGBASE是很重要的一个系统日志匹配的正则表达式]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elastic]]></title>
    <url>%2F2018%2F07%2F31%2Felastic%2F</url>
    <content type="text"><![CDATA[安装创建非root用户adduser elasticpasswd elastic 使用新用户下载curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.10.tar.gz 启动：./bin/elasticsearch 打开另一个终端进行测试： curl ‘http://localhost:9200/?pretty‘你能看到以下返回信息：{ “status”: 200, “name”: “Shrunken Bones”, “version”: { “number”: “1.4.0”, “lucene_version”: “4.10” }, “tagline”: “You Know, for Search”} 报错：[root@localhost ~]# curl -XGET ‘http://localhost:9200/?pretty‘ Redirection Redirect 关闭防火墙和代理unset $http_proxyunset $https_proxy 修改绑定ip尝试修改配置文件 elasticsearch.yml中network.host(注意配置文件格式不是以#开头的要空一格， ：后要空一格) 为network.host: 0.0.0.0 安装kibana sense下载解压kibana5.6.10Sense was renamed to Console and is built into Kibana 5.https://github.com/elastic/sense/blob/master/README.md 直接启动./bin/kibana会连接上默认配置的elastic restful API命令格式命令格式：https://www.elastic.co/guide/cn/elasticsearch/guide/current/_talking_to_elasticsearch.html -i 选项curl -i -XGET ‘localhost:9200/‘-i指定请求返还响应的头 简单搜索GET /megacorp/employee/_search?q=last_name:Smith直接在url后边添加参数，但是这种方式不支持单词的部分匹配GET /megacorp/employee/_search?q=last_name:Sm是搜索不到Smith的 指定请求体count返回符合条件的文档数量curl -XGET localhost:9200/_count?pretty -d ‘{ “query”: { “match_all”: {} }}’ count返回符合条件的文档数量curl -XGET ‘localhost:9200/megacorp/employee/_search’ -d ‘{ “query” : { “match” : { “last_name” : “Smith” } }}’ 单查询与组合多查询 单查询‘{ “query” : { &quot;match&quot; : { &quot;last_name&quot; : &quot;Smith&quot; } }}’query和filter的区别filter用于精确字段的精确查找和过滤，没有scoce，只返回精确匹配查找到的docquery用于 filtered用于组合query和filter‘{“query”:{ “filtered”:{ &quot;query&quot; : { &quot;match&quot; : { &quot;last_name&quot; : &quot;Smith&quot; } }, &quot;filter&quot;:{ term:{ &quot;age&quot;:12 } } } }}’组合多查询:使用boolbool下面可以包含4个子句: must,must_not,should,filter‘{ “query” : { &quot;bool&quot;: { &quot;must&quot;: { &quot;match&quot; : { &quot;last_name&quot; : &quot;smith&quot; } }, &quot;filter&quot;: { &quot;range&quot; : { &quot;age&quot; : { &quot;gt&quot; : 30 } } } } }}’constant_score可以用来代替bool查询语句https://www.elastic.co/guide/cn/elasticsearch/guide/current/combining-queries-together.html 创建索引或者添加文档添加文档时，若索引不存在会自动创建索引，可以指定自动创建的索引所使用的模板，这样对于自动创建的索引进行控制curl -XPUT ‘localhost:9200/intel/employee/3’ -d ‘{ “first_name” : “Douglas”, “last_name” : “Fir”, “age” : 35, “about”: “I like to build cabinets”, “interests”: [ “forestry” ]}’创建索引时有三个配置项，shards,replication,以及analysisanalysis的使用：https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html定制化分析器：可以配置type为某个内置的analyzer然后配置这个analyzer的选项，也可以直接指定type为custom，然后配置tokenizer，filter以及char_filterhttps://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-custom-analyzer.html 关闭和打开索引http://cwiki.apachecn.org/pages/viewpage.action?pageId=4882797curl -XPOST ‘localhost:9200/my_index/_close?pretty’curl -XPOST ‘localhost:9200/my_index/_open?pretty’ 查询语句的区别:https://www.elastic.co/guide/cn/elasticsearch/guide/current/_most_important_queries.htmlmatch: 会用对应查询的字段的分析器去分词并匹配计算score，与term的区别match_all: 匹配所有对应文档 { “query”: { “match_all”: {} } }match_phrase: 精确完全匹配上整串短语,保留那些包含 全部 搜索词项，且 位置 与搜索词项相同的文档https://www.elastic.co/guide/cn/elasticsearch/guide/current/_phrase_search.htmlterm:查询被用于精确值 匹配,注意term区分大小写，所以一个字段field如果是text类型，在倒排索引中会被状态成小写，直接term查找会找不到，需要term查找这个字段的field.keywordterms:terms 查询和 term 查询一样，但它允许你指定多值进行匹配。如果这个字段包含了指定值中的任何一个值，那么这个文档满足条件prefix: 前缀查询，不会对输入的查询信息进行analyzewildcard:使用标准的 shell 通配符查询regexp:使用正则表达式通配符查询match_phrase_prefix:range：multi_match: 在多个字段上搜索同一个文本https://www.elastic.co/guide/cn/elasticsearch/guide/current/multi-match-query.html有三种评分方式：best_field,most_field,cross_fieldhttps://www.elastic.co/guide/cn/elasticsearch/guide/current/_cross_fields_queries.html scroll：游标查询，可以用于批量查询数据https://www.elastic.co/guide/cn/elasticsearch/guide/current/scroll.htmlfuzzy:模糊匹配https://www.elastic.co/guide/cn/elasticsearch/guide/current/fuzzy-query.htmlrange和term常用于filter 查看字段映射信息GET /_mapping?prettyGET /index/_mapping?prettyGET /index/_mapping/type?pretty mapping中text和keyword的区别“about”: { “type”: “text”, “fields”: { “keyword”: { “type”: “keyword”, “ignore_above”: 256 } }}about字段类型是text，默认会被analyze和倒排索引about.keyword字段则不会被analyze “fielddata”: truefielddata主要用于聚类，只有text字段要配置fielddata用于倒排索引，text字段的fielddata默认是关闭的，需要对字段聚类时要配置它打开:https://blog.csdn.net/baristas/article/details/78974090其它类型的字段用doc_values用于倒排索引 doc_values与fielddata的区别doc_values用于非text字段聚合，默认是打开的，作为倒排索引的转置存放在硬盘上，可以在创建索引时关闭fielddata用于text字段，默认是关闭的，可以创建索引时打开，第一次使用字段的聚类时生成，并存放在内存中 查看分析器curl -XGET http://10.239.182.93:9200/_analyze?pretty -d ‘{“analyzer”:”standard”,”text”:”Text to analyze”}’用于查看standard分析器是如何分析Text to analyze这句话的 获得具体搜索时分析的信息GET /my_index/my_type/_validate/query?explain{ “query”: { “match”: { “name”: “brown fo” } }}GET /my_index/doc/_search?explain{ “query”: { “term”: { “text”: “fox” } }} search的时候评分的规则https://www.elastic.co/guide/cn/elasticsearch/guide/current/scoring-theory.html 排序：sort 聚类理解两个概念，桶和度量分桶之后，根据指定的度量计算每个桶的度量值 地理位置地理坐标点不能被动态映射 （dynamic mapping）自动检测，而是需要显式声明对应字段类型为 geo-point123456789101112131415PUT /attractions&#123; &quot;mappings&quot;: &#123; &quot;restaurant&quot;: &#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125;, &quot;location&quot;: &#123; &quot;type&quot;: &quot;geo_point&quot; &#125; &#125; &#125; &#125;&#125; 集群状态监测GET _cluster/healthGET _nodes/statsGET _cluster/statshttps://www.elastic.co/guide/cn/elasticsearch/guide/current/_cluster_stats.htmlGET /_cat 列出所有可用的cat APIGET /_cat/healthGET /_cat/health?v?v 参数： 显示表头 #集群修改vim config/elasticsearch.ymlcluster.name: leslie-elastic #多个instance同一个cluster namenode.name: node-1 #独立的node namenetwork.host: 10.239.182.240 #外网访问的IPdiscovery.zen.ping.unicast.hosts: [“10.239.182.240”, “10.239.182.51”]默认是单播模式，只会在一台机器上去搜索同一个名字的elastic，希望搜索其它host需要在discovery.zen.ping.unicast.hosts添加上搜索的IP vim config/kibana.ymlserver.host: 10.239.182.240elasticsearch.url: “http://10.239.182.240:9200“]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反汇编]]></title>
    <url>%2F2018%2F05%2F21%2F%E5%8F%8D%E6%B1%87%E7%BC%96%2F</url>
    <content type="text"><![CDATA[准备编译后的目标文件中包含哪些内容：https://www.jianshu.com/p/4c938ccda653 objdump用于将机器码生成汇编代码gcc命令objdump用法objdump -x obj 以某种分类信息的形式把目标文件的数据组织（被分为几大块）输出 &lt;可查到该文件的所有动态库&gt;objdump -t obj 输出目标文件的符号表()objdump -h obj 输出目标文件的所有段概括()objdump -j .text/.data -S obj 输出指定段的信息，大概就是反汇编源代码把objdump -S obj C语言与汇编语言同时显示 查看是否调用某个指令集：objdump -d combin | grep avx objdump -d 反汇编程序，从机器码生成汇编代码 nm显示可执行文件的符号表最好用gcc -g 编译之后在用nm 编译结果文件，查看文件的符号表，gcc -g会加入更多的符号表信息gdb就是通过读取符号表来查看程序的调用栈的信息 strings打印文件中可打印的字符strings 源代码 就是打印出源代码了strings 编译结果文件 就是把二进制文件中可以打印的部分文本给打印出来了]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HDFS]]></title>
    <url>%2F2018%2F05%2F21%2FHDFS%2F</url>
    <content type="text"><![CDATA[介绍使用bigdl的时候需要将训练数据集放在分布式文件系统中 准备环境保证各个节点之间免ssh登陆单节点搭建hadoophttps://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html多节点搭建hadoop namenode系统环境变量：export JAVA_HOME=/root/jdk1.8.0_161export CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:.export HADOOP_PREFIX=/home/hadoop/hadoop-2.6.5export HADOOP_HOME=$HADOOP_PREFIX/binexport HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoopPATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH:$HOME/bin:/home/jiahaofa/spark/spark-2.2.1-bin-hadoop2.7/bin:$HADOOP_HOME:$HADOOP_PREFIX/sbinexport PATH 配置hadoopetc/hadoop/hadoop-env.sh 写入 export JAVA_HOME=/usr/java/latest 配置etc/hadoop/slaves文件r02s01r02s02 配置etc/hadoop/core-site.xml fs.defaultFS hdfs://r02s01:9000 io.file.buffer.size 131072 hadoop.tmp.dir file:///home/hadoop/hadoop-2.6.5/tmp 配置 etc/hadoop/hdfs-site.xml dfs.namenode.name.dir file:/home/hadoop/hadoop-2.6.5/tmp/dfs/name dfs.datanode.data.dir file:/home/hadoop/hadoop-2.6.5/tmp/dfs/data datanode系统环境变量：系统环境变量：export JAVA_HOME=/root/jdk1.8.0_161export CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:.export HADOOP_PREFIX=/home/hadoop/hadoop-2.6.5export HADOOP_HOME=$HADOOP_PREFIX/binexport HADOOP_CONF_DIR=$HADOOP_PREFIX/etc/hadoopPATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH:$HOME/bin:/home/jiahaofa/spark/spark-2.2.1-bin-hadoop2.7/bin:$HADOOP_HOME:$HADOOP_PREFIX:sbinexport PATH 配置hadoopetc/hadoop/hadoop-env.sh 写入 export JAVA_HOME=/usr/java/latest 配置etc/hadoop/core-site.xml 一定要配置，很重要 fs.defaultFS hdfs://r02s01:9000 不配置 etc/hadoop/hdfs-site.xml 启动：$HADOOP_PREFIX/bin/hdfs namenode -format$HADOOP_PREFIX/sbin/start-dfs.sh 启动之后用jps查看namenode和datanode的进程 关闭：$HADOOP_PREFIX/sbin/stop-dfs.sh 如果出现namenode或者datanode无法启动，查看机器上的log有明确信息 hdfs命令测试namenode:hdfs dfs -put ./testdata/lesliename.txt /其它节点hdfs dfs -ls /hdfs dfs -cat /lesliename.txt datanode:启动spark-shell：val textFile = spark.read.textFile(“hdfs://r02s01:9000/lesliename.txt”)textFile.first() 输出文件内容说明HDFS部署成功]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高并发系统开发]]></title>
    <url>%2F2018%2F04%2F12%2F%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[分布式系统https://www.zhihu.com/question/23645117 两个系统之前如何实现事务的同步eBay架构看一个例子：中行账户A向建行账户B转账1000元，应该如何实现，首先，中行本地有两张表，第一张表是账户表，第二张表是消息表。 开始转账后，中行账户A扣款1000元，通过本地事务将事务消息插入至消息表。 本地通常通过消息MQ(消息队列)的方式发送异步消息通知建行账户B，增加1000元。对方订阅并监听消息后自动触发转账的操作，为了保证幂等性，防止触发重复的转账操作，需要在执行转账操作方新增一个trans_recv_log表用来做幂等，在第二阶段收到消息后，通过判断trans_recv_log表中的字段来检测相关记录是否被执行，如果未被执行则会对B账户余额执行加1000元的操作，并会将该记录增加至trans_recv_log,事件结束后通过回调更新trans_message的状态值。 在上述例子中，转账方由于网络原因出现多次发送请求的情况怎么处理在中行账户中，每次请求都有个ID，hash值，在收款方的trans_recv_log表首先查询是否有这行请求的记录，没有的话就插入记录，并将这行的状态位标志为未处理，然后开始处理业务，在业务处理完成后，将状态位标志为已经处理。这样当重复请求过来，查看到状态位为已经处理，就不再处理业务。 在上述例子中，两次重复请求之间时间间隔很短怎么办，也就是第二次请求发过来的时候，第一次请求还在处理业务，还没来得及回调更新trans_recv_log表的标志位给trans_recv_log表的每一行加锁，这样第二请求来的时候就会等待，等到第一个请求完成，第二请求查询到标志位已经完成就不会触发业务了 在上述例子中，可能存在一个情况，就是第一个请求刚处理完业务，给行解锁准备更新标志位的时候，第二请求来了，因为还没来的及更新标志位，所以第二个请求会触发业务，业务被击穿了在业务请求之前，一定要写上锁，再查询在业务完成之后，一定要先更新状态，再解锁]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/C++内联汇编]]></title>
    <url>%2F2018%2F04%2F08%2FC-C-%E5%86%85%E8%81%94%E6%B1%87%E7%BC%96%2F</url>
    <content type="text"><![CDATA[工具gcc asm去编译汇编，这个叫做汇编器编译器将C代码编译成汇编代码，汇编器将汇编代码编译成机器码教程： https://www.ibm.com/developerworks/cn/aix/library/au-inline_assembly/index.htmlhttps://www.jianshu.com/p/1782e14a0766 代码AT&amp;T格式汇编123456789101112#include &quot;stdio.h&quot;void main()&#123; int a=10, b; printf(&quot;%d&quot;,a); asm(&quot;movl %1, %%eax \n\t&quot; &quot;movl %%eax, %0&quot; :&quot;=r&quot;(b) /* output */ :&quot;r&quot;(a) /* input */ :&quot;%eax&quot; /* clobbered register */ ); printf(&quot;%d&quot;,b);&#125; 编译运行12gcc test.c -o test./test intel格式汇编 https://blog.werner.wiki/72829768/1234567891011121314#include &quot;stdio.h&quot;void main()&#123; //printf(&quot;hello world!&quot;); int a=10, b=0; printf(&quot;%d \n&quot;,b); asm(&quot;mov eax,5 \n\t&quot; &quot;mov eax,%1 \n\t&quot; &quot;mov %0,eax&quot; :&quot;=r&quot;(b) :&quot;r&quot;(a) :&quot;eax&quot; ); printf(&quot;%d \n&quot;,b);&#125; 编译运行12gcc -masm=intel test.c -o test./test intel格式汇编与AT&amp;T格式汇编的区别https://blog.csdn.net/tigerjibo/article/details/7708811https://blog.csdn.net/tianshuai1111/article/details/7900084 C转汇编1,把.c程序转变为AT&amp;T格式汇编.s[root@xxx asm_study]# gcc -S asm.c -o asm.s[root@xxx asm_study]# ls -al asm.s-rw-r–r– 1 root root 1387 06-30 10:41 asm.s 2,把.c程序转变为Intel格式汇编.s[root@xxx asm_study]# gcc -masm=intel test.c -o test.s当然，要想把c程序转为Intel汇编时，其中不能包含AT&amp;T格式的汇编，否则无法转。 C++AT&amp;T风格123456789101112131415#include &lt;iostream&gt;using namespace std;void main()&#123; int a=10,b=0; cout&lt;&lt;b&lt;&lt;endl; asm(&quot;movl %1, %%eax \n\t&quot; &quot;movl %%eax, %0&quot; :&quot;=r&quot;(b) /* output */ :&quot;r&quot;(a) /* input */ :&quot;%eax&quot; /* clobbered register */ ); cout&lt;&lt;b&lt;&lt;endl; return;&#125; 编译12icpc test.cpp -o test3./test3 intel风格123456789101112131415#include &lt;iostream&gt;using namespace std;void main()&#123; int a=10,b=0; cout&lt;&lt;b&lt;&lt;endl; asm(&quot;mov eax, %1 \n\t&quot; &quot;mov %0, eax&quot; :&quot;=r&quot;(b) /* output */ :&quot;r&quot;(a) /* input */ :&quot;eax&quot; /* clobbered register */ ); cout&lt;&lt;b&lt;&lt;endl; return;&#125; 编译运行12icpc -masm=intel test.cpp -o test3./test3 读取cpuid原理：读cpu的信息只需要一条汇编指令 cupid ,入口参数在EAX寄存器，返回的信息在EAX，EBX，ECX，EDX寄存器，也就是说执行cupid之前先给EAX寄存器赋值，在执行cupid，执行过之后，cpu的相关信息就在EAX，EBX，ECX，EDX寄存器中了，入口参数EAXhttps://blog.csdn.net/fisher_jiang/article/details/4348194https://blog.csdn.net/razor87/article/details/87117121234567891011121314151617181920#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;void main()&#123; //string message; int a=10; int iEAXValue,iEBXValue,iECXValue,iEDXValue; asm volatile(&quot;mov eax,0 \n\t&quot; &quot;cpuid \n\t&quot; &quot;mov %0,ebx \n\t&quot; &quot;mov %1,ecx \n\t&quot; &quot;mov %2,edx&quot; :&quot;=r&quot;(iEBXValue),&quot;=r&quot;(iECXValue),&quot;=r&quot;(iEDXValue) :&quot;r&quot;(a) :&quot;eax&quot; ); cout&lt;&lt;hex&lt;&lt;iEBXValue&lt;&lt;endl&lt;&lt;iECXValue&lt;&lt;endl&lt;&lt;iEDXValue&lt;&lt;endl; return;&#125;]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[powerManagement]]></title>
    <url>%2F2018%2F03%2F22%2FpowerManagement%2F</url>
    <content type="text"><![CDATA[Power mode设置cpupower模式为performance或者powersavecpupower frequency-set -g performance(powersave) 修改kernel的启动参数如何添加kernel启动的参数vi /boot/efi/EFI/redhat/grub.cfg找到对应的启动的kernel找到这一行linuxefi /vmlinuz-3.10.0-514.6.1.el7.x86_64 root=UUID=b3343e70-94d7-4506-88e2-025037204d23 ro crashkernel=auto rhgb quiet LANG=en_US.UTF-8 在这一行末尾添加参数，，以intel_pstate为例（https://www.kernel.org/doc/html/v4.14/admin-guide/kernel-parameters.html）linuxefi /vmlinuz-3.10.0-514.6.1.el7.x86_64 root=UUID=b3343e70-94d7-4506-88e2-025037204d23 ro crashkernel=auto rhgb quiet LANG=en_US.UTF-8 intel_pstate=disable reboot机器之后会生效 Driver有两种power manager的driverintel_pstate 和 acpi-cpufreq 通过 cpupower frequency-info 可以查看到当前使用的驱动通过在kernel设置intel_pstate=disable来使用acpi-cpufreq intel_pstate会使用hardware P state control (HWP)去控制cpu的P stateacpi-cpufreq 不会使用hardware P state control (HWP) 使用intel_pstate时，fixfreq的脚本不起作用只有set 0x774寄存器set 一下fixfreq的脚本rdmsr -a 0x774rdmsr -a 0x198 读取0x198的寄存器看频率数据cpupower monitor(freqency-info) 去看看会看到数值之间有差距 使用acpi-cpufreq时，fixfreq的脚本起作用set 一下fixfreq的脚本rdmsr -a 0x774rdmsr -a 0x198 读取0x198的寄存器看频率数据cpupower monitor(freqency-info) 去看看 工作原理总结官方介绍文档,第一个总体介绍cpu 频率的调节原则，第二个具体介绍了其中的一种pstate算法https://www.kernel.org/doc/html/v4.19/admin-guide/pm/cpufreq.htmlhttps://www.kernel.org/doc/html/v4.12/admin-guide/pm/intel_pstate.htmlintel的owner rafael.j.wysocki@intel.com看完官方文档再结合代码就明白了 原来linux是用acpi-drive去调节cpu 频率新的Intel cpu用intel-pstate drive去调节CPU频率后来intel又提供了Hardware P 去调节CPU频率要完全使用intel-pstate，需要在bios里面把Hardware disable掉,或者启动kernel的时候添加参数intel_pstate=no_hwp看kernel这个代码drivers\cpufreq\intel_pstate.c写了：HWP存在的时候，intel-pstate会被ignore掉 更底层的理解(可能不全面):操作系统的driver(acpi或者pstate)，根据目前cpu的负载(计算cpu在5种状态下的时间比例top命令可以看到)，计算得到的目标频率。请求ucode将这个目标频率写入某个pcode可以读的寄存器里面，pcode运行在硬件的pcu里面(pcode是一个单while循环，循环中间有checkpoint，每运行到一个checkpoint会去检查是否有更高优先级的事情要处理)，pcode读到这个目标频率之后生成一个rv,rv通过一系列的硬件序列化，检查阈值等操作得到最终的tv值，tv值就是真正的目标的运行频率。pcu控制cpu的电压以及运行频率。 acpi-drive支持5种governor的调节模式:Performance,powersave,Userspace,Ondemand和Conservativeintel-pstate只支持两种governor:Performance和powersave，intel-pstate的powersave的策略不同于acpi-drive，更像是acpi-drive的Ondemand策略 利用kernel提供的cpupower工具可以查看当前kernel使用的driver以及governor类型：12345678910111213141516root# cpupower frequency-infoanalyzing CPU 0: driver: intel_pstate CPUs which run at the same hardware frequency: 0 CPUs which need to have their frequency coordinated by software: 0 maximum transition latency: Cannot determine or is not supported. hardware limits: 1.20 GHz - 3.80 GHz available cpufreq governors: performance powersave current policy: frequency should be within 1.20 GHz and 3.80 GHz. The governor &quot;performance&quot; may decide which speed to use within this range. current CPU frequency: Unable to call hardware current CPU frequency: 1.20 GHz (asserted by call to kernel) boost state support: Supported: yes Active: yes 要修改driver，在boot选项中disable intel-pstate然后重启机器要修改governor，可以hot-change，直接利用kernel工具,cpupower1cpupower frequency-set -g performance 通过查看kernel源码：tools\power\cpupower\lib\cpupower.c12345678910111213141516171819202122232425static unsigned int sysfs_cpufreq_write_file(unsigned int cpu, const char *fname, const char *value, size_t len)&#123; char path[SYSFS_PATH_MAX]; int fd; ssize_t numwrite; snprintf(path, sizeof(path), PATH_TO_CPU &quot;cpu%u/cpufreq/%s&quot;, cpu, fname); fd = open(path, O_WRONLY); if (fd == -1) return 0; numwrite = write(fd, value, len); if (numwrite &lt; 1) &#123; close(fd); return 0; &#125; close(fd); return (unsigned int) numwrite;&#125; 知道这个工具其实是往sysfs对应的文件写入performance/sys/devices/system/cpu/cpu*/cpufreq/scaling_governor sysfs将内核空间的一些数据结构的接口暴露到了用户空间 进一步看intel-pstate调节的代码代码在driver/cpufreq模块里面，有三层：core提供代码执行的框架，governor提供计算目标频率的算法，driver提供操作硬件的接口 整个初始化流程： 调用driver’s -&gt;init() 函数：intel_pstate.c文件里面的intel_pstate_cpu_init函数 调用governor’s -&gt;init() 和start函数: cpufreq.c文件cpufreq_init_governor以及cpufreq_start_governor函数cpufreq_start_governor函数里面根据实例化的governor去调用start函数如果是intel-pstate的话，governor安全被重写了成了intel_pstate.c的setpolicy函数 正常工作的流程：intel_pstate.c的setpolicy函数被kernel注册为https://www.kernel.org/doc/html/v4.19/admin-guide/pm/cpufreq.html文档里面有描述:Instead, the driver’s -&gt;setpolicy() callback is invoked to register per-CPU utilization update callbacks for each policy.也就是说cpu的利用率更新的回调函数就是setpolicy函数，通过kernel去调度执行 看驱动代码drivers\cpufreq\intel_pstate.c看cpufreq_driver这个结构体可以知道target和setpolicy必定要设置一个 driver的setpolicy函数会在drivers\cpufreq\cpufreq.c文件里面被调用到cpufreq_set_policy函数里面会调用cpufreq_driver-&gt;setpolicy这个就对应了具体driver的setpolicy函数 当driver是intel_pstate的时候关键函数是setpolicy：intel_pstate_set_policy首先调用intel_pstate_update_perf_limits 去获得最大以及最小频率值设置到cpudata这个结构体里面，cpudata这个结构体存了每个cpu实例的数据intel_pstate_set_update_util_hook函数：这里hwp activate的话直接返回否则调用cpufreq_add_update_util_hook函数，进一步调用intel_pstate_update_util函数intel_pstate_update_util函数里面关键调用了intel_pstate_sample去读msr寄存器的值采集当前cpu的繁忙状态和intel_pstate_adjust_pstate函数去设置pstate，也就是写msr寄存器hwp activate的话调用intel_pstate_hwp_set函数：intel_pstate_hwp_set函数里面intel_pstate_get_epp函数去获得状态，intel_pstate_set_epb去设置pstate pstate 设置成passive模式的时候，driver就是intel_cpufreq运行时的关键函数是target：intel_cpufreq_target，这个函数的执行流程：cpufreq_freq_transition_begin函数：等待直到被唤醒intel_pstate_prepare_request函数：获得target_pstate如果target_pstate和当前pstate不相等: 写msr寄存器wrmsrl_on_cpu(msr:0x00000199)intel_cpufreq_trace函数:先调用intel_pstate_sample函数去采样获得当前的cpu的繁忙状态，再调用trace_pstate_sample函数等待唤醒 drivers\devfreq目录下面有各个governor对应的文件governor_performance.c文件为例：1subsys_initcall(devfreq_performance_init); subsys_initcall的作用就是将初始化函数注册到一个特定的段里面内核初始化的时候调用do_initcalls决定是否调用这个段对应的初始化函数这个文件里面定义一个devfreq_performance_func回调函数12345678910111213static int devfreq_performance_func(struct devfreq *df, unsigned long *freq)&#123; /* * target callback should be able to get floor value as * said in devfreq.h */ if (!df-&gt;max_freq) *freq = UINT_MAX; else *freq = df-&gt;max_freq; return 0;&#125; 直接把目标freq设置成最大值所以performance governor很暴力，每一次都把目标频率设置成最大值，交给pcu去调节 Intel-Pstate的turboturbo状态是 不可持续 的每个cpu有个turbo threshold的频率值，通过读msr可以知道对应cpu的这个值： 高于这个值就是turbo状态，power不支持所有core同时进入turbo状态，也无法保证一个core在turbo状态下呆多久低于这个值是非turbo状态，把频率fix在非turbo状态下的某个值，所有core都可以跑在这个值，不会低于这个值，但是某些core可以偶偶运行在高于这个值的频率上甚至turbo频率上面]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建Spark机群]]></title>
    <url>%2F2018%2F03%2F01%2F%E6%90%AD%E5%BB%BASpark%E6%9C%BA%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[介绍搭建一个spark机群进行数据分析结构：主节点+2个工作节点首先保证3个节点之间可以ssh免密码登录 依赖安装 主节点： java mvn：有必要配置代理,.m2/settings.xml spark：用做命令行测试，开发java程序，用mvn下载依赖包 工作节点： java spark： 启动salve并连接主节点正确安装各个依赖包之后，需要正确配置环境变量。 测试是否正确安装主节点 测试spark命令行，参考文档 测试spark用mvn构建，参考代码1234mvn packagespark-submit --class &quot;org.intel.dcg.leslie.SimpleApp&quot; --master local[4] target/simple-project-1.0.jar--class 指定jar包入口的class类--master local[4] 运行在本地的4线程 工作节点将主节点构建的jar包拷贝到工作节点123spark-submit --class &quot;org.intel.dcg.leslie.SimpleApp&quot; --master local[4] target/simple-project-1.0.jar# --class 指定jar包入口的class类# --master local[4] 运行在本地的4线程 构建机群参考文档 工作原理 运行命令行 standalone 主工具 步骤 首先配置cluster managers，参考standalone 主工具1.1 sbin/start-master.sh通过查看log可以看到master的url12345# start commandcd $spark_home/sbin./start-master.sh# read logvim $spark_home/logs/spark-root-org.apache.spark.deploy.master.*.log 从log里面得到启动的master的url： spark://headnode:7077这个变量要set到代码的SparkContext的master的变量里面1.2 编写 conf/slaves file1234vim $spark_home/conf/slaves#contentknm009knm010 1.3 在headnode上运行sbin/start-slaves.sh 运行所有slaves在worknode的节点上查看slaves的所有的log以及java进程12cd $spark_home/sbin./start-slaves.sh 用运行命令行启动应用12345678910# code:https://github.com/Leslie-Fang/basicSparkcluster branch# buildmvn package# how to run:# 跑在worknodes上面spark-submit --class &quot;org.intel.dcg.leslie.SimpleApp&quot; --master spark://headnode:7077 target/simple-project-1.0.jar# 跑在本地spark-submit --class &quot;org.intel.dcg.leslie.SimpleApp&quot; --master local[4] target/simple-project-1.0.jar 坑问题：worknode的log里看到无法连接Failed to connect to master headnode:7077http://blog.csdn.net/ybdesire/article/details/70666544需要关闭headnode的防火墙关闭之后将headnode上worknode上的spark进程都关闭关闭之后，重启headnode上的spark-master以及spark-client 搭建 BigDLBigDL是基于spark的进行DL的框架参考文档 安装 12345git clone https://github.com/intel-analytics/BigDL.gitcd $BigDL_Home# buildbash make-dist.sh -P spark_2.x#生成一个dist的folder 使用入门 setup spark的cluster 下载数据集合 运行spark，指定bigDL的jar包构建BigDL的jar包，和spark的multi-node一样的方式运行 1spark-submit --master spark://headnode:7077 --executor-cores 1 --total-executor-cores 2 --class com.intel.analytics.bigdl.models.vgg.Train dist/lib/bigdl-0.3.0-SNAPSHOT-jar-with-dependencies.jar -f /home/lf/bigdl/data/cifar-10-batches-bin -b 2 坑java虚拟机的堆空间溢出java.lang.OutOfMemoryError: Java heap space]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins]]></title>
    <url>%2F2018%2F02%2F27%2FJenkins%2F</url>
    <content type="text"><![CDATA[介绍Jenkins是一个自动化构建，测试工具 官网地址 教程https://jenkins.io/doc/pipeline/tour/hello-world/#examples 启动服务器： java -jar jenkins.war –httpPort=8080 启动服务器之后在页面上配置代理： skip配置代理先 用户名:leslie 123456 进入之后看到用户管理页面 新建一个项目 在项目页面上构建build的命令 build之后可以在项目页面中，进入build结果的页面 查看build结果中命令行的输出 配置maven代理： 公司内网没有配置成功，还是无法连接上maven的中心仓库 和github的集成可以在线安装插件有时候代理不可用的时候也可以离线安装plugin https://stackoverflow.com/questions/14950408/how-to-install-a-plugin-in-jenkins-manually 插件下载地址： https://updates.jenkins-ci.org/download/plugins/git/安装完插件之后如何和集成： https://www.jianshu.com/p/2836551a45ba]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[odata]]></title>
    <url>%2F2018%2F02%2F05%2Fodata%2F</url>
    <content type="text"><![CDATA[介绍开放数据协议（Open Data Protocol，缩写 OData）是一种描述如何创建和访问 Restful 服务的 OASIS 标准。sapui5和后端通过odata作为接口，odata的wiki介绍,官网教程 sapui5+odataopenui5的文档搜索odata可以看到如何使用odata和后端交互数据推荐使用：sap.ui.model.odata.v2.ODataModel]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark]]></title>
    <url>%2F2018%2F01%2F30%2FSpark%2F</url>
    <content type="text"><![CDATA[Install Download &amp; uncompressed jdk set the environment variables of java 123456export JAVA_HOME=/home/automation/java/jdk1.8.0_161export CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:.export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATHexport SBT_HOME=/home/automation/spark/sbt/sbtexport SPARK_HOME=/home/automation/spark/spark-2.2.1-bin-hadoop2.7export PATH=$PATH:$SBT_HOME/bin:$SPARK_HOME/bin Download &amp; uncompressed spark set the environment variables of spark install sbt： used to build scala Doc官方入门文档 打开命令行交互dataset的构造函数中传入输入文件，调用dataset的[API处理文档]（https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset） 编写可运行的文件 build.sbtSimpleApp.scala放在规定的目录结构下面12345678910111213import org.apache.spark.sql.SparkSessionobject SimpleApp &#123; def main(args: Array[String]) &#123; val logFile = &quot;YOUR_SPARK_HOME/README.md&quot; // Should be some file on your system val spark = SparkSession.builder.appName(&quot;Simple Application&quot;).getOrCreate() val logData = spark.read.textFile(logFile).cache() val numAs = logData.filter(line =&gt; line.contains(&quot;a&quot;)).count() val numBs = logData.filter(line =&gt; line.contains(&quot;b&quot;)).count() println(s&quot;Lines with a: $numAs, Lines with b: $numBs&quot;) spark.stop() &#125;&#125; sbt package 的时候如果有些包因为proxy无法下载将包离线下载下来以后放到对应的目录下面 ~/.sbt/preloaded/*]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MKL]]></title>
    <url>%2F2018%2F01%2F19%2FMKL%2F</url>
    <content type="text"><![CDATA[介绍MKL是intel开发的一个数学运算库，集成在psxe软件包中。提供了一写API供开发者调用。 安装首先安装psxe包含了所有的原件，或者单独安装mkl以及icc 如何使用MKL入门教程 C语言：在代码投include mkl的头文件： #include “mkl.h”在代码中调用mkl的API 编译：source MKL的环境，主要配置环境变量，设置动态链接库的路径：source /opt/intel/compilers_and_libraries_2018.1.163/linux/mkl/bin/mklvars.sh intel64 source一下iccsource /opt/intel/bin/iccvars.sh intel64 直接编译文件：icc mkl-lab-solution.c -mkl用makefile肯定也是类似的 生成一个可执行文件：a.out可以直接运行：./a.out 1000]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MKLDNN]]></title>
    <url>%2F2018%2F01%2F19%2FMKLDNN%2F</url>
    <content type="text"><![CDATA[介绍MKLDNN是一个Intel开发的基于Intel芯片架构的开源库，提供用于深度学习的API.Intel 开源软件中心MKLDNN Github 主页教程主页 编译安装mkldnn1234561. Git clone mkldnn2. source psxe3. Cd mkldnn &amp;&amp; mkdir build &amp;&amp; cd build4. CC=icc CXX=icpc cmake .. -DCMAKE_INSTALL_PREFIX=../mkldnn_install/ ##debug版本编译加参数 -DCMAKE_BUILD_TYPE=Debug5. CC=icc CXX=icpc make -j 66 &amp;&amp; make install make install之后：如果第二步没有指定目录，会安装在/usr/local目录下面Shared libraries (/usr/local/lib):头文件：Header files (/usr/local/include):文档:Documentation (/usr/local/share/doc/mkldnn): 编译链接代码：入门文档这个文档内容有点问题：具体编译的命令看github的readme：https://github.com/01org/mkl-dnn首先配置环境变量12345678910source psxe(应该只需要mkl模块)export MKLDNNROOT=/home/automation/mkldnn/selfBuilt/mkl-dnn-0.12/mkldnn_installG++ 编译g++ -std=c++11 -I$&#123;MKLDNNROOT&#125;/include -L$&#123;MKLDNNROOT&#125;/lib simple_net.cpp -lmkldnn -o ./bin/simple_net_cpp编译debug版本:g++ -g -std=c++11 -I$&#123;MKLDNNROOT&#125;/include -L$&#123;MKLDNNROOT&#125;/lib simple_net.cpp -lmkldnn -o ./bin/simple_net_cpp用icc编译的话：icpc -std=c++11 -I$&#123;MKLDNNROOT&#125;/include -L$&#123;MKLDNNROOT&#125;/lib simple_net.cpp -lmkldnn -o ./bin_icc/simple_net_cpp 编译完的运行：报错找不到mkldnn的动态链接库添加动态链接库12345678export LD_LIBRARY_PATH=$LD_LIBRARY_PATH://home/automation/mkldnn/selfBuilt/mkl-dnn-0.12/mkldnn_install/lib报错找不到mkl_rt：source 一下mkl或者psxe然后运行：./bin_icc/simple_net_cpp运行成功，不会报错 Simple_Net Code API 代码的解释https://software.intel.com/en-us/articles/intel-mkl-dnn-part-2-sample-code-build-and-walkthrough 调试simple_net.cpp代码看一个primitive的例子：step1：line:117convolution_forward(conv1_prim_desc, conv1_src_memory, conv1_weights_memory, user_bias_memory, conv1_dst_memory)convolution_forward就是primitive的名字 step2：看convolution_forward的构造函数调用了mkldnn_primitive_create step3：mkldnn_primitive_create的构造函数：调用了primitive_desc-&gt;create_primitive step4:看primitive_desc-&gt;create_primitive这个是个虚函数，需要看具体的primitive_desc子类的实现用gdb去看看到底调用哪个实现函数debug12345gdb a.outbreak primitive.cpp:35(mkldnn_primitive_create这个函数上)单步调试到return primitive_desc-&gt;create_primitive(primitive, inputs, outputs);看看调用了哪个kernelbt 单步调试n，遇到return primitive_desc-&gt;create_primitive(primitive, inputs, outputs); s：step in这个实现 看到create_primitive函数创建memory的时候调用了12#0 mkldnn::impl::cpu::cpu_memory_t::pd_t::create_primitive (this=0x634400, primitive=0x7ffffffea508, inputs=0x0, outputs=0x0) at /home/lesliefang/mkldnn/mkl-dnn-0.17.2/src/cpu/cpu_memory.hpp:45 reoder这个op对应了1/home/lesliefang/mkldnn/mkl-dnn-0.17.2/src/cpu/jit_uni_reorder.cpp:818 conv这个op对应调用到了/home/lesliefang/mkldnn/mkl-dnn-0.17.2/src/cpu/jit_avx512_common_convolution.hpp:461234567jit_avx512_common_convolution_fwd_t的构造函数里面new jit_avx512_common_conv_fwd_kerneljit_avx512_common_conv_fwd_kernel构造函数里面调用generate方法generate方法就是jit去生成汇编，可以看到里面调用了xbyak的库函数generate函数最后ker_ = getCode&lt;decltype(ker_)&gt;();把生成的代码放在ker_这个类有个operator方法是真实运行的代码，函数里面会调用ker_(&amp;args);operator方法在这个类的execute_forward函数里面的parallel方法里面被调用 进一步看generate方法： jcp变量jcp是一个jit_conv_conf_t类型的成员变量在jit_avx512_common_conv_fwdkernel初始化成员列表里面做初始化jcp(ajcp)ajcp是传进来的参数conf.jcpconf是jit_avx512_common_convolution_fwd_t的成员变量pdt conf;在jit_avx512_common_convolution_fwdt初始化成员函数列表里面构造conf(*pd) generate函数开始从jcp里面读出输入输出变量的维度计算会调用compute_loop函数，compute_loop根据jcp.ver类型选择调用compute_loop_vnni或者compute_loop_4fma 多线程计算的实现需要链接openMP去实现 step1:全局搜1234grep -rni &quot;pragma omp parallel&quot;看到src/common/mkldnn_thread_parallel_nd.hpp:47:# pragma omp parallel num_threads(nthr)src/common/mkldnn_thread_parallel_nd.hpp:154:# pragma omp parallel 应该是封装在了这个parallel函数里面1234#elif MKLDNN_THR == MKLDNN_THR_OMP if (nthr == 1) &#123; f(0, 1); return; &#125;# pragma omp parallel num_threads(nthr) f(mkldnn_get_thread_num(), mkldnn_get_num_threads()); 一般用openMP的线程不用tbb的线程 step2:在src目录下面搜索parallel的函数调用是在execute函数里面调用的，所以并行化是在stream提交了之后，调用kernel的execute的函数的时候执行的继续以simple_net.cpp代码中的jit_avx512_common_convolution.hpp:46的jit_avx512_common_convolution_fwd_t作为例子stream提交之后会调用jit_avx512_common_convolution_fwd_t中的execute函数，如果2D卷积的话调用execute_forward_2d函数这个函数里面调用了parallel函数去做多线程运算parallel函数的第二个参数就是每个线程要执行的函数，一般就是个lamba匿名函数匿名函数里面通过jit_conv_ker_pipeline_owthr去调用kernel-&gt;jit_ker执行运算 kernel_变量在_jit_avx512_common_convolution_fwdt构造函数里面实现kernel = new jit_avx512_common_conv_fwdkernel(conf.jcp, *conf.attr());jit_ker在jit_avx512_common_conv_fwd_kernel的构造函数里面通过jit_ker = (void (*)(jit_conv_call_s *))getCode();实现 MKLDNN的primitive如何选择对应的kernel在调用privimite-&gt;create_primitivate的时候会去遍历所有的kernel，在每个kernel的函数中都有一个init_conf的函数，在遍历所有的kernel的时候，会去看这个init_conf的函数是否满足条件，满足条件就意味着调用这个kernel，否则的话就看下个kernel 以_jit_avx512_common_convolution_fwd_t为例子是在构造primitive desc的时候就选择好了使用哪个kernel step1:在simple_net.cpp line:93auto conv1_prim_desc = convolution_forward::primitive_desc(conv1_desc, cpu_engine);创建primitive desc step2:convolution_forward::primitive_desc构造函数中调用mkldnn::primitive_desc step3:mkldnn::primitive_desc里面调用mkldnn_primitive_desc_iterator_create_v2 step4:mkldnn_primitive_desc_iterator_create_v2函数里面创建primitive_desc_iterator_t对象这个函数比较难懂，记录下自己的理解123456789101112131415161718status_t mkldnn_primitive_desc_iterator_create_v2( primitive_desc_iterator_t **iterator, const_c_op_desc_t c_op_desc, const primitive_attr_t *attr, engine_t *engine, const primitive_desc_t *hint_fwd_pd) &#123; const op_desc_t *op_desc = (const op_desc_t *)c_op_desc; auto it = new primitive_desc_iterator_t(engine, op_desc, attr, hint_fwd_pd); if (it == nullptr) return out_of_memory; ++(*it); if (*it == it-&gt;end()) &#123; delete it; return unimplemented; &#125; *iterator = it; return success;&#125; new primitive_desc_iterator_t的时候返回一个iterator，同时lastidx遍历impllist所有op直到末尾，用于end()成员方法的调用。impllist 通过engine_-&gt;get_implementationlist() 在构造函数的初始化列表里面生成engine对应的cpu_engine 看get_implementation_list方法是cpu_engine.cpp文件里面的函数，直接返回了cpu_impl_list变量cpu_impl_list数组里面,每个元素都调用instance 宏创建了一个模板函数指针istance宏其实是根据输入类型创建了mkldnn_primitive_desc::create这个模板函数指针（在primitive_desc.hpp文件里面）在后面调用++it的时候，这段代码（auto s = impllistidx_;）其实就是调用了这个实例化mkldnn_primitive_desc::create这个模板函数指针mkldnn_primitive_desc::create函数里面会去尝试创建对应的primitive descriptionmkldnn_primitive_desc::create方法调用失败返回unimplemented调用成功，把创建的pd赋值给传入的参数，同时返回success同时++it函数里面也会去判断是否success Ps.source insight里面搜索primitive_desc_iterator_t符号using primitive_desc_iterator_t = mkldnn_primitive_desc_iterator;impllist包含了所有kernel的实现 ++(*it); primitive_desc_iterator_t里面对++运算符进行了重载，在++重载的运算符中遍历尝试根据输入的类型去创建primitive desc（auto s = impllistidx_;），创建失败就尝试下一个primitive desc直到成功 if (*it == it-&gt;end()) 判断一下是不是创建成功退出的 *iterator = it; 创建成功的话，直接把it赋值给iterator返回通过以上步骤就找到了对应要调用的primitive_desc后面在创建primitive的时候调用primitive_desc-&gt;create_primitive，就是对应pd的create_primitive函数通过下面对PD的分析可以知道这里调用到的就是pd里面DECLARE_COMMON_PD_T里面的create_primitive方法 get_implementation_list在哪里实例化list里面的kernel这个engine_是传进来构造的看cpu_engine.cpp文件中get_implementation_list的实现line:331123const pd_create_f* cpu_engine_t::get_implementation_list() const &#123; return cpu_impl_list;&#125; 这里的cpu_impl_list是个列表每个成员都是pd_create_f对象 #define INSTANCE(…) &amp;primitive_desc_t::create调用了primitive_desc_t::create创建了每个primitive desc的类型放在cpu_impl_list里面 using primitive_desc_t = mkldnn_primitive_desc;primitive_desc_t就是mkldnn_primitive_desc mkldnn_primitive_descmkldnn_primitive_desc有create方法，传进来的参数是VA_ARGS::pd_t比如_jit_avx512_common_convolution_fwd_t就是这个op的pd_t成员看mkldnn_primitive_desc有create方法，里面调用了_pd-&gt;init()，就是_jit_avx512_common_convolution_fwd_t的pd_t成员的init方法 MKLDNN框架介绍 Caffe调用MKLDNN可以我的另外一篇博客参考：Caffe中的生产者模式 caffe的layer_factory会去创建mkldnn的层 caffe在调用layer.forward函数的时候会调用到对应mkldnn的层的forward_cpu函数 在这个函数中(initxxxpd)的方法会先去判断对应的pd(privimite descriptive)和privimite是否存在，如果不存在的话会去创建对应的pd 在initxxxpd方法中会去调用reset的方法去创建pd(privimite descriptive)和privimite reset方法的传入的参数就是new出来的一个新的mkldnn的primitive进入mkldnn 在new一个新的mkldnn的primitive的时候，可以看到create后缀或者init后缀的函数 在这些create函数中最后会去调用一个privimite-&gt;create_primitivate的函数，这是个虚函数 这个虚函数和具体的运算kernel之间如何调用实现的，暂时不是很清楚，应该有复杂的调用关系，但是核心的思想是：在调用privimite-&gt;create_primitivate的时候会去遍历所有的kernel，在每个kernel的函数中都有一个init_conf的函数，在遍历所有的kernel的时候，会去看这个init_conf的函数是否满足条件，满足条件就意味着调用这个kernel，否则的话就看下个kernel MKLDNN with VTunehttps://github.com/intel/mkl-dnn/blob/master/doc/perf_profile.md#intelr-vtunetm-profiling kernel的名字igemm_s8u8s32:blass8u8s32: s8表示输入的数据类型，u8表示权重的数据类型术语：https://github.com/intel/mkl-dnn/tree/master/tests/benchdnn 运行benchdnnhttps://github.com/intel/mkl-dnn/tree/master/tests/benchdnn编译完mkldnn在build目录下面 环境变量veboseexport MKLDNN_VERBOSE=1https://intel.github.io/mkl-dnn/perf_profile.html Dumping JIT-kernelsexport MKLDNN_JIT_DUMP=1https://intel.github.io/mkl-dnn/perf_profile.html VERBOSE如何工作环境变量设置了VERBOSE=1的话mkldnn_verbose()-&gt;level的值就是1看这个文件cpu_engine_t.cpp在stream在submit的时候，如果设置了verbose就会打印出来12345678910111213141516status_t cpu_engine_t::submit(primitive_t *p, event_t *e, event_vector &amp;prerequisites) &#123; /* FIXME: this should live in primitive execute function... */ if (mkldnn_verbose()-&gt;level) &#123; double ms = get_msec(); p-&gt;execute(e); ms = get_msec() - ms; printf(&quot;mkldnn_verbose,exec,%s,%g\n&quot;, p-&gt;pd()-&gt;info(), ms); fflush(0); &#125; else &#123; p-&gt;execute(e); &#125; if (msan_enabled) unpoison_outputs(p); return success;&#125; p-&gt;pd()-&gt;info()就是这个primitive对应的pd的信息p是mkldnn_primitive类型的primitive.hpp文件定义了这个类的成员和函数p-&gt;pd()p-&gt;kind() 根据MKLDNN_VERBOSE输出内容查看对应调用到的primitive和kernel设置verbose=1之后看到日志输入1mkldnn_verbose,exec,convolution,jit:avx512_common,backward_weights,fsrc:nChw16c fwei:OIhw16i16o fbia:undef fdst:nChw16c,alg:convolution_direct,mb64_ic32oc64_ih14oh14kh5sh1dh0ph2_iw14ow14kw5sw1dw0pw2,25.3359 关键字： jit:avx512_common mkldnn找到这两个文件jit_avx512_common_convolution.hppjit_avx512_common_convolution.cpp hpp文件里面订了了这个primitive的类，里面pd_t的结构体就是这个promitive的desciptive调用pd-&gt;create_primitive的时候就调用了这个pd_t结构体里面的123DECLARE_COMMON_PD_T( JIT_IMPL_NAME_HELPER(&quot;jit:&quot;, avx512_common, &quot;&quot;), jit_avx512_common_convolution_fwd_t); 这个内联函数，里面创建了这个primitive的实例看这个primitive的构造函数1234567jit_avx512_common_convolution_fwd_t(const pd_t *apd, const input_vector &amp;inputs, const output_vector &amp;outputs) : cpu_primitive_t(apd, inputs, outputs)&#123; kernel_ = new jit_avx512_common_conv_fwd_kernel(pd()-&gt;jcp_, *pd()-&gt;attr());&#125; 关键：12kernel_ = new jit_avx512_common_conv_fwd_kernel(pd()-&gt;jcp_, *pd()-&gt;attr()); 这里引出了两个kernel的文件：jit_avx512_common_conv_kernel.cppjit_avx512_common_conv_kernel.hpp 看jit_avx512_common_conv_fwd_kernel的构造函数1234567891011jit_avx512_common_conv_fwd_kernel(jit_conv_conf_t ajcp, const primitive_attr_t &amp;attr) : jcp(ajcp), attr_(attr), eltwise_injector_(nullptr)&#123; if (jcp.with_eltwise) eltwise_injector_ = new jit_uni_eltwise_injector_f32&lt;avx512_common&gt;( this, jcp.eltwise); generate(); jit_ker = (void (*)(jit_conv_call_s *))getCode();&#125; generate();函数就是去生成汇编代码jit_ker = (void (*)(jit_conv_call_s *))getCode();函数就是把汇编代码放到jit_ker这个kernel对象的成员变量里面（这个kernel对象又是这个primitive对象的成员变量）getcode函数也会去dump bin文件(如果设置了环境变量:export MKLDNN_JIT_DUMP=1) stream submit之后发生了什么stream-&gt;submit(pd)之后调用了jit_avx512_common_convolution.hpp里面的exectue函数exectue函数根据条件选择jit_avx512_commonconvolution.cpp里面具体的exectue的实现具体的exectue的实现里面，调用了parallel去做并行化的计算，每个线程里面调用kernel-&gt;jit_ker（jit_ker按照上一节的解释就是对应的汇编代码）]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链]]></title>
    <url>%2F2018%2F01%2F17%2F%E5%8C%BA%E5%9D%97%E9%93%BE%2F</url>
    <content type="text"><![CDATA[入门资料 什么是区块链https://www.youtube.com/watch?v=chQttZ4PH24]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kernel学习笔记]]></title>
    <url>%2F2018%2F01%2F07%2Fkernel%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[用户态与内核态http://jakielong.iteye.com/blog/771663 linux启动过程https://www.youtube.com/watch?v=yeMA7AJFtb8https://www.youtube.com/watch?v=ALzySqflHJwyoutube:Basics of the Linux Boot Process 内存管理http://gityuan.com/2015/10/30/kernel-memory/youtube的教程：Virtual Memory，包括TLB的使用 Hyper-threading 技术Intel的CPU可以再BIOS仲打开hyper-threading比如说2socket，每个socket有28个物理的core，打开hyper-threading之后可以有56个逻辑core，一共是112个逻辑core可以通过 1numactl --hardware 查看socket 0上的逻辑core的编号是0-27,56-83socket 1上的逻辑core的编号是28-55,84-111可以通过1taskset -c 0,56(逻辑core的编号) process 将特定的process运行在这些逻辑core上面 进程与线程进程通过调用fork这个kernel的api实现线程通过调用Pthreads这个kernel的api实现通过top可以看到进程的pid通过top -p 进程pid可以看到这个进程包含的线程]]></content>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mango's Journey of Python]]></title>
    <url>%2F2017%2F12%2F10%2FforMango%2F</url>
    <content type="text"><![CDATA[IntroductionThis is a python learning plan for Mango who has a dream of being an professional analyst. Rome Was not Building in a Day. Wish you to be dedicated and enjoy the gain after pay. Main Content Python basic concept(5 weeks) Flask Module and Web develop(1 week) Numpy Module(2 weeks) Pandas Module(1 week) AI Introduction(1 week) Weekly PlanHere we would use World Standards Week ,which is in short of WW, to count learning progress. World Week Plan WW50 PyCharm installation: pycharm is my favourite develop tool for python Python Introduction Variable and expression WW51 Condition(If..else..) Loop(for and while) 2017WW52-2018WW1 Merry Christmas and Enjoy the holiday WW2 Python FunctionData Structure WW3 Python modules WW4 Flask Module and Web develop WW5 Python Class WW6 Review and independent Task（Greedy Snake） WW7-8 Spring Festival WW9-10 Review and independent Task WW11 Introduction of Numpy WW12 Introduction of Pandas WW13 Introduction of AI with the application of numpy and pandas]]></content>
      <tags>
        <tag>Daily</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ncurses]]></title>
    <url>%2F2017%2F12%2F04%2Fncurses%2F</url>
    <content type="text"><![CDATA[介绍ncurses是一个库提供了API进行终端(termal)的编程，可以看到类似于我们在终端编译内核的时候出现的选项界面。除了C语言，还可以用nodejs，python等去调用. 参考文章https://www.gnu.org/software/ncurses/http://tldp.org/HOWTO/NCURSES-Programming-HOWTO/]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[numactl]]></title>
    <url>%2F2017%2F12%2F02%2Fnumactl%2F</url>
    <content type="text"><![CDATA[介绍NUMA(Non-Uniform Memory Access)字面直译为“非一致性内存访问”对于多核CPU而言，它的作用可以将程序绑定在固定的CPU的进程以及固定的内存块上，避免了程序在不同CPU和内存块之间切换导致的时间消耗。从而可以提高程序的性能 查看cpu的配置1numactl --hardware 来看两类CPU的值： CPU1，物理上有两个socket，每个socket 28core，每个core可以超线程2注意socket0，1上超线程的那个线程的值是错开的0,56在同一个物理core上面123456789101112131415161718192021available: 2 nodes (0-1)node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83node 0 size: 96071 MBnode 0 free: 93860 MBnode 1 cpus: 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111node 1 size: 0 MBnode 1 free: 0 MBnode distances:node 0 1 0: 10 21 1: 21 10 这里我们希望特定的程序运行在特定的memory以及特定的线程上面可以使用这样的命令1numactl -m 0(1) taskset -c 0,56 command to start the program CPU2，物理上只有1个socket，每个socket 72core，每个core可以超线程4所以所有的CPU的进程都在CPU上面但是CPU2在CPU内部还有内存，所以看到CPU2上进程数为0，但是有memory 123456789101112131415161718192021available: 2 nodes (0-1)node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287node 0 size: 193306 MBnode 0 free: 191208 MBnode 1 cpus:node 1 size: 16125 MBnode 1 free: 15831 MBnode distances:node 0 1 0: 10 31 1: 31 10 所以如果希望程序使用CPU内部的这部分内存可以这样1numactl -m 1 command to start the program auto numa balanceredhat系统默认打开auto numa balance理论上使用numactl的时候就不会用到auto numa balance numastatnumastat查看numa的使用情况博客资料http://dupengair.github.io/2016/10/12/%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95-%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E5%B7%A5%E5%85%B7%E7%AF%87-numastat/]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[caffe]]></title>
    <url>%2F2017%2F11%2F11%2Fcaffe%2F</url>
    <content type="text"><![CDATA[介绍Caffe 是Berkeley Vision and Learning Center(BVLC)开发的一个深度学习的框架，github地址,最初是用于图像处理，也可以用于自然语言处理。英特尔根据自己的CPU对caffe做了优化，并发布了intelcaffe版本，调用MKL以及MKLDNN库，从而编译后使用最新的指令集加速运算。 基本概念 Blob就是caffe封装的数据，默认的输入图像的格式是(NCHW):number N x channel K x height H x width W solver: 定义一个solver文件,里面指定使用哪个net，步长多少 安装 安装一些系统依赖包 下载Intel caffe的源码 cp Makefile.config.example Makefile.config 修改Makefile.config中的编译选项 make -j 270 all（指定编译过程中可以使用的进程数量） 手写数字识别(Mnist)准备数据下载数据运行这个脚本$CAFFE_ROOT/data/mnist/get_mnist.sh下载数据集到当前目录下面$CAFFE_ROOT/data/mnist/ 转换数据格式运行这个脚本去转换数据格式$CAFFE_ROOT/examples/mnist/create_mnist.sh会在$CAFFE_ROOT/examples/mnist/目录下面生成两个.lmdb后缀的文件，里面就是训练集和测试集 LeNet模型要使用caffe，最重要的就是定义模型，也就是编写对应的.prototxt文件$CAFFE_ROOT/examples/mnist/lenet_train_test.prototxt LeNet的求解器solversolver定义了求解的参数$CAFFE_ROOT/examples/mnist/lenet_solver.prototxt 运行的环境变量设置与脚本./examples/mnist/train_lenet.sh在solver中有指定训练多少itertaion之后保存一次模型参数可以用于后面进一步的训练或者inference]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译Ubuntu内核]]></title>
    <url>%2F2017%2F10%2F30%2F%E7%BC%96%E8%AF%91Ubuntu%E5%86%85%E6%A0%B8%2F</url>
    <content type="text"><![CDATA[介绍根据使用需要，有时候关闭一些内核选项，然而在OS没有提供对应工具的情况下，就需要重新编译linux的kernal 查看内核版本1234# 查看内核版本uname -r# 查看OS版本lsb_release -a 下载源码apt-get install linux-source下载内核默认下载到 /usr/src 目录 解压缩包12tar xf linux-.*.tar.xz -C /usr/src/ln -sv linux-.* linux # 有需要的话需要创建一个链接 配置内核选项并编译配置编译选项配置内核的方法的编译选项的方法有好多种，下面的每一种make就对应了一种方法，只需要从里面选一种就可以了，最常见的就是make menuconfig, 但是需要安装cc和ncurses-devel这两个包12345678make config：遍历选择所要编译的内核特性make allyesconfig：配置所有可编译的内核特性make allnoconfig：并不是所有的都不编译，而是能选的都回答为NO、只有必须的都选择为yes。make menuconfig：这种就是打开一个文件窗口选择菜单，这个命令需要打开的窗口大于80字符的宽度，打开后就可以在里面选择要编译的项了下面两个是可以用鼠标点选择的、比较方便哦：make kconfig(KDE桌面环境下，并且安装了qt开发环境)make gconfig(Gnome桌面环境，并且安装gtk开发环境)menuconfig：使用这个命令的话、如果是新安装的系统就要安装gcc和ncurses-devel这两个包才可以打开、然后再里面选择就可以了、通这个方法也是用得比较多的： 另外一种常见的方法是基于当前OS的编译配置选项去修改，复制当前系统上的/boot/config-版本-平台编译选项文件，将这个文件复制到/usr/src/linux/.config覆盖./config这个文件，然后make oldconfig去配置：这种方法下面，相同的选项就用.config里面老的配置，新的选项会去提示我们怎么配置12c /boot/config .configyes &quot;&quot; | make oldconfig#(使用.config里面的配置，.config里面没有配置的地方使用默认的选项) 编译用screen开一个子窗口，在子窗口中编译1make -j144 all 2&gt;&amp;1 | tee make_record.txt centos上面报错找不到openssl的某个文件12## 安装一下这个packageyum install openssl-devel 这一步不确定是否需要,目前感觉不一定需要。目前看下来，是编译的镜像要在别的机器上用的时候才需要，如何是在编译的本地机器上使用的话，应该是不需要make 之后 在 make install之前还需要make bzImage一下，不然会报错* Missing file: arch/x86/boot/bzImage 编译后的安装12345make modules_install #这一步是需要的 这步完了之后你可以查看一下/lib/modules/目录下就会生成一个以版本号命名的一个文件模块了make install 安装完之后会在/boot/目录下生成一个内核文件vmlinuz-3.13.2、还有几个跟你当前编译的版本一样的文件、可以ls去看一下：ls /boot/ 配置启动项编译好了一个新内核了之后可以到grub.conf配置文件时看一下： vim /boot/grub/grub.conf参考文档2 How GRUB2 selects which kernel to boot fromhttps://www.thegeekdiary.com/centos-rhel-7-change-default-kernel-boot-with-old-kernel/By default, the value for the directive GRUB_DEFAULT in the /etc/default/grub file is “saved”.1234567# cat /etc/default/grubGRUB_TIMEOUT=5GRUB_DEFAULT=savedGRUB_DISABLE_SUBMENU=trueGRUB_TERMINAL_OUTPUT=&quot;console&quot;GRUB_CMDLINE_LINUX=&quot;nomodeset crashkernel=auto rd.lvm.lv=vg_os/lv_root rd.lvm.lv=vg_os/lv_swap rhgb quiet&quot;GRUB_DISABLE_RECOVERY=&quot;true&quot; This instructs GRUB 2 to load the kernel specified by the saved_entry directive in the GRUB 2 environment file, located at /boot/grub2/grubenv. 真正起作用的是/boot/efi/EFI/centos下面的grubenv和grub.cfg而不是/boot/grub2/grub下面grubenv和grub.cfg因为我们用的是UEFI的BIOS去启动的 重启系统，在重启界面上可以看到各个可以启动的内核的信息，选择我们刚刚编译好的这个内核如果在第一层没有看到内核的选项，进入到advance的里面一级选项，里面会看到编译好的内核的启动选项 删除不需要的kernal直接在/boot下面把对应的文件删除，一个kernal应该有三个文件然后在/boot/grub/grub.cfg文件里面把对应的启动项给删除了修改grub.cfg是只读属性chmod 644 grub.cfg改完保存之后chmod 444 grub.cfg 重新改成只读的属性启动之后看到旧的选项被删除了]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[受限玻尔兹曼机]]></title>
    <url>%2F2017%2F10%2F21%2F%E5%8F%97%E9%99%90%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[介绍受限玻尔兹曼机常用作无监督学习.包含两层，可见层和隐藏层，层内神经元无连接，层间神经元全连接，因此受限玻尔兹曼机对应了一个二分图. 核心概念调整参数，使得用RBM表示的概率分布尽可能的和训练数据集相符合。核心训练算法采用对比散度法 代码参考参考github仓库-fork from xidui.]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[同一OS下不同python2.7与3.4]]></title>
    <url>%2F2017%2F10%2F15%2F%E5%90%8C%E4%B8%80OS%E4%B8%8B%E4%B8%8D%E5%90%8Cpython2-7%E4%B8%8E3-4%2F</url>
    <content type="text"><![CDATA[介绍目前大部分程序都是基于python2.7开发的，但是python2只维护到2020年，未来是python3的，本文只要为了在一台机器上同时安装python2和python3，避免发生包冲突的问题。 安装可以参考链接1macos上默认安装的就是python2.7直接1brew install python3 安装完成之后python -V看到的还是python2.7.10 安装完成之后python3 -V看到python3的版本 强烈建议使用virtualenv链接 创建python2的虚拟环境 123pip install virtualenvpython -Vvirtualenv --no-site-packages venv3 --python=python2.7 创建python3的虚拟环境 123pip3 install virtualenvpython3 -Vvirtualenv --no-site-packages venv3 --python=python3.6]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python_virtualenv]]></title>
    <url>%2F2017%2F10%2F15%2Fpython-virtualenv%2F</url>
    <content type="text"><![CDATA[介绍为了解决不同python程序之间，所依赖的包的版本不同导致程序无法运行的问题。 解决方法解决方法可以是将在现有的程序代码的目录下运行 创建创建一个venv目录，这个目录表示的就是一个python虚拟环境1virtualenv --no-site-packages venv 启动虚拟环境一下命令可以启动虚拟环境1source venv/bin/activate 关闭虚拟环境关闭虚拟环境1deactivate 删除直接删除venv文件夹及可以 开发在pycharm的default设置中可以选择到这个虚拟环境中的python，来解析pcharm中的包的依赖问题]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[postgresql学习笔记]]></title>
    <url>%2F2017%2F10%2F15%2Fpostgresql%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[介绍PostgreSQL相对于竞争者的主要优势为可编程性：对于使用数据库资料的实际应用，PostgreSQL让开发与使用变得更简单。微信支付核心数据库也是基于 PostgreSQL链接 安装ubuntu下面: 安装客户端sudo apt-get install postgresql-client 安装服务器sudo apt-get install postgresql安装完成后，PostgreSQL服务器会自动在5432端口开启，所以如果在阿里云上部署，需要远程访问的话记得在阿里云管理界面上管理规则组中打开5432端口 创建新用户和数据库安装postgresql之后默认生成一个名为postgres的数据库和一个名为postgres的数据库用户，同时还生成了一个名为postgres的Linux系统用户，有两种方法使用shell命令行的方法 创建数据库用户创建数据库用户leslie，并指定其为超级用户1sudo -u postgres createuser --superuser leslie 如果原来是在root用户下12su - postgrescreateuser --superuser leslie_postgres3 登录数据库控制台,设置账号密码psql命令登录PostgreSQL控制台123sudo -u postgres psql #login the PostgreSQL Console\password leslie_postgres3 # enter new password 123456\q #leave the PostgreSQL Console 创建数据库123sudo -u postgres createdb -O leslie_postgres3 testdb2orsu - postgres createdb -O leslie_postgres3 testdb2 登录数据库12345psql -U dbuser -d exampledb -h 127.0.0.1 -p 5432# -U username# -d database name# -h ip# -p port 常见console命令123456789101112\h：查看SQL命令的解释，比如\h select。\?：查看psql命令列表。 # 按q返回\l：列出所有数据库。\c [database_name]：连接其他数据库。\d：列出当前数据库的所有表格。\d [table_name]：列出某一张表格的结构。\du：列出所有用户。\e：打开文本编辑器。\conninfo：列出当前数据库和连接的信息。\q: 离开console\i: 从指定的文件中读取命令 比如:\i basics.sql直接使用SQL命令操作数据库 新特性 窗口函数1SELECT depname, empno, salary, **avg(salary) OVER (PARTITION BY depname)** FROM empsalary; 功能和group by 有点类似 继承123CREATE TABLE capitals ( state char(2)) INHERITS (cities); 这样capitals表继承了cities表在cities表查询数据的时候会获得所有的数据，如果用 only cities则只会包含cities表中的数据 开发接口标准的ODBC和JDBCpython 开发接口：psycopg模块官方教程入门教程]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MPI在高性能计算中的应用]]></title>
    <url>%2F2017%2F10%2F07%2FMPI%E5%9C%A8%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[介绍MPI(Message Passing Interface)在高性能计算中(High performance calculation 下面简称为HPC)具有广泛的应用。基本的应用范式可以分为两类: 单机多进程并行计算 多机集群并行计算 MPI的实现由以下几种库： MPICH open-mpi intel-mpi 其中前两个库是开源的，intel的库不是开源的，集成在intel的MKL当中 MPI安装可以通过两种方式安装： OS的软件库安装： ubuntu 的apt-get install MAC-OS的brew install redhat的yum install 通过源码包比如下载mpich的源码包,安装过程就是一般的老三套: configure 添加编译选项生成makefile文件 make编译 make install 安装 如果有必要，将mpi/bin目录添加到环境变量 MPI 编程基本的流程可以分成3个步骤 调用MPI的API，实现代码逻辑 编译:mpic++ -std=c++11 -o 可执行文件名字 源码 运行mpiexec -n 进程数 ./可执行文件 输入参数（mpiexec基本与mpirun等价） MPI的一般代码逻辑开启MPI:123MPI_Init(NULL, NULL);MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_size);//comm_size is the number of processMPI_Comm_rank(MPI_COMM_WORLD, &amp;comm_rank);//comm_rank is the process&apos;s number 其中comm_size就是调用命令时传入的进程数量comm_rank是每个进程的标识分别从(0到comm_size-1) 逻辑块 一般的编程思路是将大量独立的计算分割成几个块，每个块分别放入到一个进程中进行并行计算，计算结束之后，在第一个进程(rank 0)中搜集各个进程的计算结果，归总判断，进行下一轮计算或者结束计算 在编程过程中可以通过comm_rank来判断当前处在哪个进程中 通过调用MPI_Barrier(comm)，其中comm为一个对象承担各个进程之间通信的任务，则会等待所有进程都执行到这一句代码，每个进程才会继续往下执行 数据的搜集:在每一轮计算之后，搜集各个进程的计算结果到rank 0中 123456789if(my_rank != 0)&#123; MPI_Send(&amp;has_change, 1, MPI_BYTE, 0, 0, comm);&#125;else&#123; bool localhas_change = false; for(int j=1;j&lt;p;j++)&#123; MPI_Recv(&amp;localhas_change, 1, MPI_BYTE, j, 0, comm, &amp;state); has_change = localhas_change | has_change; &#125;&#125; 每个进程都把各自的数据发出来，进程0搜集到每个进程发出来的数据之后，对数据进行逻辑运算 数据的广播:主要用于数据的同步，可以用在计算开始之前以及每一轮计算结束并搜集数据准备开始下一轮计算之前 1234567if(my_rank == 0)&#123; for(int k = 1; k &lt; p; k++)&#123; MPI_Send(&amp;has_change, 1, MPI_BYTE, k, 0, comm); &#125;&#125;else&#123; MPI_Recv(&amp;has_change, 1, MPI_BYTE, 0, 0, comm, &amp;state);&#125; 进程0将归纳好的数据发出来，其它进程搜集到这些数据之后进行数据的同步 结束MPI当计算结束之后，结束MPI1MPI_Finalize(); 实例代码可以参考我的github仓库，这个仓库中的serial_bellman_ford.cpp以及mpi_bellman_ford.cpp分别通过串行以及mpi并行的方式实现了Bellman-Ford算法计算单源图的最短路径。]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GDB调试程序]]></title>
    <url>%2F2017%2F09%2F25%2FGDB%2F</url>
    <content type="text"><![CDATA[介绍GDB可以用在linux shell下debug程序GDB简明教程：https://zhuanlan.zhihu.com/p/21987947https://www.jianshu.com/p/08de5cef2de9 编译程序在编译的时候手动加上-g选项1g++ -g file.cpp -o file 启动GDB环境进入GDB调试环境1gdb file #file为编译后的可执行文件 查看源码123list #查看后10行list - #查看前10行help list #查看帮助，看到可以列出指定文件指定的行，或者函数 添加断点123456789101112help break #查看帮助文档b function_nameb row_numb file_name:row_numb row_num if conditioninfo break #查看断点i b #查看断点，会返回断点的Numdisable 1 #禁用断点，Num 为info查看到的断点号d 1 #删除断点，Num 为info查看到的断点号 运行程序1234567run(r)#运行程序n #单步执行until NUM #离开循环，执行到指定的行step #跳入函数finish #离开函数quit #离开gdb环境c #跑到下一个断点 打印变量12345678910print var #打印变量默认打印var长度为200个字符show print elements查看设置无限制长度：set print elements 0watch var #监控变量info watch #查看监控的变量whatis var #查看变量类型x 虚拟地址 #查看特定虚拟地址上的值，默认一个值是4Bytesx/1sb addrhttps://blog.csdn.net/allenlinrui/article/details/5964046 打开图形化界面1wi #通过图形化界面查看debug过程更形象 查看调用栈1bt 具体列子调试C++程序，想看C++在什么时候读取的图片 直接在函数的位置打log gdb加断点写一个简单C函数打断点extern “C” my_debug() {} //用C函数，编译后符号表里面函数名方便认识，方便用b 函数名打断点mydebug() {print(__line)}my_debug() ;b my_debugbt gdb ./build/tools/caffeset args time -model ./caffe_validation_models/TrueImageModels/lmdb/default_resnet_50/deploy.prototxt –forward_only –phase TEST –iterations 100 –engine=MKLDNN 编译的时候去掉选项 -O2 -O3添加编译选项-g 查看文件中是否有O3find . -name “Makefile” | xargs grep O3查找所有makefile文件xargs命令的作用就是把每个查找到的文件送入grep 打印变量出错gdb 因为编译时的优化，在makefile里面把O2去掉或者改成O0或者makefile里面定义一个OPTIMIZATION变量OPTIMIZATION?=-O0make OPTIMIZATION=-O0 GUI工具试了下gdbgui感觉还可以(https://www.gdbgui.com/)123pip install gdbguigdbgui #start 启动之后会自动弹出来服务器的firefox(如果服务器有桌面，工具配置了X11)，也可以关闭之后，像notebook一样在命令行配置1ssh -N -f -L localhost:5000:localhost:5000 root@remoteip 在本地chrome里面启动http://localhost:5000/启动之后可以加载binary也可以attach process右上角可以debug右侧中边可以看到各个变量的值]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置https的ssl证书]]></title>
    <url>%2F2017%2F09%2F25%2F%E9%85%8D%E7%BD%AEssl%E8%AF%81%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[使用nginx配置ssl证书https://aotu.io/notes/2016/08/16/nginx-https/index.html阿里云服务器配置https://www.cnblogs.com/tianhei/p/7726505.html]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx]]></title>
    <url>%2F2017%2F09%2F25%2FNginx%2F</url>
    <content type="text"><![CDATA[介绍一些web框架入django,flask，express等内部已经集成了一些web服务器，如：web服务器与应用程序交互规范：最早出现的是 CGI，后来又出现了改进 CGI 性能的FasgCGI，Java 专用的 Servlet 规范，Python 专用的 WSGI 规范等等但是这些web服务器社和用在开发环境不适合用在生产环境。在生产环境的用法是nginx+uWSGI+web应用框架程序 其中web应用程序的框架只提供服务 uWSGI作为web程序和nginx服务器之间的桥梁 ngnix作为服务器 安装配置 下载安装nginx官网https://www.nginx.com/resources/wiki/start/topics/tutorials/install/添加repo仓库，然后安装，根据平台不同，repo仓库的配置文件有一些对应的字段需要修改http://nginx.org/en/linux_packages.html基本的安装以及入门教程http://www.itzgeek.com/how-tos/linux/centos-how-tos/install-nginx-on-centos-7-rhel-7.html ubuntu:http://wiki.ubuntu.org.cn/Nginx通过apt-get install 安装也可以通过systemctl start(stop,reload,restart) nginx来控制ngnix配置文件目录：/etc/nginxlog文件目录：/var/log/nginx自带的html目录: /usr/share/nginx/html uWSGIuWSGI的介绍：https://github.com/unbit/uwsgi 安装pip install uwsgi报错: no python.h file，https://github.com/MeetMe/newrelic-plugin-agent/issues/151先装python-devel和装 python-devel,https://stackoverflow.com/questions/23215535/how-to-install-python27-devel-on-centos-6-5先找到适合的包，yum search python | grep -i devel然后Yum install 配置快速入门教程: http://uwsgi-docs.readthedocs.io/en/latest/WSGIquickstart.html这个快速入门教程里面介绍了如何使用:1.uWSGI+web程序框架 2.ngnix+uWSGI+web程序框架（flask,djano等） ngnix最好的nginx的教程：http://openresty.org/download/agentzh-nginx-tutorials-zhcn.html 三者集成的一些文章生产环境不使用flask自带的WSGI服务器，独立配置http://knarfeh.com/2016/06/11/%E5%86%99%E7%BB%99%E6%96%B0%E6%89%8B%E7%9C%8B%E7%9A%84Flask+uwsgi+Nginx+Ubuntu%E9%83%A8%E7%BD%B2%E6%95%99%E7%A8%8B/flask官方：http://flask.pocoo.org/docs/0.12/deploying/uwsgi/入门配置nginx: https://segmentfault.com/a/1190000002411626 实例代码https://github.com/Leslie-Fang/D3Demo 仅仅使用uwsgi:uwsgi –http :5000 –manage-script-name –mount /=main:appuwsgi各个参数的含义参考的配置–http 指定端口–mount 绑定上特定的APP，其中main.py是文件名字，app是文件名中的APP的名字(app = Flask(name))–manage-script-name 经常和–mount一起使用 使用uwsgi+ngnixuwsgi:uwsgi –socket 127.0.0.1:5000 –wsgi-file main.py –callable app –processes 4 –threads 2 –stats 127.0.0.1:9191 –socket: 指定绑定的socket，在ngnix的配置中会使用到–wsgi-file： 指定web应用的入口文件–callable： 指定入口文件中的APP名字(app = Flask(name))–stats: 将uWSGI状态作为一个JSON对象导出到一个socket(http://uwsgi-docs-zh.readthedocs.io/zh_CN/latest/StatsServer.html),通过这个socket可以读取uwsgi的信息 ngnix:ubuntu的话/etc/ngnix/ngnix.conf文件在http块中添加server块： 12345678server&#123; listen 8070; server_name 0.0.0.0; location / &#123; include uwsgi_params; uwsgi_pass 127.0.0.1:5000; &#125;&#125; 解决实现负载均衡过程中的session问题 nginx使用iphash策略去分配访问流量iphash策略会将同一个ip的访问分配给同一台服务器，那么同一个用户每一次访问的session就是相同的缺点：要是再同一个用户访问期间，服务器挂了，这时候nginx会将访问分配给不同的服务器，session不一样了，用户需要重新登录 将session存在cookie里面将session存在cookie里面，但是要对cookie数据加密，不然session数据不安全优势：1.不存在session在服务器存储和同步问题 2.比如说这时候有两个web服务器，一个django写的，一个express写的，用户只要在一台服务器上登录成功，带着cookie访问另外一台服务器就自己会登录了缺点：每一次访问带的cookie数据量变大了，但是其实时间消耗也没多多少 将session存在redis里面，同时不同服务器之间的redis数据热同步redis之间共享数据也就2ms缺点：访问峰值的时候可能会很慢 第1，3个方法可以结合使用，第二个方法比较独立(leetcode就是这么实现负载均衡的) nginx 配置基础配置文档123456789101112131415server&#123; server&#123; listen 3389; server_name 0.0.0.0; error_page 404 /40x.html; location / &#123; # root /usr/share/nginx/html; index testnginx.html; &#125; location /index &#123; root /usr/share/nginx/html; index testnginx2.html; &#125; &#125;&#125; root如果不配置，就会默认使用nginx安装过程中的html目录，也就是自带的html目录: /usr/share/nginx/html,这个例子中将root配置成上述的绝对路径也是可以的 index配置：表示location后面没有带具体的资源的名字的时候(比如这个例子中第一个location的/，就符合条件，没有带上具体访问哪个资源)，则返回这个index配置的资源 server_name:如果nginx中只配置一个server域的话，则nginx是不会去进行server_name的匹配的。 第二个location，如果请求http://47.91.245.251:3389/index/，则会到/usr/share/nginx/html/index目录下面去查找，因为这个location也没有带上具体的资源，所以返回index对应的资源（这个请求和http://47.91.245.251:3389/index/testnginx2.html请求效果是一样的）]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[numpy]]></title>
    <url>%2F2017%2F09%2F24%2Fnumpy%2F</url>
    <content type="text"><![CDATA[使用ipython进行数据分析ipython有shell的接口也有web的接口官网：https://ipython.org/ipython功能:https://www.zhihu.com/question/51467397 运行：jupyter notebook –ip=0.0.0.0 –allow-root 特殊用法 Tab键自动补全 内省，变量后跟？，显示变量的信息 入门教程：https://zhuanlan.zhihu.com/p/24988491书籍：https://detail.tmall.com/item.htm?_u=om6p4lp35f6&amp;id=36838488413 生成随机数numpy各种生成随机数的函数:http://www.jianshu.com/p/214798dd8f93numpy.random.seedhttps://www.reddit.com/r/learnpython/comments/3nidns/how_to_use_numpyrandomseed/用法：numpy.random.seed(num1)生成随机数下一次再生成随机数的时候再调用一次numpy.random.seed(num1)依然生成同样的随机数如果numpy.random.seed(num2)再生成随机数就是不同的随机数 Numpy.genfromtxt从文件读取数据http://www.jianshu.com/p/82110f1dbb94 array.tolist作用:convert a NumPy array to a Python Listhttps://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.tolist.htmlb = a.tolist()重新创建a = np.array(b) 广播法则处理不同维度的矩阵之间的运算https://ptorch.com/news/38.html 从文件读取数据np.genfromtxt(filename)http://www.jianshu.com/p/82110f1dbb94]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker]]></title>
    <url>%2F2017%2F09%2F21%2Fdocker%2F</url>
    <content type="text"><![CDATA[基本概念 docker daemon image container network label:https://docs.docker.com/engine/userguide/labels-custom-metadata/ storage driver:http://dockone.io/article/1765 volumes 安装centos上面用这个区安装https://docs.docker.com/install/linux/docker-ce/centos/ 像Suse这样的OS找不到镜像的话，可以直接下载二进制包去安装https://docs.docker.com/install/linux/docker-ce/binaries/参考docker-ce 里面的Binaries下面的方法安装之后，follow这个链接的最下面去创建systemd的配置项https://docs.docker.com/config/daemon/systemd/#httphttps-proxy 常用命令 docker ps: 查看正在运行的container 通过dockerfile去定义image： https://docs.docker.com/get-started/part2/#apppy dockerbuild 利用dockerfile去生成image docker build -t friendlyhello . (friendlyhello 镜像名)important: 在dockerfile里面用pip去安装包的时候也需要配置代理 docker images 查看有没有生成镜像 docker run -p 4000:80 friendlyhello (-p 4000:80 把container的80端口映射到 主机的4000端口)docker run -d -p 4000:80 friendlyhello（-d 参数表示运行在后台，in detached mode） attach a containerdocker attach container_name这样就会进入contaienr内部要deattach这个container，Ctrl+P+Q docker container ls(只显示activate的container)查看所有的container: docker container ls -a查看到container id 停止正在运行的containerdocker stop container_id在容器内部直接exit 删除containerdocker rm container_id 删除imagedocker image rm image_id（必须要保证这个image没有container在使用） copy文件docker copy * #copy文件 常用的一系列用法下载好image以后docker run -tid imagenamedocker container lsdocker attach container-id #进入容器host上docker cp等进行修改docker commit container-id new-name #保存成新的镜像 Error messgae:commit的时候看到error messageError response from daemon: Error processing tar file(exit status 1): unexpected EOF看dockerd的日志，是zip文件不能保存 docker save -o update1.tar update //镜像的导出docker load &lt; update1.tar //镜像的导入 删除文件,减小镜像大小在container中删除文件之后，再commit发现镜像大小不变是因为docker commit会保留原来的layer的信息 用exportdocker export container_id &gt; name_tag.tar再次导入docker import name_tag.tar name:tag 无法使用numa的问题 docker run -itd –privileged image–privileged可以给container权限推荐用这个方法 方法二docker run -itd –cap-add=SYS_NICE image当方法1的performance掉了的话，用这个方法试试看 代理设置为docker-run设置代理https://docs.docker.com/config/daemon/systemd/#httphttps-proxy 为docker容器本身设置代理和普通OS一样直接设置代理，试过可以工作export http_proxy=http://***export https_proxy=https://*** 在启动container的时候可以添加参数https://docs.docker.com/network/proxy/ http://www.vadmin-land.com/2018/09/using-docker-behind-a-proxy/ 设置docker的工作目录1vi /etc/docker/daemon.json And add the following to tell docker to put all its files in this folder, e.g:1234&#123; &quot;graph&quot;:&quot;/workspace&quot;&#125;systemctl restart docker 之后 docker的工作目录就到了/workspace的目录下面 镜像目录/workspace/docker_data/images container目录/workspace/docker_data/containers/ 数据存储/workspace/docker_data/volumes 管理命令docker volume ls docker volume rm volume_name 指定volume的挂载位置指定挂在位置docker run -itd -v /data/:/data1 centos bash // -v 用来指定挂载目录,-v的格式为: 上传镜像docker login位image添加标签 docker tag image username/repository:tagdocker tag test1 lesliefang/get-started:v.0 docker image ls会看到这个lesliefang/get-started:v.0 image 上传docker push username/repository:tag登录docker hub 可以看到相关的信息 ## 创建services:scale our application by running this container in a service用service可以实现负载均衡一个service其实就是定义了一个镜像如何跑（运行在哪个端口，跑多少个container）用docker-compose.yml文件去定义: 创建完compose文件之后 docker swarm init（多张网卡的话：docker swarm init –advertise-addr 10.239.182.67） docker stack deploy -c docker-compose.yml appname(自己定义一个名字) 查看正在运行的servicedocker service ls 查看每个容器进程的process iddocker service ps service_id docker inspect container_name(通过docker container ls可以查看) docker inspect –format{} container_name 来限制输出的内容 scale利用swarm进行伸缩 直接修改docker-compose.yml文件中的replicas的个数然后重启docker： docker stack deploy -c docker-compose.yml appname不需要停止原来的app，热更新 停止stackdocker stack rm appname 删除了service，但是container还在docker swarm leave –force 删除container Swarms:多台机器(实体机或者虚拟机)有一台机器作为swarm manager,所有的命令都在swarm manager上运行Swarm managers are the only machines in a swarm that can execute your commands, or authorize other machines to join the swarm as workers. Workers are just there to provide capacity and do not have the authority to tell any other machine what it can and cannot do. 在swarm manager上运行docker swarm init（多张网卡的话：docker * swarm init –advertise-addr 10.239.182.67）使能swarm模式。在其它节点的机器上面运行docker swarm join使其它机器加入swarm作为workersdocker swarm init 会返回告诉你docker swarm join的命令里面的token怎么敲 在其它机器上运行docker swarm join，让其它机器加入如果没办法加入，首先确保关闭manager的防火墙：http://www.jianshu.com/p/3ab849248b52 docker的各个端口的作用：https://www.digitalocean.com/community/tutorials/how-to-configure-the-linux-firewall-for-docker-swarm-on-centos-7 在公司电脑上是有可能是代理的问题：https://github.com/moby/moby/issues/34825 在/etc/systemd/system/docker.service.d/[Service]Environment=”http_proxy=http://child-prc.intel.com:913“ “NO_PROXY=localhost,127.0.0.1,10.239.182.67”把manager的地址添加到no_proxy里面 在manager上运行docker node ls查看机器个数 stack:A stack is a group of interrelated services that share dependencies, and can be orchestrated and scaled together. 在docker-compose.yml文件的services的tag下面再去定义一个service多个service一起部署 Kubernetes作用和docker swarm类似（解决容器编排问题），但是比swarm更强大 基本概念 pod：容器的集合，一个pod可以包含一个或多个container。一个pod内运行相同业务的容器，一个pod只能运行在一台机器上 replicateion controller(rc) 管理pod，保证任何时间有特定数量的pod在运行，多了删除pod，少了创建pod service：将pod提供的服务暴露到外网 label： 用于区分 pod,rc,service的key/value pair kubectl: 命令行,调用kubernetes的API Kubernetes master: 运行在主节点上，收集三个进程的信息：: kube-apiserver, kube-controller-manager and kube-scheduler 其它非主节点运行两个进程：kubelet(与主节点通信), kube-proxy(网络代理，反映了各个节点的kubernetes的网络状况) Kubernetes Control Planek8s里面所有组件都叫做对象，Kubernetes Control Plane在任意时间都会监测这些对象，保证对象的数量和目标状态 etcd 是 CoreOS 团队发起的一个管理配置信息和服务发现（service discovery）的项目http://www.infoq.com/cn/articles/coreos-analyse-etcd install我们是在cluster上装：https://kubernetes.io/docs/getting-started-guides/centos/centos_manual_config/这个文档不能用了，有错问题1：当前k8s还不支持docker17版本需要用docker1.12版本，https://stackoverflow.com/questions/44891775/kubernetes-installation-on-centos7 所以需要首先卸载docker17版本，直接用k8s的安装手册，上面会安装合适版本的docker老版本的docker的命令和新版本不太一样 现在推荐用kubeadm去enable，过程和swarm有点像https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/http://tonybai.com/2016/12/30/install-kubernetes-on-ubuntu-with-kubeadm/ 比较容器调度方案docker swarm VS k8shttp://dockone.io/article/1138http://www.jianshu.com/p/07daa3a16878]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习知识点]]></title>
    <url>%2F2017%2F09%2F13%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[玻尔兹曼机 过拟合：偏差很小，但方差很大（所以欠拟合叫做高偏差，过拟合叫做高方差）训练数据太少，模型参数太多解决方法：1. 剔除不必要的模型参数 2. 使用正则化（regularizaion），保留模型参数，但是减小模型参数的数量级（对某些参数，在loss函数中添加惩罚项） L2正则项解决过拟合的问题https://www.zhihu.com/question/20924039 交叉验证https://baike.baidu.com/item/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81将数据集分成多个多个小的数据集，先用小数据集1训练，用小数据集2验证（评估正则化函数），直到最后一个小的数据集被用于验证 极大似然估计http://www.jianshu.com/p/f1d3906e4a3e 激活函数在神经网络中引入非线性的成分sigmod：0，1之间tanh：-1，1之间softmax: 多分类，一般用在输出层的激活 epoch、 iteration和batchsizehttp://blog.csdn.net/sinat_30071459/article/details/50721565 交叉熵https://zhuanlan.zhihu.com/p/27223959在机器学习中，可以用交叉熵来定义loss function BP神经网络反向传播计算——BackPropagation单个参数：http://www.cnblogs.com/charlotte77/p/5629865.html矩阵计算：http://www.jeyzhang.com/cnn-learning-notes-2.html 卷积神经网络CNN局部连接，参数共享，卷积，池化等概念介绍：http://www.jeyzhang.com/cnn-learning-notes-1.html模型训练：http://www.jeyzhang.com/cnn-learning-notes-2.html 局部对比归一化Local contrast normalizationhttp://blog.csdn.net/zouxy09/article/details/10007237 batch normalizationhttp://blog.csdn.net/hjimce/article/details/50866313http://minibatch.net/2017/06/11/%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87-Batch-Normalization/https://zhuanlan.zhihu.com/p/26682707反向计算梯度：http://mlnote.com/2016/12/20/Neural-Network-Batch-Normalization-and-Caffe-Code/ Good:https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html 白化http://blog.csdn.net/hjimce/article/details/50864602http://blog.csdn.net/whiteinblue/article/details/36171233]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[crontab]]></title>
    <url>%2F2017%2F09%2F10%2Fcrontab%2F</url>
    <content type="text"><![CDATA[介绍crontab常用来周期性的执行命令。 启动service cron(crond) status //ubuntu 和centos有不同 service cron(crond) start(restart,reload) //如果没有启动，启动一下 用法查看crontab命令：-l``` :系统级配置的任务好像无法通过crontab -l 来查看12编辑crontab命令:```crontab -e 移除crontab命令:-r```12345### 修改配置文件系统级配置:在/etc/crontab 文件中编辑用户级配置:用特定用户登录，在命令行中配置命令，是配置和用户相关的```crontab -e 将命令写入文件中，然后直接crontab filename来读取文件中的所有命令 配置文件的写法： 周期性定时执行 分 小时 日 月 星期 命令 0-59 0-23 1-31 1-12 0-6 command (取值范围,0表示周日一般一行对应一个任务) 日中有数字，表示的每个月到这一日都会执行月中有数字，表示每年到这个月都会执行星期中有数组，表示每周到这一天都会执行 在特定时候执行 @reboot commandsuch as：@reboot root /bin/bash /test.sh debug查看/var/log/cron文件]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建和发布npm包]]></title>
    <url>%2F2017%2F08%2F05%2F%E5%88%9B%E5%BB%BA%E5%92%8C%E5%8F%91%E5%B8%83npm%E5%8C%85%2F</url>
    <content type="text"><![CDATA[创建包123//在初始化话时我们定义了module的入口文件是index.js//在初始化的时候输入的package的名字就是后面npm install时的名字，后面也可以再package.json里面修改npm init 在index.js中定义需要export出来的函数 发布包新用户,先去npm的网站注册 12345678//输入注册npm时的账号密码以及邮箱npm adduser//查看信息npm config ls//发布npm publish 更新包修改的原有的包的代码之后不可以直接publish的已有的仓库和版本当中,会提示我们没有权限复写已经publish的包这时候需要修改package.json里面包的版本号 在已经依赖于这个的包的用户这边1npm update 可以将使用的包更新的最新 包的使用需要使用这个package的时候1npm install pkg-name --save(--save-dev) 删除已经发布的包1npm unpublish [&lt;@scope&gt;/]&lt;pkg&gt;[@&lt;version&gt;] 在Git上维护自己的包新建一个主分支和一个开发分支每一部分开发完成开一个版本分支，将版本的分支publish到npm上面 在develop分支上进行开发，开发完成切换到对应的版本的备选分支，review备选分支的代码，没有问题的话merge的备选分支里面修改package.json里面的版本号，上传到git以及发布到npm切回到develop分支进行新的开发]]></content>
      <tags>
        <tag>技术 Node.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于express和reactjs开发的web框架]]></title>
    <url>%2F2017%2F07%2F23%2F%E5%9F%BA%E4%BA%8Eexpress%E5%92%8Creactjs%E5%BC%80%E5%8F%91%E7%9A%84web%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[前几个月基于express和reactjs写过几个简单的web应用，现在回过头来看很多代码都想不起来了。这周利用下班时间重新将这个框架梳理了一下，并写下这篇文章作为基于这两个框架开发web应用的BKM。 使用到的主要工具介绍 Express：基于nodejs的后端框架 Reactjs+Redux：前端框架，React更多的是扮演着MVC中的view的角色，Model以及Control类似的功能可以用flux或者更进一步用Redux来实现，链接 里面的图片将redux和reactjs之间的关系描述的很清楚 Babel：转换ES6以及JSX的语法到ES5，commonJS Webpack: 浏览器不支持commonJS，因此需要通过webpack打包之后，才可以将js嵌入到html当中，当然经过webpack之后在生产环境中最好再用gulp经过一次uglify，可以减小js文件的大小 Gulp：前端开发自动化的利器，在开发过程中可以监听文件的变化重启服务器 数据库：目前使用MySQL存储用户信息，使用Redis存储session的hotdata。下一步可以把mongodb的接口移植过来。 框架实现的基础功能这是个基础框架，不涉及任何的业务逻辑。在这个框架的基础上可以根据实际需求，开发主页面和相关的业务逻辑。 注册和登入功能：使用bcrypt模块对密码进行加密，用户名和密码存储在MySQL里面进行用户信息的验证。验证通过、用户登入之后在cookie中设置session id对应的session数据，并将session的用户热点数据储存在Redis里面。 登出功能：通过销毁和重新建立session，来实现用户的登出功能。redis的session数据可以再redis里面设置数据自动销毁的超时时间。当然cookie中的session id也可以通过设置cookie的超时销毁时间来实现。 用户登入状态控制：用户的每一次访问根据cookie中的session id进行用户登录状态的控制，未登录用户无法看到定制的信息。 业务逻辑：根据业务需求在main页面中进行业务逻辑的开发 Reactjs + Redux的前端框架介绍框架的介绍这里介绍一下我在写这个框架的时候的一些BKM： 一般在javascript目录下面建立三个目录：一个react目录，是开发的前端代码；一个babel目录：是将react目录下代码经过babel转译之后得到的代码;一个webpack目录：是将babel目录下需要嵌入在html中的代码打包之后的代码。 其中只在react目录下开发我们的代码：react的根目录下面：有一个store.js文件，这个是在redux中存储应用状态和数据的。除了store.js之外的文件都是component文件，就是html页面的显示元件，component文件可以通过container目录下面的各个container文件包含的模块化的组件拼凑出来，因此我们说reactjs很好的做到了前端组件的模块化和复用。 react目录下面的container目录包含了就是前端模块化的组件。react目录下面的action目录下的代码功能类似于MVC模型中的control，就是一些前端的触发函数，在这些函数被执行之后可以dispatch一些action，reducer就在监听这些action，并获得action的返回数据 react目录下面的reducer目录下的代码，就在监听action目录下代码派发的action，一旦监听到对应的代码，就可以触发页面跳转或者返回状态数据到store当中，这些数据通过store和container绑定的，就会触发container中对应的数据的更新。每一个reducer的作用就是传入上一次的state和action，输出这一次的新的state的对象。export var logout = function(state = {logout:null},action)，这里面state = {logout:null}，只有当第一次调用到的时候才会有{logout:null}，以后每一次调用到都会输入上一次的state对象。 一些常见的问题react：component的名字要大写开头redux： reducer下面每个case里面返回的对象每一次都需要新建，可以用object.assign(用在单个对象添加属性可以返回新的对象)，用filter也会新建对象(可以用在数组上面)，redux如何获取服务器端数据库的数据，在action里面写restful的请求给服务器端，需要配置多个action，一个action1发送请求，在action1获得请求的数据处理中dispatch一个数据完成的action 使用redux实现撤销undo和再做redo功能基本的思想，就是在原有的reducer的基础上，新建一个高阶的reducer（什么是高阶：就是指函数返回的值也是函数）参考这部分代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364export var saveCurrentCommentState = function(state = &#123;currentComment:null&#125;,action)&#123; switch (action.type) &#123; case &apos;SAVE_COMMENT&apos;: console.log(&apos;return the saveCurrentComment&apos;,state, &apos;and action&apos;, action); //console.log(action.payload.username); //console.log(Object.assign(&#123;&#125;,state,&#123;username:action.payload.username&#125;)); return Object.assign(&#123;&#125;,state,&#123;currentComment:action.payload.comment&#125;); default: console.log(&apos;return the defalut saveCurrentComment&apos;,state, &apos;and action&apos;, action); return Object.assign(&#123;&#125;,state); &#125;&#125;;var highOrdersaveCurrentCommentState = function(reducer)&#123;//for pastComment currentComment and futureComment: each one is a state or state array const initialState = &#123; pastComment: [], currentComment: reducer(&#123;currentComment:null&#125;, &#123;&#125;), futureComment: [] &#125;; return function (state = initialState, action) &#123; const &#123; pastComment, currentComment, futureComment &#125; = state; switch (action.type) &#123; case &apos;UNDO_COMMENT&apos;: console.log(&apos;return the highOrdersaveCurrentCommentState&apos;, state, &apos;and action&apos;, action); //console.log(action.payload.username); //console.log(Object.assign(&#123;&#125;,state,&#123;username:action.payload.username&#125;)); const newpastComment = pastComment.slice(0, pastComment.length - 1); const previousComment = pastComment[pastComment.length - 1]; futureComment.push(currentComment); console.log(&quot;=========&gt;&quot;); console.log(previousComment); return &#123; pastComment: newpastComment, currentComment: previousComment, futureComment: futureComment &#125;; //return Object.assign(&#123;&#125;, state, &#123;comment: action.payload.comment&#125;); case &apos;REDO_COMMENT&apos;: console.log(&apos;return the highOrdersaveCurrentCommentState&apos;, state, &apos;and action&apos;, action); pastComment.push(currentComment); const nextComment = futureComment[futureComment.length - 1]; const newfutureComment = futureComment.slice(0, futureComment.length - 1); return &#123; pastComment: pastComment, currentComment: nextComment, futureComment: newfutureComment &#125;; default: console.log(&apos;return the defalut highOrdersaveCurrentCommentState&apos;, state, &apos;and action&apos;, action); const newcurrentComment = reducer(currentComment, action); if (newcurrentComment === currentComment) &#123; return state &#125; pastComment.push(currentComment); return &#123; pastComment: pastComment, currentComment: newcurrentComment, futureComment: [] &#125; &#125; &#125;&#125;;export var undoRedoCommentState = highOrdersaveCurrentCommentState(saveCurrentCommentState); 其中saveCurrentCommentState这个reducer是一个基本的reducer，每一次正常的状态更新都会触发这个reducer来更新对应的状态定义一个高阶函数highOrdersaveCurrentCommentState，这个函数传入的参数是一个reducer(In)，返回的也是一个reducer(Out)。定义一个新的reducer，undoRedoCommentState，这个reducer就是通过调用 highOrdersaveCurrentCommentState(saveCurrentCommentState)得到的返回的reducer。redo和undo的功能都是在这个highOrdersaveCurrentCommentState高阶函数里面实现的，我们现在来看看这个函数里面实现了什么。这个函数只在初始化的时候被调用了一次，首先定义reducer(Out)的初始化的initialState ，并传入到返回的reducer中。在返回的这个reducer中： 如果没有监测到undo或者redo的action，就会触发default的操作，在default操作中会先调用saveCurrentCommentState这个基本的reducer看看是否有正常的状态转移（也就是判断一下是不是状态转移的action触发的，还是和当前的reducer没有半毛钱关系的action触发的），如果是正常的状态转移，那么当前的state加入到past里面，更新当前的state。 如果监测到undo的action，就会把当前的state放入到future中，从past里面取一个state出来放到当前的state里面 如果监测到redo的action，就把当前的state放入到past里面，从future里面取状态回来。 主要的实现逻辑就是这些。当然在这部分代码里面还可以进一步添加，undo的时候是不是past里面存有过去的状态（即是不是完全popout的），redo的时候也需要看看future里面的状态是不是完全popout的。 代码的链接github托管的代码的链接地址其中相对于master分支，develop分支实现了用户数据在session中的储存，用户的登出功能。 下一步开发计划 用户登入部分改成https的请求]]></content>
      <tags>
        <tag>技术 web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python调用命令行脚本]]></title>
    <url>%2F2017%2F07%2F19%2Fpython%E8%B0%83%E7%94%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[阻塞态调用和非阻塞态调用，这两个名字是自己根据调用的特点给区分的。两者主要的区别在于是否会另外开辟一个子进程去调用这些命令行的脚本。在所谓的阻塞态调用下，python会等待这个脚本执行完毕再顺序往下执行其它的程序。在所谓的非阻塞态调用下，python则会开辟一个子进程，将脚本放在子进程里面执行，自己则立刻向下运行。 阻塞态调用使用os模块，主要涉及到popen和system两种方法。这两种方法的区别参考一下链接os.system(cmd) 返回的是程序运行的结果状态，比如程序运行成功，则返回0，有错误则返回其对应的错误代码os.popen(cmd) 返回的是程序输出的结果，比如cmd=“ls”的时候，通过popen就可以得到ls的结果 123cmd = &quot;echo hello wolrd&quot;ret = os.popen(cmd)information = os.system(cmd) 非阻塞态调用非阻塞态调用主要用到了subprocess 这个模块简单的用法就用subprocess.call(cmd)就可以了更高级复杂的用法可以使用subprocess.popen(cmd)比如说有时候因为环境变量的配置我们需要在特点的目录下执行脚本，就可以使用subprocess.popen的cwd参数,要配置环境变量而不是继承原有的环境变量可以使用env参数123workingDirector = r&quot;C:/testcode&quot;cmd = r&quot;test.bat&quot;subprocess.popen(cmd,cwd=workingDirector)]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卷积神经网络（CNN）]]></title>
    <url>%2F2017%2F07%2F15%2F%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[介绍 卷积核： 用来和图像做卷积运算的小矩阵 stride 步长：每一次卷积运算之后，卷积核沿着图像移动的像素点的长度 Padding： 在图像边沿位置做卷积运算时，需要补充的像素点，一般像素点值补0就可以 步骤 图像卷积（将特征值平均化，提取特征值）,根据需要 可以/不 将图像padding补0，定义一个需要的卷积核(如果定义多个不同的卷积核，每一个卷积核可以对应于一个图像的通道(ex. rgb/hsv 三个通道)，卷积和池化之后就可以得到不同的通道对应的新的图像 池化（降采样，减少图像运算的像素点的个数），con-max-pooling 就是取一片区域当中的最大值，对每一个通道都进行池化操作1，2步骤可以重复多次最后将图像的每一个通道都flattern（展开成一维数组），每一个通道都作为一个输入量，输入到全连接的前馈神经网络中进行训练（一般在网络中会对不同通道的值进行融合） CNN用于手写数字识别整个项目的框架如下图所示：通过摄像头捕获手写数字，输入到计算机中，运行手写数字算法，将识别结果通过无线设备发送到智能硬件算法的框图入如下图所示整个神经网络共包含了5层（除去第一层输入层）其中包含了二层卷积层、一层全连接层、一层dropout层以及一层的输出层在每一层的卷积层中，每一个卷积操作，定义stride为1，Padding补充为0；每一个池化操作，都使用2x2的矩阵块中取出最大值 第一层神经网络第一个卷积层定义了32个通道（对应了32个卷积核），每一个卷积核是5x5的矩阵块1234# First convolutional layer - maps one grayscale image to 32 feature maps.W_conv1 = weight_variable([5, 5, 1, 32])b_conv1 = bias_variable([32])h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) 其中weight_variable([5, 5, 1, 32])前两个参数对应了卷积核的大小，第三个参数是输入的通道数(原始为灰度图像1个通道)，第四个参数为输出的通道数最后用卷积后的结果作为relu神经元的构造函数，神经元里面定义了对应的激活函数 第一个池化层1h_pool1 = max_pool_2x2(h_conv1) 第一个卷积层输出为32个通道，每一个通道的图像是28x28经过一个2x2的池化层之后，输出的每一个通道的图像是14x14 第二层神经网络第二个卷积层定义了64个通道（对应了64个卷积核），每一个卷积核是5x5的矩阵块123W_conv2 = weight_variable([5, 5, 32, 64])b_conv2 = bias_variable([64])h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) 输入为32个通道每个通道为14x14的图像经过卷积运算，输出为64个通道每个通道14x14的图像1h_pool2 = max_pool_2x2(h_conv2) 第二个池化层输入为64个通道每个通道14x14的图像输出为64个通道每个通道7x7的图像 第三层神经网络经过前两层已经完成了卷积运算，特征提取和降维第三层叫做全连接层fully connected layer 也叫做 Densely Connected Layer第二层的输出为64通道，每个通道为7x7的图像所以先将第二层的输出flattern1h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64]) 第三层我们定了了1024个神经元所以做乘法需要1024（77*64）个权重的参数以及1024个bias偏差量1234W_fc1 = weight_variable([7 * 7 * 64, 1024])b_fc1 = bias_variable([1024])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) 最后构造成relu神经元 Dropout层为了避免过拟合添加了Dropout层dropout的概念：就是在训练时，对每一批次的训练数据，关闭部分神经元，这样每一批次的数据只训练了部分神经元的参数，最后把这些参数累加并乘以一个系数得到训练后模型的参数12keep_prob = tf.placeholder(tf.float32)h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) 通过keep_prob参数来控制需要关闭的神经元的比例 输出层经过第三层之后输出为1024shape的数据我们希望得到的属于10个数据的证据，可以将证据转为为概率所以这一层的输出为10维的向量1234W_fc2 = weight_variable([1024, 10])b_fc2 = bias_variable([10])y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2 代码链接最后附上训练好的模型、图像预处理代码以及测试集的下载地址 资料http://www.jeyzhang.com/cnn-learning-notes-1.htmlhttp://www.jeyzhang.com/cnn-learning-notes-2.html]]></content>
      <tags>
        <tag>技术 深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手写数字识别]]></title>
    <url>%2F2017%2F07%2F06%2F%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[前言这几日，作息回到了早睡早醒，每天就花些时间去读书、去摄影、去锻炼以及做那些在WaitingList里躺了很久的有趣的事。老板出差在美国，工作显得并不是那么忙碌，就在每天下班后抽出几个小时的时间去做了个手写数字识别的项目。主要涉及的技术包括了：机器视觉、深度学习（人工神经网络），当然相关的编程语言也是不可少的。 深度学习就像hello world是每一个码农写的第一行代码，手写数字识别也是每一个想进入人工智能领域的人必上的第一课。深度学习的框架很多，比如我司的caffe，但是由于最近实在对C++无感，所以本文采用了tensorflow，这个google大法开源的python框架。如果官网访问有难度，请自觉科学上网。训练的数据集来自Yann LeCun’s website训练模型我采用了最简单的softmax，因为急于先将整个流程走通，这个模型最后的测试集合的识别率只有92%。很槽糕，对不对，但是没关系以后还可以慢慢优化，:)希望可以说到做到。训练过程用了梯度下降法去优化模型参数，大约300圈，识别率就打到了90%左右，后面的迭代基本就是不断的出现过拟合和修正过拟合问题。在训练结束之后可以保存训练模型：123saver = tf.train.Saver()save_path = &quot;./model/model.ckpt&quot;saver.save(sess, save_path) 以后在inference阶段，就可以直接提出这个模型和训练好的参数123saver = tf.train.Saver([W, b])sess = tf.Session()saver.restore(sess, &quot;./model/model.ckpt&quot;) 有没有觉得这个过程很简单，哈哈，那是因为我对这个算法也是一知半解，也失去了少年时推导出数学公式时的欣喜。 图形预处理事实上，更多的时间花会花在inference阶段如何对识别到的图形进行预处理上面。机器视觉最主要的一个问题在于算法的通用性上，因为视觉受环境的影响很大，不同光照环境中得到的图片差别就像隔了一条银河。所以你会发现在自动驾驶领域，总会集成视觉、激光雷达、IMU等多种类型的传感器(ps.多元传感器信息融合是我的老本行，哈哈，爸爸就是靠这个硕士毕业的)。所以在拍摄到每一张图片以后就需要对图片进行预处理和特征的提取，这里只罗列了关键的步骤，详细的代码请参考附录我的git的仓库。 拍摄得到原始彩色图片 做一次5阶的gauss平滑 转换成灰度图像 二值化，二值化的阈值要考实验，当然参数不好后面也有一步去补救 对二值化后的图片进行腐蚀和膨胀，主要是去除噪点让图像看起来比较饱满 用canny算子提取ROI(region of interest 不知道中文怎么说，感兴趣的区域？)的轮廓 找到ROI的外接矩形 裁剪出ROI的subImage resize 这个subImage倒特定的像素点（因为训练模型需要固定像素点的输入图形） 最后再对这张图做一次膨胀和腐蚀（注意顺序和前面不一样哦，哈哈，想知道为什么请自行谷歌） 最后将这张图形输入inference，模型就可以告诉你你到底写的是什么鸟语了 TensorBoard图形化展示在模型的最后添加一行代码保存模型图到文件，这里保存到了当前.路径下面1file_writer = tf.summary.FileWriter(&apos;.&apos;, sess.graph) 之后只需要在对应的路径(这里为当前路径)下运行1tensorboard --logdir . 之后就可以显示出图形化展示的URL地址。ex.http://192.168.1.6:6006直接访问以上地址就可以读取训练模型相关的图形化的显示,详细的资料可以参考一下链接 下一步计划 搭建更好的训练模型 改善预处理的算法 做一块智能硬件，和电脑端无线通讯，在电脑端得到识别结果之后，发给硬件板子，板子可以触发对应的动作，比如说控制无人机的姿态，想不出来其它点子，有点累了，脑洞变小了。 附录最后附上训练好的模型、图像预处理代码以及测试集的下载地址]]></content>
      <tags>
        <tag>技术 深度学习 图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python类与继承]]></title>
    <url>%2F2017%2F06%2F27%2FPython%E7%B1%BB%E4%B8%8E%E7%BB%A7%E6%89%BF%2F</url>
    <content type="text"><![CDATA[类变量与实例变量看这个例子因为当用self.var去call一个变量的时候的顺序是实例的dict-&gt;类的dict-&gt;基类也就是如果再实例里面找到这个变量相同的名字，就用实例的变量，没有找到就去找类变量，再没有找到就会找基类的变量，最后还没有找到就会报错类变量还可以用 类名.变量名去调用实例变量只可以用self.变量名 类的实例方法，静态方法与类方法参考这个链接 实例方法形式：class A(object):def function(self,var1):最常见的方法包括了init等函数 类方法用@classmethod修饰，需要传入一个非self参数，这个参数的名字常写作cls或者cls_obj(也可以是其它名字，不是self), 可以被实例调用也可以被对象调用 1234567891011121314class Person(object): num = 0 def __init__(self,name): self.name=name Person.num +=1 @classmethod def get_nomber_of_instance(cls): return cls.numif __name__ == &quot;__main__&quot;: print(&quot;hello world&quot;) a = Person(&quot;bob&quot;) b = Person(&quot;bob2&quot;) print(Person.get_nomber_of_instance()) print(a.get_nomber_of_instance()) 这样的好处是在类的内部，通过第一个参数cls把类传递出来 静态方法用@staticmethod修饰，它的适用场景决定了它一般不需要传入参数(self也不需要传入)12345678910111213141516171819202122232425#needPrintName = &quot;no&quot; #yes or noneedPrintName = &quot;yes&quot;class Person(object): num = 0 def __init__(self,name): self.name=name Person.num +=1 def printName(self): if self.needPrintName(): print(self.name) else: print(&quot;Doesn&apos;t need to print name&quot;) @classmethod def get_nomber_of_instance(cls): return cls.num @staticmethod def needPrintName(): return needPrintName==&quot;yes&quot;if __name__ == &quot;__main__&quot;: print(&quot;hello world&quot;) a = Person(&quot;bob&quot;) b = Person(&quot;bob2&quot;) print(Person.get_nomber_of_instance()) print(a.get_nomber_of_instance()) a.printName() 这样的好处是，有一些方法和类的功能相关，但是又不需要类或者对象本身去参与 类的继承最基础的类就是objectclass child_class(base_class):注意点： 派生类不会自动调用基类的init方法，需要在派生类的init函数里面去调用，base_class.init(self) 调用基类的方法的时候，需要加上基类的类名前缀，而且调用基类的函数记得带上self 总是先在本类中找方法，找不到再去基类里面找（派生类的方法会覆盖基类的方法）123456789101112131415161718192021222324class Person(object): num = 0 def __init__(self,name): self.name=name Person.num +=1 def printName(self): print(self.name) @classmethod def get_nomber_of_instance(cls): return cls.numclass Student(Person): def __init__(self,name,score): Person.__init__(self,name) self.score=scoreif __name__ == &quot;__main__&quot;: print(&quot;hello world&quot;) a = Person(&quot;bob&quot;) b = Person(&quot;bob2&quot;) print(Person.get_nomber_of_instance()) print(a.get_nomber_of_instance()) a.printName() b.printName() c = Student(&quot;bob3&quot;,100) c.printName() 如果基类继承了object类，还可以用super去调用基类的方法推荐这种写法super(chrild_class,self)._init__(arg)(这里的arg不写self)，因为原来直接call基类的init函数存在这样的一种例外的情况1234567891011121314151617181920212223242526import sysclass Person(object): num = 0 def __init__(self,name): self.name=name Person.num +=1 def printName(self): print(self.name) @classmethod def get_nomber_of_instance(cls): return cls.numclass Student(Person): def __init__(self,name,score): super(self.__class__,self).__init__(name) self.score=scoreif __name__ == &quot;__main__&quot;: print(&apos;all argv:&#123;&#125;&apos;.format(sys.argv)) print(len(sys.argv)) a = Person(&quot;bob&quot;) b = Person(&quot;bob2&quot;) print(Person.get_nomber_of_instance()) print(a.get_nomber_of_instance()) a.printName() b.printName() c = Student(&quot;bob3&quot;,100) c.printName() 备注 获取对象的类 ins_obj.class.method(var)123456789101112def howperson(a): return a.__class__.numclass Person(object): num = 0 def __init__(self,name): self.name=name Person.num +=1if __name__ == &quot;__main__&quot;: print(&quot;hello world&quot;) a = Person(&quot;bob&quot;) b = Person(&quot;bob2&quot;) print(howperson(a))]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash学习笔记]]></title>
    <url>%2F2017%2F06%2F12%2Fbash%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[diffdiff 用于比较两个文件（也可以用于目录）的差别1diff file_1_1.txt file_1_2.txt 常规模式输出： a为后一个文件比前一个文件多的行 d为后一个文件比前一个文件少的行 c为两个文件不一样的行 1diff file_1_1.txt file_1_2.txt -y 比较模式输出：按每一行对比两个文件 vim查找字符串输入查找在命令模式下输入 ？或者/然后输入要查找的单词按回车开始查找，按n查找下一个(上一个)单词N与n的反方向进行搜索 根据光标位置的单词查找在光标位置的单词按*或者#按n查找下一个(上一个)单词，N与n的反方向进行搜索 后台运行Mthod1: ./cycle.sh 200 chassis31_6 AC 2&gt;&amp;1|tee chassis31_6.log &amp;在命令的最后加一个&amp;，表示希望这个命令在后台运行Method2: 使用screen $?$? 表示上一个进程或者函数运行之后的返回值在写bash函数的时候，函数里面return返回值在调用这个函数之后再调用一次 $? 表示读取一次返回值，注意$?只能用一次 重定向&gt; /dev/null 2&gt;&amp;1命令 &gt; /dev/null 2&gt;&amp;1命令 1&gt; /dev/null 2&gt;&amp;1两条都不会输出任何东西，表示将错误定向到标准输出，又将标准输出定向到null这里的&amp;表示后面的1是文件描述符（标准输出），并不是文件名 运行脚本`` `command`键盘最左上角的字符，也就是markdown里面的代码的符号表示运行``之间的command grep匹配行首grep &quot;^${group}&quot; local.cfg | awk -F: &#39;{print $2}&#39;^表示匹配行首 匹配正则表达式 =~[[ $phrase =~ $keyword ]]正则表达式 bash数组申明：declare -a arr12341. $&#123;arr[*]&#125; # All of the items in the array2. $&#123;!arr[*]&#125; # All of the indexes in the array3. $&#123;#arr[*]&#125; # Number of items in the array4. $&#123;#arr[0]&#125; # Length of item zero 构造数组arr=(element1 element2 … element3) 为数组添加新的元素arr=(${arr[@]} elementNew)for example: chassisarr=(${chassisarr[@]} $group)意思是，取出原有数组中的所有元素加上新元素赋值回数组 Top命令http://www.cnblogs.com/peida/archive/2012/12/24/2831353.html 查看进程包含的线程的信息首先top看到进程的pid然后:top -p PID -Hd1]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[powerman]]></title>
    <url>%2F2017%2F06%2F10%2Fpowerman%2F</url>
    <content type="text"><![CDATA[介绍powerman是一个开源的工具，被谷歌用于cluster的机群管理通过SNMP协议可以管理PDU电源通过ipmi协议可以管理机器的reboot以及开关机 安装源码下载地址安装流程参考源码中的INSTALL文件 configure自动生成makefile 1./configure 编译 12makemake check //check the make result 安装 1make install]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DeepLearning]]></title>
    <url>%2F2017%2F05%2F20%2FDeepLearning%2F</url>
    <content type="text"><![CDATA[框架概述 Tensorflow： Google Python Caffe： well supported by Intel Synaptic：Nodejs Tensorflow]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用别名远程登入服务器]]></title>
    <url>%2F2017%2F05%2F20%2F%E4%BD%BF%E7%94%A8%E5%88%AB%E5%90%8D%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%85%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[前言远程登入服务器进行维护的时候，SSH登入有两种模式ssh username@ip 模式1：使用密码登入，输入username的配置密码 模式2：使用密钥登入，在本地机器使用ssh-keygen生成私钥与公钥，将公钥放置到服务器上，以后就可以免密码登入了使用 模式2 ssh username@ip登入服务器时，经常会忘记ip地址，因此更好的方法是配置服务器的别名alias，以后使用ssh alias 就可以登入服务器了 使用别名登入 打开本地机器的~/.ssh/config文件，添加以下内容：123456Host server-alias # server-alias为希望配置的服务器别名HostName server-ip # 服务器地址Port 22User username # 服务器端用户名PreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsa # 私钥地址，默认为 ~/.ssh/id_rsa 配置之后就可以通过别名远程登入服务器了1ssh server-alias 上述方法通过自己的服务器配置验证]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CherryPy]]></title>
    <url>%2F2017%2F05%2F12%2FCherryPy%2F</url>
    <content type="text"><![CDATA[介绍CherryPy是一个python的web框架是目前接触过的三种python编写的web框架里(Django,Tornado,CherryPy)最轻量化的因为公司项目的开发需要，最近开始用每天的业余时间学习一下这个框架设计模式首先谈一下读完教程配合着写一些简单的应用之后的整体感受，相比于另外两个框架，CherryPy配合着SQLite使用的确做到了轻量化，但是这也意味着框架固定，灵活性不足。 安装123pip install cherrypy#使用import cherrypy 框架搭建最小应用时可以参考我的仓库 配置文件定义一个字典通常命名为conf，可以定义多个不同的配置字典conf1，conf2 启动服务有两种方式：1.1cherrypy.quickstart(webapp, &apos;/&apos;, conf) webapp是类名，在这个类中定义RESTAPI‘/’是对应的URLconf是对应的配置文件2.1234cherrypy.tree.mount(webapp, &apos;/&apos;, conf)#cherrypy.tree.mount(Forum(), &apos;/forum&apos;, forum_conf)cherrypy.engine.start()cherrypy.engine.block() 渲染文件在根目录定义index.html文件然后定义入口 1234class StringGenerator(object): @cherrypy.expose def index(self): return open(&apos;index.html&apos;) RESTFUL API1234567891011@cherrypy.exposeclass myFirstService(object): @cherrypy.tools.accept(media=&apos;text/plain&apos;) def GET(self): with sqlite3.connect(DB_STRING) as c: cherrypy.session[&apos;ts&apos;] = time.time() r = c.execute(&quot;SELECT * FROM STUDENT&quot;) print r.fetchone() return &apos;hhui&apos; def POST(self): 静态文件在配置中添加1234&apos;/static&apos;: &#123; &apos;tools.staticdir.on&apos;: True, &apos;tools.staticdir.dir&apos;: &apos;./public&apos;&#125; 所以根目录下的public文件夹里的东西对应了就是URL-static 数据库CherryPy配合SQLite使用可以搭建轻量化的web应用通常在Linux发行版本中都会预装SQLite的数据库定义DB文件的名字DB_STRING = “testDB.db”连接数据库||执行CURD操作12345with sqlite3.connect(DB_STRING) as c:cherrypy.session[&apos;ts&apos;] = time.time()r = c.execute(&quot;SELECT * FROM STUDENT&quot;)print r.fetchone()return &apos;hhui&apos;]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重定向]]></title>
    <url>%2F2017%2F05%2F10%2F%E9%87%8D%E5%AE%9A%E5%90%91%2F</url>
    <content type="text"><![CDATA[介绍重定向是linux很常用的命令 cmd &gt; record.txt 将cmd的输出从命令行重定向到文件中，先将文件清除再写 cmd &gt;&gt; record.txt 和&gt;类似，但是是追加的模式 文件描述符文件描述符 是与打开的某个文件或者数据流相关联的整数。文件描述符0,1,2是系统预留的。 0 - stdin(标准输入) 1 - stdout(标准输出) 2 - stderr(标准错误) 2> record.txt 只将错误信息重定向的文件中，**正常的信息输出在命令行**123456789也可以这样：cmd 2&gt; out.txt 1&gt; temp.txt将 **标准错误和标准输出** 重定向到两个文件中。当然，还有更精简的方式输出到同一个文件中：cmd 2&gt;&amp;1 out.txt进一步这条命令可以简写为cmd &amp;&gt; out.txt或者cmd &gt;&amp; out.txt]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow学习笔记]]></title>
    <url>%2F2017%2F05%2F06%2Ftensorflow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[前言Tensorflow 是Google出的基于人工神经网络(ANN)的深度学习的框架，官网需要科学上网工具才能访问 安装 为了避免python环境的污染，可以先安装一个python的虚拟环境VirtualEnv 打开虚拟环境，用pip安装tensorflow的包 和普通包一样使用tensorflow的包 硬件有GPU别忘了使用CUDA 实验源代码用的是anishathalye大神的仓库先看看最后训练出来的效果图 原图是去年在上海迪士尼玩的时候随手拍的照片 想要训练的风格图片用的梵高的 《星夜》 结论 玩机器学习对计算机的硬件要求很高，这是GPU的强项下面这个实验在一台cpu为i5-4200H，8G内存的台式机上跑的结果，整个训练过程时长了5个小时，运行过程中使用TOP命令查看，CPU一直处于100%以上的负荷，如果有GPU的话，理论上时间应该再20分钟左右结论 没有GPU硬件的支持是玩不了机器学习的]]></content>
      <tags>
        <tag>技术 tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Awk学习笔记]]></title>
    <url>%2F2017%2F05%2F04%2FAwk%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基本用法 awk ‘{print $0}’ filename 打印第n，m个字段 awk ‘{print $n $m}’ filename 添加上说明 awk ‘{print “字段n” $n “字段m” $m}’ filename 设置分隔符awk -F”:” ‘{print $0}’ filename 编程文件test.awk文件123456789BEGIN&#123; FS=&quot;:&quot;&#125;&#123; print $0&#125;END&#123; print &quot;over&quot;&#125;]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sed学习笔记]]></title>
    <url>%2F2017%2F04%2F26%2Fsed%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[学习使用sedThis blog is used to record the usage of sed.sed 不会对原始文件产生影响，一行行读取，一行行匹配处理 正则表达式正则表达式,在sed里面要加两个slash ^匹配开头 /^#/ 匹配#开头的行，注释行 $匹配末尾 /^$/ 匹配空行 /./ 匹配一个字符 /../ 匹配两个字符 * 匹配前面0个或多个字符 剔除指定行，打印剩余行 sed -e ‘1,5d’ filename 删除1到5行，打印剩余行 sed -e ‘/^#/d’ filename 删除所有#开头的行，打印剩余行 sed -e ‘/leslie/p’ filename 删除所有包含leslie的行，打印剩余行 打印指定的行 sed -n -e ‘1,5p’ filename 打印1到5行 sed -n -e ‘/^#/p’ filename 打印所有#开头的行 sed -n -e ‘/leslie/p’ filename 打印所有包含leslie的行 sed -n -e ‘regureexpression1,regureexpression2’ filename 从匹配第一个正则表达式的第一行开始到匹配第二正则表达式的第一行 sed -e ‘=’ filename 打印行号 替换sed -e ‘s/word1/word2/g’ filenames表示替换，用word2替换word1g表示全局替换，没有g则只会对第一个出现word1的位置替换为word2 组合多条命令使用；分割多条命令 sed -n -e ‘1,5=;1,5p’ filename或者 sed -n -e ‘1,5=’ -e ‘1,5p’ filename 读取文本中的命令新建一个 (command).sed后缀名的文件在里面写入命令sed -n -f command.sed filename]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[handlebars]]></title>
    <url>%2F2017%2F04%2F18%2Fhandlebars%2F</url>
    <content type="text"><![CDATA[介绍Handlebars 作为一种模板引擎可以很好的实现前端html代码的模块化和复用 基本的用法参考这个链接 里面描述的很清楚这个是hbs的官网 也提供了参考的代码这个是博客中代码的地址 提供了参考的代码]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mongodb]]></title>
    <url>%2F2017%2F04%2F16%2FMongodb%2F</url>
    <content type="text"><![CDATA[基本术语collection 对应了 tabledocument 对应了 rowfield 对应了 columndatabase，index，primary key都是一致的 Macos用homebrew安装， 运行 mongodb：两种方式方式1：打开mongodb的图形化界面，默认连接的数据目录的配置文件在/usr/local/etc/mongod.conf可以修改/data/db的路径 方式2： 命令行下，在shell中进入安装目录，我的mac：/Applications/MongoDB.app/Contents/Resources/Vendor/mongodb将这个目录配置到PATH环境变量里面配置数据目录 默认路径为/data/db,运行 sudo mongod(需要sudo，因为/data/db在根目录),这样就打开了mongodb，可以等待连接了或者在用户目录~下建立~/data/db,然后在启动mongod时：mongod -dapath ~/data/path 管理mongodb：两种方式 命令行运行mongo把上面的路径配置到PATH下面，运行mongo，进入mongo-shell管理界面可以用show dbs显示所有数据库use db_name使用某个数据库 1234# 查看collection中的所有记录db.collection.find()# 查看collection中的记录的数量db.collection.count() 用用MongoChef图形化界面进行管理运行mongo进入管理界面之后， Nodejs接口Nodejs下面有两种模块的接口支持对MongoDB的访问，mongodb的官网使用的是mongodb, 但是在实际生产环境使用Mongoose更多一点 mongodbmongodb的使用和在mongo的命令行从操作数据库比较类似用GraphQL和mongondb写过一些操作的例子，具体的语法可以参考官网的教程，或者github代码链接 Mongoose官网中文教程在nodejs下面可以用Mongoose模块进行mongodb管理schema，model，的概念，先定义一个schema对应了数据表(collection)的结构，然后用schema来创建一个一个model，使用model来具体操作数据(document),代码的组织可以参考这个中文教程一般会在一个独立的文件中新建一个schema以及model，然后将这个model export出来在需要用到的地方require这个model 保存数据document=new model（data）传入数据，创建一个新的document（一行数据）document.save（function（）{ }）调用save保存到数据库中，在回调函数中进行处理 更新数据,三个参数model.update(query，data，callback)1.query是匹配查找你想要更新哪一行数据(哪个document)2.data是你希望更新的数据1.set修改数据2.如果数据的数组，可以往里面push，pop一个element3.callback，是更新结束之后的回调函数 查询model.find(function(){})在回调函数中进行查询到的数据的处理 Pymongo在python下面可以通过pymongo模块进行mongodb的管理12345678910111213141516171819202122232425262728293031323334353637### 连接数据库client = pymongo.MongoClient(dbConfig[&apos;url&apos;], dbConfig[&apos;port&apos;])### 获取数据库db = client[&apos;quant&apos;] # same as &apos;db = client.quant&apos;### 获取Collectioncollection = db[&apos;tradeHistoryData&apos;]### 创建数据库db = client[&apos;quant&apos;] #如果数据库不存在会自己创建### 创建collectioncollection = db[&apos;tradeHistoryData&apos;] # collection 不存在则会被创建### 插入数据#### 单挑插入document1 = &#123;&#125; ### 创建数据，字典类型post_1 = collection.insert_one(document1).inserted_id ##其中.inserted_id将返回ObjectId对象#### 批量插入new_posts = [&#123;document1&#125;,&#123;document2&#125;]result = collection.insert_many(new_posts)### 获取单条数据(document)collection.find_one()### 获取所有documentlines = collection.find()lines = collection.find(&#123;&quot;author&quot;: &quot;Mike&quot;&#125;) ## 添加查找的条件collection.find(&#123;&quot;author&quot;: &quot;Mike&quot;&#125;).count ## 计数### 创建索引result = collection.create_index([(&apos;user_id&apos;, pymongo.ASCENDING)], unique=True)### 更新数据collection.update_one(&#123;&apos;x&apos;:4&#125;,&#123;&apos;$set&apos;:&#123;&apos;x&apos;:3&#125;&#125;) ##其中传入的第一个参数是你想要更新的数据，第二个是你想要更新的最新数据。其中$set部分是必要元素，如果没有会报出错误。除了$set外还有很多其它的比如$inc，对应着不同的功能### 删除数据collection.delete_one(&#123;&apos;x&apos;:3&#125;)### 关闭连接client.close() 数据库冷备份和还原参考这篇文章可以冷备份还原数据库；数据库中的指定表；指定表的指定字段]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django]]></title>
    <url>%2F2017%2F04%2F15%2FDjango%2F</url>
    <content type="text"><![CDATA[开发过程新建一个app之后，在settings.py的INSTALLED_APPS中需要注册一下这个APP 模板的配置在app的目录下面新建一个tempaltes的目录在base_dir/app_name/templates/app_name/xxx.html这个目录下面去写html然后在setting.py的TEMPLATES的’DIRS’加上，[os.path.join(BASE_DIR, app_name, ‘templates’),这样在app下面的views里面就可以render这个html了，然后在url里面做配置 静态文件的配置在app的目录下面新建一个static的目录在base_dir/app_name/static/app_name/目录下面去建imgaes，css,js等目录在下面摆放静态文件在settings.py按照模板配置 集成ajax主要是要注意：在用ajax提交表单的时候，需要在header中包含进csrf-token 集成reactjsDjango默认使用的templates比较适合用在静态页面(页面不太变化的场景下面)，所有的html中的数据都通过context传进去。Reactjs则比较适合用在动态页面中，一般会在项目的根目录下建立一个目录(front)专门用于储存reactjs的代码，同时将reactjs的code经过webpack之后的代码放入另一个目录中(webpack)。在Django的setting中static文件需要包含从这个webpack目录中去找。在Django的html文件中：1.需要包含reactjs渲染的主块 2.另外reactjs的代码express中是通过script包含进去的，在django中则是使用django webpack load去包含进去。 同时在webpack中可以配置生成的文件用hash之后的名字命名。这样在生产环境中可以避免浏览器缓存的问题，就是浏览器缓存了上一版本的js文件，用hash之后的文件名就会重新加载。webpack会生成一个json文件，里面包含了webpack前后的文件名的对应关系，这样在html中引入webpack之后的hash名的js文件的时候，就不需要没有刺激都修改引入的文件名了。比如：通过webpack-bundle-tracker会写入webpack-stats.json文件中 python manage.py runserver 来启动django 敲gulp 来生成babel和webpack的文件 webpack配置webpack-bundle-tracker来生成webpack-stats.json文件 部署部署到阿里云上，创建好数据库之后，启动，会报错说数据表不存在，python manager.py makemigrations 也会报同样的错有两种可能的解决方法： 数据迁移把开发环境中的数据都迁移到云端，mysql比较方便，用冷迁移就可以了备份数据: mysqldump -u root -p databaseName &gt; data.sql恢复: mysqldump -u root -p databaseName &lt; data.sql 当然mysql也支持数据的热备份，只需要在mysql中配置就可以了，本质上就是在A服务器上对数据库操作的sql语句会备份在一个log文件中，B服务器会监听这个log文件，实时更新到本地，并执行对应的sql语句 将各个APP下面的migration文件夹中的00x开头的记录django数据model变化的文件删除，然后重新migrate一下]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python_CookBook]]></title>
    <url>%2F2017%2F04%2F15%2FPython-CookBook%2F</url>
    <content type="text"><![CDATA[介绍最近在读cookbook， 记录一下阅读的心得总的感觉是书上介绍的很多用法都很精妙，有些方法也非常实用第一遍读下来还有很多高级的用法看得不是很明白，需要多写，多读源码在实践中去掌握这些写法和用法里面还是也很多的用法不熟悉，还需要好好努力！]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[黄山游记]]></title>
    <url>%2F2017%2F03%2F06%2F%E9%BB%84%E5%B1%B1%E6%B8%B8%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[黄山游记记录一趟短途的出行 2017.2.26 - 2017.2.28 游历黄山 日落2017.2.27日 黄山 丹霞峰上观看落日 日出2017.2.28日 黄山 光明顶观看日出 始信峰2017.2.27 黄山 始信峰上观看奇峰怪石]]></content>
      <tags>
        <tag>游记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建个人博客]]></title>
    <url>%2F2017%2F03%2F05%2F%E5%8D%9A%E5%AE%A2%E4%B8%BB%E9%A2%98%E4%BF%AE%E6%94%B9%2F</url>
    <content type="text"><![CDATA[如何利用git搭建个人博客工具github+nodejs+hexo首先安装nvm，然后安装node然后安装hexo npm install -g hexo-cli 下面是一些hexo常用的命令:1234hexo clean #清除public文件夹下原有的构建hexo generate #重新构建hexo deploy #部署到git上hexo server #可以先不部署，在本地运行看看效果，再部署到git上面 定制自己的博客主题可以从git上下载自己的喜欢的主题：git的仓库地址可以自行在git上搜索在配置文件_config.xml中进行配置具体的配置过程可以参考一下简书的文章 语法支持markdown语法，根据选择的主题不同会有所差别可以插入图片，本地图片或云端图片，这里推荐使用储存在七牛云上的图片]]></content>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
</search>
