<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="技术 tensorflow," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="编译
方法1：
1234567./configurebazel build --config=opt //tensorflow/tools/pip_package:build_pip_packagebuild出错清理：/root/.cache/bazel把下面的之前出错的缓存文件给删除掉生成whell包bazel-bin/tensorflow/tools/pip_package/build_pip">
<meta property="og:type" content="article">
<meta property="og:title" content="tensorflow二次开发">
<meta property="og:url" content="http://yoursite.com/2019/02/27/tensorflow二次开发/index.html">
<meta property="og:site_name" content="沉思语录">
<meta property="og:description" content="编译
方法1：
1234567./configurebazel build --config=opt //tensorflow/tools/pip_package:build_pip_packagebuild出错清理：/root/.cache/bazel把下面的之前出错的缓存文件给删除掉生成whell包bazel-bin/tensorflow/tools/pip_package/build_pip">
<meta property="og:updated_time" content="2019-05-16T13:11:28.568Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="tensorflow二次开发">
<meta name="twitter:description" content="编译
方法1：
1234567./configurebazel build --config=opt //tensorflow/tools/pip_package:build_pip_packagebuild出错清理：/root/.cache/bazel把下面的之前出错的缓存文件给删除掉生成whell包bazel-bin/tensorflow/tools/pip_package/build_pip">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/02/27/tensorflow二次开发/"/>





  <title> tensorflow二次开发 | 沉思语录 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">沉思语录</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">取次花丛懒回顾，半缘修道半缘君</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/27/tensorflow二次开发/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leslie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/popeve.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="沉思语录">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                tensorflow二次开发
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-27T10:50:46+08:00">
                2019-02-27
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/02/27/tensorflow二次开发/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2019/02/27/tensorflow二次开发/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv">本文总阅读量
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><ul>
<li><p>方法1：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">./configure</div><div class="line">bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package</div><div class="line">build出错清理：</div><div class="line">/root/.cache/bazel</div><div class="line">把下面的之前出错的缓存文件给删除掉</div><div class="line">生成whell包</div><div class="line">bazel-bin/tensorflow/tools/pip_package/build_pip_package /root/tensorflow/wheel_pkg/build_withSource</div></pre></td></tr></table></figure>
</li>
<li><p>方法2：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">yes &quot;&quot; | python configure.py</div><div class="line">bazel build --config=mkl --copt=-mavx2 --copt=-O3 --copt=-DINTEL_MKL_QUANTIZED -s //tensorflow/tools/pip_package:build_pip_package</div><div class="line">生成whell包</div><div class="line">bazel-bin/tensorflow/tools/pip_package/build_pip_package /root/tensorflow/wheel_pkg/build_withSource</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="增量编译"><a href="#增量编译" class="headerlink" title="增量编译"></a>增量编译</h3><p>直接bazel build<br>然后重新生成wheel包<br>pip unistall tensorflow<br><strong>一定先卸载然后重新安装</strong><br>否则还是原来的包</p>
<h2 id="编译之后"><a href="#编译之后" class="headerlink" title="编译之后"></a>编译之后</h2><p>生成pywrap_tensorflow_internal.py 以及 pywrap_tensorflow_internal.cc在~/.cache/bazel目录下面,所有代码都在_pywrap_tensorflow_internal.so 的动态链接库里面<br>pywrap_tensorflow_internal.py: 负责对接上层 Python 调用<br>pywrap_tensorflow_internal.cc: 负责对接下层 C API 调用</p>
<ul>
<li>pywrap_tensorflow_internal.py 模块首次被导入时，自动地加<br>载 _pywrap_tensorflow_internal.so 的动态链接库；其中， _pywrap_tensorflow_internal.so<br>包含了整个 TensorFlow 运行时的所有符号。</li>
<li>在 pywrap_tensorflow_internal.cc 的实现中，静态注册了一个函数符号表，实现了 Python 函数名到 C 函数名的二元关系。在运行时，按照 Python 的函数名称，匹找到对应的 C 函数实现，最终实现 Python 到 c_api.c 具体实现的调用关系。</li>
</ul>
<h2 id="编译debug版本的tensorflow"><a href="#编译debug版本的tensorflow" class="headerlink" title="编译debug版本的tensorflow"></a>编译debug版本的tensorflow</h2><p>添加 -c dbg选项<br>移除优化选项 –copt=-O3 以及 -c opt<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bazel build --config=mkl --copt=-mavx2 --copt=-O3 --copt=-DINTEL_MKL_QUANTIZED -s -c dbg //tensorflow/tools/pip_package:build_pip_package</div></pre></td></tr></table></figure></p>
<p>debug版本编译完大概有20G左右</p>
<h3 id="指定编译目录"><a href="#指定编译目录" class="headerlink" title="指定编译目录"></a>指定编译目录</h3><p>默认编译在/root/.cache/bazel目录下面，有时候root目录空间不够<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">build_dir=/home/lesliefang/bazel_build</div><div class="line">bazel --output_user_root=$build_dir clean</div><div class="line">bazel --output_user_root=$build_dir build --config=mkl --copt=-mavx2 --copt=-O3 --copt=-DINTEL_MKL_QUANTIZED -s -c dbg //tensorflow/tools/pip_package:build_pip_package</div></pre></td></tr></table></figure></p>
<h3 id="编译报错找不到–march-broadwell"><a href="#编译报错找不到–march-broadwell" class="headerlink" title="编译报错找不到–march=broadwell"></a>编译报错找不到–march=broadwell</h3><p>使用gcc6.3</p>
<h3 id="whell太大无法打包"><a href="#whell太大无法打包" class="headerlink" title="whell太大无法打包"></a>whell太大无法打包</h3><p><a href="https://github.com/tensorflow/tensorflow/issues/5538" target="_blank" rel="external">https://github.com/tensorflow/tensorflow/issues/5538</a></p>
<h2 id="gdb-调试"><a href="#gdb-调试" class="headerlink" title="gdb 调试"></a>gdb 调试</h2><p>二种方法方法去debug TF:<br>method1:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">1. gdb python</div><div class="line">2. run file.py</div><div class="line">3. bt</div></pre></td></tr></table></figure></p>
<p>method2:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">1. 跑测试</div><div class="line">2. top 看到python进程的pid</div><div class="line">3. gdb -p pid</div><div class="line">挂上之后，原来测试会挂住</div><div class="line">break 函数名或者其它打上断点,tensorflow找不到符号的情况下可以 文件名:line的方式去打断点</div><div class="line">continue 继续测试直到core-dump</div></pre></td></tr></table></figure></p>
<p><strong>如何添加python的信息</strong> 参考这个blog<br><a href="http://jcf94.com/2018/01/13/2018-01-13-tfunpacking/" target="_blank" rel="external">http://jcf94.com/2018/01/13/2018-01-13-tfunpacking/</a></p>
<h3 id="warning找不到文件"><a href="#warning找不到文件" class="headerlink" title="warning找不到文件"></a>warning找不到文件</h3><p>dir 目录<br>去指定文件的搜索根目录</p>
<h3 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h3><p>所有并行计算线程设置为1<br>命令后加&amp;echo $! 输出PID，进行gdb -p的调试</p>
<h2 id="mkldnn调试"><a href="#mkldnn调试" class="headerlink" title="mkldnn调试"></a>mkldnn调试</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export MKLDNN_VERBOSE=1</div><div class="line">python ***</div></pre></td></tr></table></figure>
<p>在运行测试之前，添加环境变量<br>可以打出mkldnn的信息<br>每一行的信息Each line with verbose information is formatted as a comma-separated list containing:</p>
<ul>
<li>mkldnn_verbose</li>
<li>stage, e.g. create or exec</li>
<li>primitive-kind, e.g. convolution, reorder, sum, …</li>
<li>primitive implementation name</li>
<li>propagation-kind, e.g. forward_training</li>
<li>input/output data info, e.g. data type and data format</li>
<li>auxiliary information, e.g. algorithm or number of input</li>
<li>problem description<ul>
<li>for convolution the problem description is dumped in benchdnn friendly format</li>
<li>for reorder, sum, and concat problem description is simply logical dims</li>
<li>for other primitives the problem description is similar to convolution one</li>
</ul>
</li>
<li>execution time in milliseconds</li>
</ul>
<a id="more"></a>
<h2 id="看python到C-调用关系"><a href="#看python到C-调用关系" class="headerlink" title="看python到C++调用关系"></a>看python到C++调用关系</h2><h3 id="以Session-为例子：tf-Session时候的调用关系"><a href="#以Session-为例子：tf-Session时候的调用关系" class="headerlink" title="以Session 为例子：tf.Session时候的调用关系"></a>以Session 为例子：tf.Session时候的调用关系</h3><ul>
<li>python api<br>/root/tensorflow_src/test_code/private-tensorflow/tensorflow/python<br>目录下面：</li>
</ul>
<ol>
<li>grep -rni “class Session”<br>client/session.py:1475:class Session(BaseSession):<br>里面调用了baseSession的构造函数</li>
<li><p>看baseSession<br>里面调用了tf_session</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts)</div><div class="line">from tensorflow.python import pywrap_tensorflow as tf_session</div></pre></td></tr></table></figure>
</li>
<li><p>看pywrap_tensorflow.py<br>这个就是对应了编译出来的so文件</p>
</li>
<li><p>在source insight里面搜索TF_NewSessionRef<br>看到定义在tf_session_help.cc里面<br>里面调用了TF_NewSession</p>
</li>
<li><p>source insight里面搜索TF_NewSession<br>已经进入到C++ 代码内部</p>
</li>
</ol>
<h3 id="以matmul为列"><a href="#以matmul为列" class="headerlink" title="以matmul为列"></a>以matmul为列</h3><p><a href="https://ggaaooppeenngg.github.io/zh-CN/2018/05/29/Tensorflow-%E7%9A%84-Tensor-%E5%92%8C-OpKernel-%E5%88%86%E6%9E%90/" target="_blank" rel="external">https://ggaaooppeenngg.github.io/zh-CN/2018/05/29/Tensorflow-%E7%9A%84-Tensor-%E5%92%8C-OpKernel-%E5%88%86%E6%9E%90/</a><br>调用 tf.matmul(a,b)</p>
<ol>
<li>查看<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">grep -rni &quot;tf_export.*matmul&quot; #这个函数需要用tf_export导出</div></pre></td></tr></table></figure>
</li>
</ol>
<p>ops/math_ops.py:2277:@tf_export(“linalg.matmul”, “matmul”)</p>
<ol>
<li><p>看math_ops.py:2277<br>api的使用有详细的解释<br>调用了gen_math_ops.batch_mat_mul 或者 gen_math_ops.mat_mul</p>
</li>
<li><p>看gen_math_ops.py</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">find / -name &quot;gen_math_ops.py&quot;</div></pre></td></tr></table></figure>
</li>
</ol>
<p>这个文件看文件名字，应该是在编译的时候生成的<br>这个文件里面搜:batch_mat_mul</p>
<ol>
<li>batch_mat_mul函数<br>这个函数里面调用了<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">_result = _pywrap_tensorflow.TFE_Py_FastPathExecute(</div><div class="line">        _ctx._context_handle, _ctx._eager_context.device_name, &quot;BatchMatMul&quot;,</div><div class="line">        name, _ctx._post_execution_callbacks, x, y, &quot;adj_x&quot;, adj_x, &quot;adj_y&quot;,</div><div class="line">        adj_y)</div></pre></td></tr></table></figure>
</li>
</ol>
<p>所以C++里面的op函数应该是BatchMatMul</p>
<ol>
<li>搜索所有注册这个op的地方<br>搜索op定义<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@localhost private-tensorflow]# grep -rni &quot;REGISTER_OP(\&quot;MatMul\&quot;)&quot;</div><div class="line">tensorflow/core/ops/math_ops.cc:763:REGISTER_OP(&quot;MatMul&quot;)</div></pre></td></tr></table></figure>
</li>
</ol>
<p>搜索op的kernel实现<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">grep -rni &quot;Name(\&quot;MatMul\&quot;)&quot;</div></pre></td></tr></table></figure></p>
<p>找到所有定义operation<br>break 文件名:行<br>在每个computer的d地方打断点<br>看看调用到了哪个kernel</p>
<p>看class MatMulOp 的Compute方法里面最后调用了LaunchMatMul方法<br>LaunchMatMul 继承自LaunchMatMulBase，在 LaunchMatMulBase 当中调用了 functor::MatMulFunctor，这个 functor 主要就会执行乘法操作</p>
<p>MatMulFunctor里面调用了MatMul方法<br>MatMul方法里面进一步调用了out.device(d) = in0.contract(in1, dim_pair);</p>
<p>contract是Eigen的一个方法，表示矩阵相乘，Eigen是一套高效的C++中调用的数学平台，里面实现了很多通用的数学运算。</p>
<h3 id="以conv2d为例"><a href="#以conv2d为例" class="headerlink" title="以conv2d为例"></a>以conv2d为例</h3><p>这个人博客很多好文章：<a href="http://lanhin.xyz/" target="_blank" rel="external">http://lanhin.xyz/</a><br><a href="http://lanhin.xyz/2018/10/29/tensorflow%E4%B8%AD2d%E5%8D%B7%E7%A7%AF%E4%BB%A3%E7%A0%81%E7%AE%80%E6%9E%90/" target="_blank" rel="external">http://lanhin.xyz/2018/10/29/tensorflow%E4%B8%AD2d%E5%8D%B7%E7%A7%AF%E4%BB%A3%E7%A0%81%E7%AE%80%E6%9E%90/</a></p>
<ol>
<li>python 接口 tf.nn.conv2d<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">grep -rni &quot;tf_export.*conv2d&quot;</div></pre></td></tr></table></figure>
</li>
</ol>
<p>tensorflow_src/test_code/private-tensorflow/tensorflow/python/ops/nn_ops.py:1376:@tf_export(“nn.conv2d”, v1=[])</p>
<ol>
<li><p>查找输出的地方</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">find / -name &quot;gen_math_ops.py&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>查看op注册和实现的地方</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">grep -rni &quot;REGISTER_OP(\&quot;Conv2D\&quot;)&quot;</div><div class="line">grep -rni &quot;Name(\&quot;Conv2D\&quot;)&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>进入conv_ops.cc文件<br>看Compute方法</p>
</li>
</ol>
<p>输入为浮点数float调用LaunchDeepConvOp<device, t="">::Run</device,></p>
<p>其它输入类型调用launcher_<br>进一步看调用到了<br>LaunchConv2DOp<cpudevice, t="">::operator()<br>再往下<br>tensorflow::LaunchGeneric::operator<br>这个函数里面通过不同的条件判断调用两个不同的计算kernel：functor::MatMulConvFunctor<device, t="">()和functor::SpatialConvolution<device, t="">()</device,></device,></cpudevice,></p>
<p>MatMulConvFunctor定义在conv_2d.h文件里面<br>out.device(d) = in0.contract(in1, dim_pair, output_kernel);<br>到最后还是调用了矩阵乘法的函数<br>这个contract应该是eigen库提供的接口</p>
<h3 id="INT8-operation"><a href="#INT8-operation" class="headerlink" title="INT8 operation"></a>INT8 operation</h3><ol>
<li><p>读取RN50 int8的pb<br>用tensorboard查看<br>看到用到了op：QuantizedConv2DWithBiasAndReluAndRequantize</p>
</li>
<li><p>搜索这个op</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# grep -rni &quot;name(\&quot;QuantizedConv2DWithBiasAndReluAndRequantize\&quot;)&quot;</div><div class="line">tensorflow_src/test_code/private-tensorflow/tensorflow/core/kernels/mkl_conv_ops.cc:1997:REGISTER_KERNEL_BUILDER(Name(&quot;QuantizedConv2DWithBiasAndReluAndRequantize&quot;)</div></pre></td></tr></table></figure>
</li>
</ol>
<p>这个op对应的kernel实现就是QuantizedConv2DWithBiasAndReluAndRequantize<br>对应的kernel叫做NoOp<br>看到注释：<br><strong>// Register NoOp kernel for QuantizedConv2DWithBiasAndRelu to get a python<br>// interface.<br>// This kernel will be replaced by an MKL kernel during graph-optimization pass.</strong></p>
<p>同一个文件里面看另外一个op<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">_MklQuantizedConv2DWithBiasSumAndRelu</div></pre></td></tr></table></figure></p>
<p>对应的kernel是MklQuantizedConv2DSumReluOp<br>继承了MklQuantizedConv2DOp这个kernel<br>MklQuantizedConv2DOp这个kernel继承了MklConvOp<br>MklQuantizedConv2DOp的compute方法首先调用了<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">// Compute int32 output tensor</div><div class="line">MklConvOp&lt;Device, quint8, qint8, Tbias, Toutput, Ttemp_output, int32,</div><div class="line">          biasEnabled, false&gt;::Compute(context);</div></pre></td></tr></table></figure></p>
<p>MklConvOp里面的compute方法调用了mkldnn<br>conv_fwd-&gt;Execute执行mkldnn的计算</p>
<p><strong>注意</strong><br>class MklConvOp在这个文件里面有两个类的定义<br>通过template <typename device,="" 在创建对象时传入的参数可以区分创建了哪个类="" 一个类使用了mkl，调用dnnexecute_f32的方法="" 另一个类使用了mkldnn调用conv_fwd-="">Execute</typename></p>
<p>看这个mkldnn的类的实现代码，可以先看看MKLDNN的<a href="!https://intel.github.io/mkl-dnn/index.html">教程</a>和实例代码mkldnn代码库的simple_net.cpp以及<a href="!https://intel.github.io/mkl-dnn/ex_simplenet.html">解释</a><br>基本概念比较清晰，先创建memory/operator descriptor,再创建对应的Primitive descriptor ，最后创建primitive,然后把primitive放到stream里面去执行<br>tensorflow的这个类的实现follow这个逻辑只是加了一些封装<br>至于mkldnn里面进一步的实现(如何多线程等)就是mkldnn的事情了<br>可以看我的mkldnn的文章</p>
<h2 id="自己定义个operation"><a href="#自己定义个operation" class="headerlink" title="自己定义个operation"></a>自己定义个operation</h2><p>参考文档：<a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/adding_an_op.html#AUTOGENERATED-adding-a-new-op" target="_blank" rel="external">http://wiki.jikexueyuan.com/project/tensorflow-zh/how_tos/adding_an_op.html#AUTOGENERATED-adding-a-new-op</a></p>
<h3 id="定义operation"><a href="#定义operation" class="headerlink" title="定义operation"></a>定义operation</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#include &quot;tensorflow/core/framework/op.h&quot;</div><div class="line">REGISTER_OP(&quot;ZeroOut&quot;)</div><div class="line">    .Input(&quot;to_zero: int32&quot;)</div><div class="line">    .Output(&quot;zeroed: int32&quot;);</div></pre></td></tr></table></figure>
<h3 id="定义kernel"><a href="#定义kernel" class="headerlink" title="定义kernel"></a>定义kernel</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">#include &quot;tensorflow/core/framework/op_kernel.h&quot;</div><div class="line">using namespace tensorflow;</div><div class="line"></div><div class="line">class ZeroOutOp : public OpKernel &#123;</div><div class="line"> public:</div><div class="line">  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) &#123;&#125;</div><div class="line">  void Compute(OpKernelContext* context) override &#123;</div><div class="line">    // 获取输入 tensor.</div><div class="line">    const Tensor&amp; input_tensor = context-&gt;input(0);</div><div class="line">    auto input = input_tensor.flat&lt;int32&gt;();</div><div class="line">   // 创建一个输出 tensor.</div><div class="line">    Tensor* output_tensor = NULL;</div><div class="line">    OP_REQUIRES_OK(context, context-&gt;allocate_output(0, input_tensor.shape(),</div><div class="line">                                                     &amp;output_tensor));</div><div class="line">    auto output = output_tensor-&gt;template flat&lt;int32&gt;();</div><div class="line">    // 设置 tensor 除第一个之外的元素均设为 0.</div><div class="line">    const int N = input.size();</div><div class="line">    for (int i = 1; i &lt; N; i++) &#123;</div><div class="line">      output(i) = 0;</div><div class="line">    &#125;</div><div class="line">    // 尽可能地保留第一个元素的值.</div><div class="line">    if (N &gt; 0) output(0) = input(0);</div><div class="line">  &#125;</div><div class="line">&#125;;</div><div class="line">REGISTER_KERNEL_BUILDER(Name(&quot;ZeroOut&quot;).Device(DEVICE_CPU), ZeroOutOp);</div></pre></td></tr></table></figure>
<h3 id="添加python-wrap"><a href="#添加python-wrap" class="headerlink" title="添加python wrap"></a>添加python wrap</h3><p>经过前面两步在编译之后，可以在bazel-genfiles/tensorflow/python/ops/gen_user_ops.py文件，比如我的一个例子<br>vim /home/lesliefang/bazel_build/615e7e34d0a05b2b7ebac45eda8ba3c5/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/tools/pip_package/build_pip_package.runfiles/org_tensorflow/tensorflow/python/ops/gen_user_ops.py<br>里面找到对应的operation的函数<br>为了使得python可以调用到,在tensorflow/python/user_ops/user_ops.py 文件中添加接口<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">@tf_export(v1=[&apos;user_ops.leslie_zero_out&apos;])</div><div class="line">def leslie_zero_out(input):</div><div class="line">  &quot;&quot;&quot;Example of overriding the generated code for an Op.&quot;&quot;&quot;</div><div class="line">  return _gen_user_ops.zero_out(input)</div></pre></td></tr></table></figure></p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>重新编译之后安装之后<br>测试代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"># -*- coding: utf-8 -*-</div><div class="line">import tensorflow as tf</div><div class="line">import numpy as np</div><div class="line">import datetime</div><div class="line">import os</div><div class="line">import time</div><div class="line"></div><div class="line">if __name__ == &quot;__main__&quot;:</div><div class="line">	#time.sleep(30)</div><div class="line">	with tf.Session() as sess:</div><div class="line">		sess.run(tf.global_variables_initializer())</div><div class="line">		result = tf.user_ops.leslie_zero_out([5, 4, 3, 2, 1])</div><div class="line">		print(&quot;result is &#123;&#125;&quot;.format(result))</div><div class="line">		print(&quot;result is &#123;&#125;&quot;.format(sess.run(result)))</div></pre></td></tr></table></figure></p>
<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><p>To write a multi-threaded CPU kernel, the Shard function in <strong>work_sharder.h</strong> can be used. This function shards a computation function across the threads configured to be used for intra-op threading (see intra_op_parallelism_threads in config.proto).</p>
<h2 id="核心运行机制"><a href="#核心运行机制" class="headerlink" title="核心运行机制"></a>核心运行机制</h2><p>推荐一个很好的Blog:<a href="http://jcf94.com/2018/01/13/2018-01-13-tfunpacking/" target="_blank" rel="external">http://jcf94.com/2018/01/13/2018-01-13-tfunpacking/</a><br>这个blog对C++部分session的机制分析的很清楚</p>
<p>这边从python调用session.run开始分析</p>
<h3 id="在python里面"><a href="#在python里面" class="headerlink" title="在python里面"></a>在python里面</h3><p>1.<br>session.run</p>
<ol>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">result = self._run(None, fetches, feed_dict, options_ptr,</div><div class="line">                   run_metadata_ptr)</div></pre></td></tr></table></figure>
</li>
<li><p>在_run里面</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">results = self._do_run(handle, final_targets, final_fetches,</div><div class="line">                      feed_dict_tensor, options, run_metadata)</div></pre></td></tr></table></figure>
<ol>
<li><p>do_run里面</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">return self._call_tf_sessionrun(</div><div class="line">    options, feed_dict, fetch_list, target_list, run_metadata)</div></pre></td></tr></table></figure>
</li>
<li><p>call_tf_sessionrun里面</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">return tf_session.TF_SessionRun_wrapper(</div><div class="line">   self._session, options, feed_dict, fetch_list, target_list,</div><div class="line">   run_metadata)</div></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ol>
<p>TF_SessionRun_wrapper 定义在pywrap_tensorflow_internal.py里面<br>就是python和C++的桥梁</p>
<h3 id="下面进入C-的部分"><a href="#下面进入C-的部分" class="headerlink" title="下面进入C++的部分"></a>下面进入C++的部分</h3><ol>
<li><p>TF_SessionRun_wrapper_helper函数<br>里面调用了TF_SessionRun</p>
</li>
<li><p>TF_SessionRun 函数<br>调用了TF_Run_Helper函数</p>
</li>
<li><p>TF_Run_Helper函数<br>调用了session-&gt;Run函数</p>
</li>
<li><p>这是个虚函数<br>用gdb跟进去看<br>参考这篇文章：<a href="https://zhuanlan.zhihu.com/p/26031658" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/26031658</a><br>local用direction_session<br>分布式用grpc_session<br>所以我们这边调用到了DirectSession::Run</p>
</li>
<li><p>看DirectSession::Run函数<br>这个函数的分析：<a href="http://jcf94.com/2018/01/13/2018-01-13-tfunpacking/" target="_blank" rel="external">http://jcf94.com/2018/01/13/2018-01-13-tfunpacking/</a></p>
</li>
</ol>
<ul>
<li>GetOrCreateExecutors函数里面会去寻找有没有符合条件的exectuor，不存在的话则调用CreateExecutors函数去创建executors<br>同时CreateExecutors里面调用到了CreateGraphs<br>在CreateExecutors调用了CreateGraphs之后看到：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">params.create_kernel = [this, lib, opseg](const NodeDef&amp; ndef,</div><div class="line">                                              OpKernel** kernel)</div></pre></td></tr></table></figure>
</li>
</ul>
<p>我理解就是在这里实现了param里面的创建kernel的函数指针<br>在CreateExecutors的最后调用了NewExecutor函数，会传入param变量(里面带上了create_kernel方法)<br>NewExecutor函数里面通过工厂模式来生成Executor<br>是个虚函数，通过gdb看到里面调用了<br>tensorflow::(anonymous namespace)::DefaultExecutorRegistrar::Factory::NewExecutor (this=0x1fffd10, params=…, graph=…,<br>    out_executor=0x72fdee8) at tensorflow/core/common_runtime/executor.cc:2857<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">class Factory : public ExecutorFactory &#123;</div><div class="line">  Status NewExecutor(const LocalExecutorParams&amp; params,</div><div class="line">                     std::unique_ptr&lt;const Graph&gt; graph,</div><div class="line">                     std::unique_ptr&lt;Executor&gt;* out_executor) override &#123;</div><div class="line">    Executor* ret = nullptr;</div><div class="line">    TF_RETURN_IF_ERROR(NewLocalExecutor(params, std::move(graph), &amp;ret));</div><div class="line">    out_executor-&gt;reset(ret);</div><div class="line">    return Status::OK();</div><div class="line">  &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>里面调用了NewLocalExecutor<br>进一步调用ExecutorImpl-&gt;Initialize函数<br>这个函数里面调用了params_.create_kernel函数去创建kernel<br>(这个create_kernel函数就是之前在CreateExecutors函数里面定义的)<br>同时在这个函数里面看到了一行注释<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">// Preprocess every node in the graph to create an instance of op</div><div class="line">// kernel for each node.</div></pre></td></tr></table></figure></p>
<h3 id="调试CreateExecutors的create-kernel函数"><a href="#调试CreateExecutors的create-kernel函数" class="headerlink" title="调试CreateExecutors的create_kernel函数"></a>调试CreateExecutors的create_kernel函数</h3><p>gdb断点进去CreateKernel函数<br>tensorflow/core/common_runtime/function.cc:521<br>调用到526行的CreateKernel函数<br>tensorflow/core/common_runtime/function.cc:526<br>executor.cc的CreateNonCachedKernel函数<br>op_kernel.cc的CreateOpKernel函数（*kernel = registration-&gt;factory-&gt;Create(&amp;context);）<br>mkl_conv_ops.cc的TF_CALL_float(REGISTER_MKL_CPU_2D_FUSED);函数<br>mkl_conv_ops.cc的MklFusedConvOp的构造函数</p>
<p>所以调用session.run多次，因为已经存在符合条件的exectuors，并不会多次创建图<br>（别人的评论：第一次执行 sess.run(….) 的时候会根据 python 层的图构造出 C++ 层的图然后保存下来，之后如果下次 sess.run() 的目标节点是相同的，就不需要重新构造一遍了。详细可以去分析 sess.run() 的执行流程）</p>
<ul>
<li>调用到了RunInternal函数</li>
</ul>
<ol>
<li><p>RunInternal函数<br>里面调用了item.executor-&gt;RunAsync(args, barrier-&gt;Get());<br>去执行异步计算</p>
</li>
<li><p>通过日志知道RunAsync会调用到executor的Process()函数<br>process函数做了什么：<br><a href="http://jcf94.com/2018/01/13/2018-01-13-tfunpacking/" target="_blank" rel="external">http://jcf94.com/2018/01/13/2018-01-13-tfunpacking/</a><br>遍历每个节点，针对每个节点的kernel进行计算（调用device-&gt;Compute，里面调用op_kernel-&gt;Compute(context);）<br>在每个kernel里面都可以搜索到对应的Compute函数</p>
</li>
</ol>
<h2 id="看一个inner-product的kernel是怎么生成的"><a href="#看一个inner-product的kernel是怎么生成的" class="headerlink" title="看一个inner product的kernel是怎么生成的"></a>看一个inner product的kernel是怎么生成的</h2><p>断点打在<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">b mkl_qmatmul_op.cc:183(一个setup函数里面)</div></pre></td></tr></table></figure></p>
<p>汾西代码知道这个setup函数是设置上下文变量的<br>查看调用栈<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">#0  tensorflow::MklIPFwdPrimitive&lt;float, Eigen::QUInt8, Eigen::QInt8, Eigen::QInt32, Eigen::QUInt8&gt;::Setup (this=0x3d1a300, IPFwdDims=...)</div><div class="line">    at tensorflow/core/kernels/mkl_qmatmul_op.cc:183</div><div class="line">#1  0x00007f6a77ee938c in tensorflow::MklIPFwdPrimitive&lt;float, Eigen::QUInt8, Eigen::QInt8, Eigen::QInt32, Eigen::QUInt8&gt;::MklIPFwdPrimitive (this=0x3d1a300, IPFwdDims=...)</div><div class="line">    at tensorflow/core/kernels/mkl_qmatmul_op.cc:77</div><div class="line">#2  0x00007f6a77ee81c3 in tensorflow::MklIPFwdPrimitiveFactory&lt;float, Eigen::QUInt8, Eigen::QInt8, Eigen::QInt32, Eigen::QUInt8&gt;::Get (IPFwdDims=..., do_not_cache=false)</div><div class="line">    at tensorflow/core/kernels/mkl_qmatmul_op.cc:298</div><div class="line">#3  0x00007f6a77ee0515 in tensorflow::MklIPOp&lt;Eigen::ThreadPoolDevice, Eigen::QUInt8, Eigen::QInt8, Eigen::QInt32, Eigen::QUInt8, Eigen::QUInt8, true&gt;::Compute (</div><div class="line">    this=0x1ea0f20, context=0x7f6a53f1d5f0) at tensorflow/core/kernels/mkl_qmatmul_op.cc:499</div><div class="line">#4  0x00007f6a77edee0e in tensorflow::MklQuantizedIPOp&lt;Eigen::ThreadPoolDevice, Eigen::QInt32, Eigen::QUInt8, Eigen::QUInt8, true&gt;::Compute (this=0x1ea0f20,</div><div class="line">    context=0x7f6a53f1d5f0) at tensorflow/core/kernels/mkl_qmatmul_op.cc:752</div><div class="line">#5  0x00007f6a78410eae in tensorflow::Device::Compute (this=0x40a6780, op_kernel=0x1ea0f20, context=0x7f6a53f1d5f0) at ./tensorflow/core/common_runtime/device.h:89</div><div class="line">#6  0x00007f6a6c90f868 in tensorflow::(anonymous namespace)::ExecutorState::Process (this=0x54f6480, tagged_node=..., scheduled_nsec=0)</div><div class="line">    at tensorflow/core/common_runtime/executor.cc:1817</div></pre></td></tr></table></figure></p>
<ul>
<li>#0 mkl_qmatmul_op.cc:183 在tensorflow里面这个primitive的setup函数<br>看这个setup里面，看到先创建mkldnn的primitive的desc<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">// create a inner product</div><div class="line"> context_.fwd_desc.reset(new inner_product_forward::desc(</div><div class="line">       prop_kind::forward_inference, *context_.src_md, *context_.weight_md,</div><div class="line">       *context_.bias_md,</div><div class="line">       *context_.dst_md));</div></pre></td></tr></table></figure>
</li>
</ul>
<p>然后通过这个desc去创建primitive_desc(pd),跟进到mkldnn里面看，就是在创建pd的时候回去遍历mkldnn里面所有pd找到对应的满足条件的pd</p>
<ul>
<li>#1 mkl_qmatmul_op.cc:77 MklIPFwdPrimitive的构造函数</li>
<li>#2 mkl_qmatmul_op.cc:298 MklIPFwdPrimitiveFactory的Get函数，Get函数根据输入的MklIPFwdParams去try to find a suitable one in pool<br>没有找到的话(if (IP_fwd == nullptr))会去创建</li>
<li>#3 mkl_qmatmul_op.cc:499 MklIPOp的compute方法，里面调用了MklIPFwdPrimitiveFactory的Get方法去拿到对应的IP_fwd(Primitive)<br>MklIPOp的compute方法 应该是tensorflow在运行图的节点的时候会被调用到的方法<br><strong>继续看这个MklIPOp的compute方法</strong><br>后面会调用IP_fwd-&gt;Execute(src_data, weight_data, bias_data, dst<em>data);<br>去做计算<br>这个根据前几步选中的mkldnn的pd，会调用到mkldnn的submit函数(context</em>.fwd<em>stream-&gt;submit(context</em>.fwd_primitives);)<br>可以用GDB去跟进mkldnn去看调用关系，这里已经比较好理解了<br><strong>结论</strong><br>所以tensorflow的node到mkldnn的kernel的对应关系，是在第一次运行这个图的时候确认的，同时如果set了cache(默认都是设置的),后面几次运行的时候就会保留这个对应关系</li>
<li>#4 mkl_qmatmul_op.cc:752 MklQuantizedIPOp的Compute函数，这个函数会去调用MklIPOp的compute方法</li>
<li>#5 device.h:89 Device的Compute()是个虚函数,对应了device信息</li>
<li>#6 executor.cc:1817 ExecutorState::Process函数，这里已经是tensorflow创建了exectuor之后的执行了</li>
<li>#7 executor.cc:2258  ExecutorState::ScheduleReady</li>
</ul>
<p><strong>总结</strong>，关键是这个MklIPOp的compute方法，先通过Get方法去获得对应的mkldnn的kernel，然后调用execute去执行</p>
<h2 id="通过pb文件去看调用的kernel"><a href="#通过pb文件去看调用的kernel" class="headerlink" title="通过pb文件去看调用的kernel"></a>通过pb文件去看调用的kernel</h2><ul>
<li>首先加载pb用tensorboard大概看一下</li>
<li>在代码里面加载输出每个节点的名字<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">graph_def = graph_pb2.GraphDef()</div><div class="line">with open(args.input_graph, &quot;rb&quot;) as f:</div><div class="line">  graph_def.ParseFromString(f.read()) #f就是pb文件</div><div class="line">for node in graph_def.node:</div><div class="line">    k = node.name</div><div class="line">    print(&quot;node op is &#123;&#125;&quot;.format(node.op))</div></pre></td></tr></table></figure>
</li>
</ul>
<p>打印出node的名字<br>比如其中一个MatMul</p>
<ul>
<li>在tensorlfow里面搜索注册这个op和kernel的地方<br>比如第二步打印看到的node.op是 Conv2D<br>在代码里面搜索<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">grep -rni &quot;Name(\&quot;.*Conv2D.*\&quot;)&quot;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>因为注册的kernel可能是Conv2D<br>也有可能加了mkl前缀比如:REGISTER_KERNEL_BUILDER(Name(“_MklConv2D”)<br><strong>todo</strong><br>这个点还没有搞明白，pb图上看到的是Conv2D,但是为啥对应的注册了_MklConv2D，这个前缀的名字是如何生效的<br><strong>创建kernel时候的调用栈</strong><br>断点打在mkl_conv_ops.cc:861<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">#0  tensorflow::MklConvOp&lt;Eigen::ThreadPoolDevice, float, float, float, float, float, int, false, false&gt;::MklConvOp (this=this@entry=0x36b35400,</div><div class="line">    context=context@entry=0x7ffca8d435c0) at tensorflow/core/kernels/mkl_conv_ops.cc:861</div><div class="line">#1  0x00007fa3b9de7ecc in tensorflow::MklFusedConvOp&lt;Eigen::ThreadPoolDevice, float, float, float, float, float, int, true&gt;::MklFusedConvOp (</div><div class="line">    this=0x36b35400, context=0x7ffca8d435c0) at tensorflow/core/kernels/mkl_conv_ops.cc:1474</div><div class="line">#2  0x00007fa3b9dcd7b2 in operator() (__closure=0x0, context=0x7ffca8d435c0) at tensorflow/core/kernels/mkl_conv_ops.cc:2165</div><div class="line">#3  tensorflow::&lt;lambda(tensorflow::OpKernelConstruction*)&gt;::_FUN(tensorflow::OpKernelConstruction *) ()</div><div class="line">    at tensorflow/core/kernels/mkl_conv_ops.cc:2165</div><div class="line">#4  0x00007fa3b469ac77 in tensorflow::CreateOpKernel (device_type=..., device=device@entry=0x3c346e0, allocator=allocator@entry=0x1c1e380,</div><div class="line">    flib=flib@entry=0x36bae2c0, node_def=..., graph_def_version=0, kernel=0x15b5c4bc8) at tensorflow/core/framework/op_kernel.cc:1302</div><div class="line">#5  0x00007fa3b498f80f in tensorflow::CreateNonCachedKernel (device=0x3c346e0, flib=flib@entry=0x36bae2c0, ndef=...,</div><div class="line">    graph_def_version=&lt;optimized out&gt;, kernel=kernel@entry=0x15b5c4bc8) at tensorflow/core/common_runtime/executor.cc:2764</div><div class="line">#6  0x00007fa3b49aaaf7 in tensorflow::FunctionLibraryRuntimeImpl::CreateKernel (this=0x36bae2c0, ndef=..., lib_def=0x372c000, kernel=0x15b5c4bc8)</div><div class="line">    at tensorflow/core/common_runtime/function.cc:539</div><div class="line">#7  0x00007fa3b49aac18 in tensorflow::FunctionLibraryRuntimeImpl::CreateKernel (this=&lt;optimized out&gt;, ndef=..., kernel=&lt;optimized out&gt;)</div><div class="line">    at tensorflow/core/common_runtime/function.cc:515</div><div class="line">#8  0x00007fa3ba11e40b in operator() (kernel=0x15b5c4bc8, ndef=..., __closure=0x2ef1e660) at tensorflow/core/common_runtime/direct_session.cc:1261</div><div class="line">#9  std::_Function_handler&lt;tensorflow::Status(const tensorflow::NodeDef&amp;, tensorflow::OpKernel**), tensorflow::DirectSession::CreateExecutors(const tensorflow::CallableOptions&amp;, std::unique_ptr&lt;tensorflow::DirectSession::ExecutorsAndKeys&gt;*, std::unique_ptr&lt;tensorflow::DirectSession::FunctionInfo&gt;*, tensorflow::DirectSession::RunStateArgs*)::&lt;lambda(const tensorflow::NodeDef&amp;, tensorflow::OpKernel**)&gt; &gt;::_M_invoke(const std::_Any_data &amp;, const tensorflow::NodeDef &amp;, &lt;unknown type in /home/lesliefang/venv_python36_RN50_Debug/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, CU 0x23b51f7a, DIE 0x23c57fc7&gt;) (__functor=..., __args#0=..., __args#1=&lt;optimized out&gt;)</div><div class="line">    at /home/lesliefang/gcc63/lib/gcc/x86_64-pc-linux-gnu/6.3.0/../../../../include/c++/6.3.0/functional:1717</div><div class="line">#10 0x00007fa3b49a164e in operator() (__args#1=&lt;optimized out&gt;, __args#0=..., this=0x169d87cf8)</div><div class="line">    at /home/lesliefang/gcc63/lib/gcc/x86_64-pc-linux-gnu/6.3.0/../../../../include/c++/6.3.0/functional:2127</div><div class="line">#11 tensorflow::(anonymous namespace)::ExecutorImpl::Initialize (this=this@entry=0x169d87ce0) at tensorflow/core/common_runtime/executor.cc:620</div><div class="line">#12 0x00007fa3b49a3646 in tensorflow::NewLocalExecutor (params=..., graph=..., executor=executor@entry=0x7ffca8d44218)</div><div class="line">    at tensorflow/core/common_runtime/executor.cc:2749</div><div class="line">#13 0x00007fa3b49a36d2 in tensorflow::(anonymous namespace)::DefaultExecutorRegistrar::Factory::NewExecutor (this=&lt;optimized out&gt;, params=...,</div><div class="line">    graph=..., out_executor=0x3ab72bb8) at tensorflow/core/common_runtime/executor.cc:2785</div><div class="line">#14 0x00007fa3b49a61b2 in tensorflow::NewExecutor (executor_type=..., params=..., graph=..., out_executor=out_executor@entry=0x3ab72bb8)</div><div class="line">    at tensorflow/core/common_runtime/executor_factory.cc:82</div><div class="line">#15 0x00007fa3ba128ee4 in tensorflow::DirectSession::CreateExecutors (this=this@entry=0x2edd8480, callable_options=...,</div><div class="line">    out_executors_and_keys=out_executors_and_keys@entry=0x7ffca8d448a0, out_func_info=out_func_info@entry=0x7ffca8d448b0,</div><div class="line">    run_state_args=run_state_args@entry=0x7ffca8d44fb0) at tensorflow/core/common_runtime/direct_session.cc:1296</div><div class="line">#16 0x00007fa3ba12a730 in tensorflow::DirectSession::GetOrCreateExecutors (this=this@entry=0x2edd8480, inputs=..., outputs=..., target_nodes=...,</div><div class="line">    executors_and_keys=0x7ffca8d44f48, run_state_args=0x7ffca8d44fb0) at tensorflow/core/common_runtime/direct_session.cc:1429</div><div class="line">    #17 0x00007fa3ba12b747 in tensorflow::DirectSession::Run (this=&lt;optimized out&gt;, run_options=..., inputs=..., output_names=..., target_nodes=...,</div><div class="line">    ---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---</div><div class="line">        outputs=0x7ffca8d45340, run_metadata=0x7ffca8d453a0) at tensorflow/core/common_runtime/direct_session.cc:749</div><div class="line">    #18 0x00007fa3b76729f1 in tensorflow::SessionRef::Run (this=0x38d4a5f0, run_options=..., inputs=..., output_tensor_names=...,</div><div class="line">        target_node_names=..., outputs=0x7ffca8d45340, run_metadata=0x7ffca8d453a0) at tensorflow/python/client/session_ref.cc:427</div><div class="line">    #19 0x00007fa3b78c2d9d in TF_Run_Helper (session=0x38d4a5f0, handle=handle@entry=0x0, run_options=run_options@entry=0x0, input_pairs=...,</div><div class="line">        output_tensor_names=..., c_outputs=c_outputs@entry=0x7ffca8d45708, target_oper_names=..., run_metadata=0x0, status=0x2b657788)</div><div class="line">        at tensorflow/c/c_api.cc:787</div><div class="line">    #20 0x00007fa3b78c3a3a in TF_SessionRun (session=session@entry=0x3b57ef60, run_options=run_options@entry=0x0, inputs=&lt;optimized out&gt;,</div><div class="line">        input_values=&lt;optimized out&gt;, ninputs=&lt;optimized out&gt;, outputs=0x36bbfc00, output_values=0x7ffca8d45708, noutputs=1, target_opers=0x0,</div><div class="line">        ntargets=0, run_metadata=0x0, status=0x2b657788) at tensorflow/c/c_api.cc:2638</div><div class="line">    #21 0x00007fa3b76710df in tensorflow::TF_SessionRun_wrapper_helper (session=0x3b57ef60, handle=handle@entry=0x0, run_options=0x0, inputs=...,</div><div class="line">        input_ndarrays=..., outputs=..., targets=..., run_metadata=0x0, out_status=0x2b657788, py_outputs=0x7ffca8d45a50)</div><div class="line">        at tensorflow/python/client/tf_session_helper.cc:410</div><div class="line">    #22 0x00007fa3b76711b2 in tensorflow::TF_SessionRun_wrapper (session=&lt;optimized out&gt;, run_options=&lt;optimized out&gt;, inputs=..., input_ndarrays=...,</div><div class="line">        outputs=..., targets=..., run_metadata=0x0, out_status=0x2b657788, py_outputs=0x7ffca8d45a50)</div><div class="line">        at tensorflow/python/client/tf_session_helper.cc:452</div><div class="line">    #23 0x00007fa3b760b8d0 in _wrap_TF_SessionRun_wrapper (args=&lt;optimized out&gt;)</div><div class="line">        at bazel-out/k8-dbg/bin/tensorflow/python/pywrap_tensorflow_internal.cc:20508</div></pre></td></tr></table></figure></p>
<p>关键代码分析：<br>op_kernel.cc:1302 CreateOpKernel函数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">// Everything needed for OpKernel construction.</div><div class="line">OpKernelConstruction context(</div><div class="line">    device_type, device, allocator, &amp;node_def, op_def, flib, inputs,</div><div class="line">    input_memory_types, outputs, output_memory_types, graph_def_version, &amp;s);</div><div class="line">*kernel = registration-&gt;factory-&gt;Create(&amp;context);</div></pre></td></tr></table></figure>
<p>OpKernelConstruction context构造了找寻合适的tensorflow的条件</p>
<p>总结：tensorflow这边node的多态有两层</p>
<ul>
<li>第一层是在tensorflow自己框架的设计上，在session.run的时候，第一次运行创建exectuor的时候进行</li>
<li>第二层多态是mkldnn层面上的，在调用op.Compute的方法的时候，第一次调用会去根据输入的数据类型选择并创建正确的mkldnn的pd</li>
</ul>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/技术-tensorflow/" rel="tag"># 技术 tensorflow</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/02/08/搜索/" rel="next" title="搭建电商搜索引擎">
                <i class="fa fa-chevron-left"></i> 搭建电商搜索引擎
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/03/07/推荐系统/" rel="prev" title="推荐系统">
                推荐系统 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

          
          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2019/02/27/tensorflow二次开发/"
           data-title="tensorflow二次开发" data-url="http://yoursite.com/2019/02/27/tensorflow二次开发/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/popeve.jpg"
               alt="Leslie" />
          <p class="site-author-name" itemprop="name">Leslie</p>
           
              <p class="site-description motion-element" itemprop="description">记录心情与能力的成长</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">72</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#编译"><span class="nav-number">1.</span> <span class="nav-text">编译</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#增量编译"><span class="nav-number">1.1.</span> <span class="nav-text">增量编译</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#编译之后"><span class="nav-number">2.</span> <span class="nav-text">编译之后</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#编译debug版本的tensorflow"><span class="nav-number">3.</span> <span class="nav-text">编译debug版本的tensorflow</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#指定编译目录"><span class="nav-number">3.1.</span> <span class="nav-text">指定编译目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#编译报错找不到–march-broadwell"><span class="nav-number">3.2.</span> <span class="nav-text">编译报错找不到–march=broadwell</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#whell太大无法打包"><span class="nav-number">3.3.</span> <span class="nav-text">whell太大无法打包</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#gdb-调试"><span class="nav-number">4.</span> <span class="nav-text">gdb 调试</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#warning找不到文件"><span class="nav-number">4.1.</span> <span class="nav-text">warning找不到文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#技巧"><span class="nav-number">4.2.</span> <span class="nav-text">技巧</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mkldnn调试"><span class="nav-number">5.</span> <span class="nav-text">mkldnn调试</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#看python到C-调用关系"><span class="nav-number">6.</span> <span class="nav-text">看python到C++调用关系</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#以Session-为例子：tf-Session时候的调用关系"><span class="nav-number">6.1.</span> <span class="nav-text">以Session 为例子：tf.Session时候的调用关系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#以matmul为列"><span class="nav-number">6.2.</span> <span class="nav-text">以matmul为列</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#以conv2d为例"><span class="nav-number">6.3.</span> <span class="nav-text">以conv2d为例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#INT8-operation"><span class="nav-number">6.4.</span> <span class="nav-text">INT8 operation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#自己定义个operation"><span class="nav-number">7.</span> <span class="nav-text">自己定义个operation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#定义operation"><span class="nav-number">7.1.</span> <span class="nav-text">定义operation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#定义kernel"><span class="nav-number">7.2.</span> <span class="nav-text">定义kernel</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#添加python-wrap"><span class="nav-number">7.3.</span> <span class="nav-text">添加python wrap</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#测试"><span class="nav-number">7.4.</span> <span class="nav-text">测试</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多线程"><span class="nav-number">8.</span> <span class="nav-text">多线程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#核心运行机制"><span class="nav-number">9.</span> <span class="nav-text">核心运行机制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#在python里面"><span class="nav-number">9.1.</span> <span class="nav-text">在python里面</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#下面进入C-的部分"><span class="nav-number">9.2.</span> <span class="nav-text">下面进入C++的部分</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#调试CreateExecutors的create-kernel函数"><span class="nav-number">9.3.</span> <span class="nav-text">调试CreateExecutors的create_kernel函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#看一个inner-product的kernel是怎么生成的"><span class="nav-number">10.</span> <span class="nav-text">看一个inner product的kernel是怎么生成的</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#通过pb文件去看调用的kernel"><span class="nav-number">11.</span> <span class="nav-text">通过pb文件去看调用的kernel</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Leslie</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

<div class="busuanzi-count">

  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">本站访客数<span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv">本站总访问量<span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  

</div>



        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    
    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"leslie-fang"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  













  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  

  


  

</body>
</html>
